{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import safety_gym\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from imitation_learning.utils import Dataset,STARDataset, D4RLTrajectoryDataset, evaluate_on_env, get_d4rl_normalized_score\n",
    "from imitation_learning.model import BCAgent,GuideVAE,Starloss\n",
    "import pdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--env', type=str, default='halfcheetah')\n",
    "parser.add_argument('--dataset', type=str, default='medium')\n",
    "parser.add_argument('--rtg_scale', type=int, default=1000)\n",
    "\n",
    "parser.add_argument('--max_eval_ep_len', type=int, default=1000)\n",
    "parser.add_argument('--num_eval_ep', type=int, default=10)\n",
    "\n",
    "parser.add_argument('--dataset_dir', type=str, default='data/')\n",
    "parser.add_argument('--log_dir', type=str, default='dt_runs/')\n",
    "\n",
    "parser.add_argument('--context_len', type=int, default=10)\n",
    "parser.add_argument('--n_blocks', type=int, default=3)\n",
    "parser.add_argument('--embed_dim', type=int, default=128)\n",
    "parser.add_argument('--n_heads', type=int, default=1)\n",
    "parser.add_argument('--dropout_p', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--wt_decay', type=float, default=1e-4)\n",
    "parser.add_argument('--warmup_steps', type=int, default=10000)\n",
    "\n",
    "parser.add_argument('--max_train_iters', type=int, default=200)\n",
    "parser.add_argument('--num_updates_per_iter', type=int, default=100)\n",
    "\n",
    "parser.add_argument('--device', type=str, default='cuda')\n",
    "\n",
    "parser.add_argument('--seed',type=int, default=0)\n",
    "parser.add_argument('--log_fn',type=str,default='default')\n",
    "parser.add_argument('--eval', action='store_true')\n",
    "parser.add_argument('--load_model_path', type=str,default='')\n",
    "parser.add_argument('--squences_length', type=int, default=10)\n",
    "parser.add_argument('--recovery_length', type=int, default=5)\n",
    "parser.add_argument('--total_episodes', type=int, default=2186)\n",
    "parser.add_argument('--star_batch_size', type=int, default=64)\n",
    "# parser.add_argument('--log_fn',type=str,default='default')\n",
    "parser.add_argument('--feature_size', type=int, default=120)\n",
    "parser.add_argument('--class_size', type=int, default=120)\n",
    "parser.add_argument('--latent_size', type=int, default=64)\n",
    "parser.add_argument('--batch_nums', type=int, default=1000)\n",
    "parser.add_argument('--traj_length', type=int, default=1000)\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "start time: 23-03-23-08-26-25\n",
      "============================================================\n",
      "device set to: cuda\n",
      "dataset path: data//halfcheetah_medium-v2.pkl\n",
      "model save path: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-08-26-25.pt\n",
      "log csv save path: dt_runs/dt_halfcheetah_medium-v2_log_23-03-23-08-26-25.csv\n",
      "train:statesmean and statesstd=[-6.8475075e-02  1.4725347e-02 -1.8368107e-01 -2.7612743e-01\n",
      " -3.4158602e-01 -9.3233280e-02 -2.1339475e-01 -8.7635852e-02\n",
      "  5.1738744e+00 -4.2856235e-02 -3.6295928e-02  1.4089356e-01\n",
      "  6.0693521e-02  9.5642865e-02  6.7417443e-02  4.8005907e-03\n",
      "  1.2263178e-02] and [ 0.07467017  0.30077568  0.30200034  0.34436345  0.17599103  0.50729656\n",
      "  0.25660416  0.32957837  1.2546803   0.75977516  1.9806889   6.5655966\n",
      "  7.4680963   4.469275   10.567002    5.672571    7.499262  ]\n",
      "\n",
      "train:actions_mean and statesstd=[-0.32292253 -0.4103281  -0.7357532  -0.12302412 -0.46861967 -0.1577406 ] and [0.80508125 0.67032164 0.54892266 0.68336844 0.6407193  0.71960443]\n",
      "\n",
      "train:rewards_mean and statesstd=4.771085739135742 and 1.2073556648025512\n",
      "\n",
      "==================================================\n",
      "Starting new experiment:  data//halfcheetah_medium-v2.pkl\n",
      "800 trajectories, 800000 timesteps found\n",
      "Average return: 4.77, std: 1.21\n",
      "Max return: 8.33, min: -2.84\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_2/why_22/anaconda3/envs/safe-slac/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "seed = args.seed\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "dataset = args.dataset          # medium / medium-replay / medium-expert\n",
    "\n",
    "# use v3 env for evaluation because\n",
    "# Decision Transformer paper evaluates results on v3 envs\n",
    "\n",
    "if args.env == 'walker2d':\n",
    "    env_name = 'Walker2d-v3'\n",
    "    #rtg_target = 5000\n",
    "    env_d4rl_name = f'walker2d_{dataset}-v2'\n",
    "\n",
    "elif args.env == 'halfcheetah':\n",
    "    env_name = 'HalfCheetah-v3'\n",
    "    #rtg_target = 6000\n",
    "    env_d4rl_name = f'halfcheetah_{dataset}-v2'\n",
    "\n",
    "elif args.env == 'hopper':\n",
    "    env_name = 'Hopper-v3'\n",
    "    #rtg_target = 3600\n",
    "    env_d4rl_name = f'hopper_{dataset}-v2'\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "max_eval_ep_len = args.max_eval_ep_len  # max len of one episode\n",
    "num_eval_ep = args.num_eval_ep          # num of evaluation episodes\n",
    "rtg_scale = args.rtg_scale\n",
    "\n",
    "batch_size = args.batch_size            # training batch size\n",
    "lr = args.lr                            # learning rate\n",
    "wt_decay = args.wt_decay                # weight decay\n",
    "warmup_steps = args.warmup_steps        # warmup steps for lr scheduler\n",
    "\n",
    "# total updates = max_train_iters x num_updates_per_iter\n",
    "max_train_iters = args.max_train_iters\n",
    "num_updates_per_iter = args.num_updates_per_iter\n",
    "\n",
    "context_len = args.context_len      # K in decision transformer\n",
    "n_blocks = args.n_blocks            # num of transformer blocks\n",
    "embed_dim = args.embed_dim          # embedding (hidden) dim of transformer\n",
    "n_heads = args.n_heads              # num of transformer heads\n",
    "dropout_p = args.dropout_p          # dropout probability\n",
    "star_batch_size = args.star_batch_size\n",
    "\n",
    "# load data from this file\n",
    "dataset_path = f'{args.dataset_dir}/{env_d4rl_name}.pkl'\n",
    "\n",
    "# saves model and csv in this directory\n",
    "log_dir = args.log_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# training and evaluation device\n",
    "device = torch.device(args.device)\n",
    "\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "start_time_str = start_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "prefix = \"dt_\" + env_d4rl_name\n",
    "\n",
    "save_model_name =  prefix + \"_model_\" + start_time_str + \".pt\"\n",
    "save_model_path = os.path.join(log_dir, save_model_name)\n",
    "save_best_model_path = save_model_path[:-3] + \"_best.pt\"\n",
    "\n",
    "log_csv_name = prefix + \"_log_\" + start_time_str + \".csv\"\n",
    "log_csv_path = os.path.join(log_dir, log_csv_name)\n",
    "\n",
    "csv_writer = csv.writer(open(log_csv_path, 'a', 1))\n",
    "csv_header = ([\"duration\", \"num_updates\", \"action_loss\",\n",
    "                \"eval_avg_reward\", \"eval_avg_ep_len\", \"eval_d4rl_score\"])\n",
    "\n",
    "csv_writer.writerow(csv_header)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"start time: \" + start_time_str)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"device set to: \" + str(device))\n",
    "print(\"dataset path: \" + dataset_path)\n",
    "print(\"model save path: \" + save_model_path)\n",
    "print(\"log csv save path: \" + log_csv_path)\n",
    "\n",
    "traj_dataset = Dataset(dataset_path, args.context_len,False)\n",
    "traj_star_dataset = D4RLTrajectoryDataset(dataset_path, context_len)\n",
    "\n",
    "traj_star_loader = DataLoader(\n",
    "                    traj_star_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=True\n",
    "                )\n",
    "traj_data_loader = DataLoader(\n",
    "                        traj_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True,\n",
    "                        drop_last=True\n",
    "                    )\n",
    "\n",
    "data_iter = iter(traj_data_loader)\n",
    "star_iter = iter(traj_star_loader)\n",
    "\n",
    "## get state stats from dataset\n",
    "state_mean, state_std ,reward_mean,reward_std = traj_star_dataset.get_state_stats()\n",
    "reward_mean = torch.from_numpy(np.array(reward_mean)).to(device)\n",
    "reward_std = torch.from_numpy(np.array(reward_std)).to(device)\n",
    "\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "model_guide = GuideVAE(args.feature_size, args.class_size, args.latent_size).to(device)\n",
    "model = BCAgent(\n",
    "            state_dim=state_dim,\n",
    "            act_dim=act_dim,\n",
    "            n_blocks=n_blocks,\n",
    "            h_dim=embed_dim,\n",
    "            context_len=context_len,\n",
    "            n_heads=n_heads,\n",
    "            drop_p=dropout_p,\n",
    "        ).to(device)\n",
    "\n",
    "optimizer_guide = torch.optim.AdamW( \n",
    "                        model_guide.parameters(),\n",
    "                        lr=lr,\n",
    "                        weight_decay=wt_decay\n",
    "                    )\n",
    "optimizer = torch.optim.AdamW(\n",
    "                    model.parameters(),\n",
    "                    lr=lr,\n",
    "                    weight_decay=wt_decay\n",
    "                )\n",
    "\n",
    "scheduler_guide = torch.optim.lr_scheduler.LambdaLR(\n",
    "                        optimizer_guide,\n",
    "                        lambda steps: min((steps+1)/warmup_steps, 1)\n",
    "                )\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "                        optimizer,\n",
    "                        lambda steps: min((steps+1)/warmup_steps, 1)\n",
    "                    )\n",
    "\n",
    "max_d4rl_score = -1.0\n",
    "total_updates = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of updates: 100\n",
      "GODA loss: 1.70667\n",
      "\n",
      "num of updates: 200\n",
      "GODA loss: 1.66806\n",
      "\n",
      "num of updates: 300\n",
      "GODA loss: 1.66792\n",
      "\n",
      "num of updates: 400\n",
      "GODA loss: 1.60038\n",
      "\n",
      "num of updates: 500\n",
      "GODA loss: 1.55275\n",
      "\n",
      "num of updates: 600\n",
      "GODA loss: 1.50771\n",
      "\n",
      "num of updates: 700\n",
      "GODA loss: 1.46302\n",
      "\n",
      "num of updates: 800\n",
      "GODA loss: 1.40118\n",
      "\n",
      "num of updates: 900\n",
      "GODA loss: 1.31922\n",
      "\n",
      "num of updates: 1000\n",
      "GODA loss: 1.23680\n",
      "\n",
      "num of updates: 1100\n",
      "GODA loss: 1.14650\n",
      "\n",
      "num of updates: 1200\n",
      "GODA loss: 1.04169\n",
      "\n",
      "num of updates: 1300\n",
      "GODA loss: 0.95276\n",
      "\n",
      "num of updates: 1400\n",
      "GODA loss: 0.88355\n",
      "\n",
      "num of updates: 1500\n",
      "GODA loss: 0.82907\n",
      "\n",
      "num of updates: 1600\n",
      "GODA loss: 0.76977\n",
      "\n",
      "num of updates: 1700\n",
      "GODA loss: 0.71855\n",
      "\n",
      "num of updates: 1800\n",
      "GODA loss: 0.66975\n",
      "\n",
      "num of updates: 1900\n",
      "GODA loss: 0.62810\n",
      "\n",
      "num of updates: 2000\n",
      "GODA loss: 0.58725\n",
      "\n",
      "num of updates: 2100\n",
      "GODA loss: 0.54841\n",
      "\n",
      "num of updates: 2200\n",
      "GODA loss: 0.50730\n",
      "\n",
      "num of updates: 2300\n",
      "GODA loss: 0.47690\n",
      "\n",
      "num of updates: 2400\n",
      "GODA loss: 0.44766\n",
      "\n",
      "num of updates: 2500\n",
      "GODA loss: 0.41622\n",
      "\n",
      "num of updates: 2600\n",
      "GODA loss: 0.38454\n",
      "\n",
      "num of updates: 2700\n",
      "GODA loss: 0.35613\n",
      "\n",
      "num of updates: 2800\n",
      "GODA loss: 0.32430\n",
      "\n",
      "num of updates: 2900\n",
      "GODA loss: 0.29500\n",
      "\n",
      "num of updates: 3000\n",
      "GODA loss: 0.26862\n",
      "\n",
      "num of updates: 3100\n",
      "GODA loss: 0.23772\n",
      "\n",
      "num of updates: 3200\n",
      "GODA loss: 0.21768\n",
      "\n",
      "num of updates: 3300\n",
      "GODA loss: 0.19971\n",
      "\n",
      "num of updates: 3400\n",
      "GODA loss: 0.16308\n",
      "\n",
      "num of updates: 3500\n",
      "GODA loss: 0.13358\n",
      "\n",
      "num of updates: 3600\n",
      "GODA loss: 0.10820\n",
      "\n",
      "num of updates: 3700\n",
      "GODA loss: 0.07909\n",
      "\n",
      "num of updates: 3800\n",
      "GODA loss: 0.04475\n",
      "\n",
      "num of updates: 3900\n",
      "GODA loss: 0.02424\n",
      "\n",
      "num of updates: 4000\n",
      "GODA loss: -0.00338\n",
      "\n",
      "num of updates: 4100\n",
      "GODA loss: -0.02794\n",
      "\n",
      "num of updates: 4200\n",
      "GODA loss: -0.04850\n",
      "\n",
      "num of updates: 4300\n",
      "GODA loss: -0.07823\n",
      "\n",
      "num of updates: 4400\n",
      "GODA loss: -0.09763\n",
      "\n",
      "num of updates: 4500\n",
      "GODA loss: -0.12544\n",
      "\n",
      "num of updates: 4600\n",
      "GODA loss: -0.15203\n",
      "\n",
      "num of updates: 4700\n",
      "GODA loss: -0.17178\n",
      "\n",
      "num of updates: 4800\n",
      "GODA loss: -0.19727\n",
      "\n",
      "num of updates: 4900\n",
      "GODA loss: -0.21216\n",
      "\n",
      "num of updates: 5000\n",
      "GODA loss: -0.23850\n",
      "\n",
      "num of updates: 5100\n",
      "GODA loss: -0.26619\n",
      "\n",
      "num of updates: 5200\n",
      "GODA loss: -0.27493\n",
      "\n",
      "num of updates: 5300\n",
      "GODA loss: -0.29741\n",
      "\n",
      "num of updates: 5400\n",
      "GODA loss: -0.31820\n",
      "\n",
      "num of updates: 5500\n",
      "GODA loss: -0.33546\n",
      "\n",
      "num of updates: 5600\n",
      "GODA loss: -0.35154\n",
      "\n",
      "num of updates: 5700\n",
      "GODA loss: -0.36856\n",
      "\n",
      "num of updates: 5800\n",
      "GODA loss: -0.37402\n",
      "\n",
      "num of updates: 5900\n",
      "GODA loss: -0.39955\n",
      "\n",
      "num of updates: 6000\n",
      "GODA loss: -0.40597\n",
      "\n",
      "num of updates: 6100\n",
      "GODA loss: -0.42353\n",
      "\n",
      "num of updates: 6200\n",
      "GODA loss: -0.43422\n",
      "\n",
      "num of updates: 6300\n",
      "GODA loss: -0.43943\n",
      "\n",
      "num of updates: 6400\n",
      "GODA loss: -0.45959\n",
      "\n",
      "num of updates: 6500\n",
      "GODA loss: -0.46727\n",
      "\n",
      "num of updates: 6600\n",
      "GODA loss: -0.49198\n",
      "\n",
      "num of updates: 6700\n",
      "GODA loss: -0.49313\n",
      "\n",
      "num of updates: 6800\n",
      "GODA loss: -0.49792\n",
      "\n",
      "num of updates: 6900\n",
      "GODA loss: -0.51266\n",
      "\n",
      "num of updates: 7000\n",
      "GODA loss: -0.52393\n",
      "\n",
      "num of updates: 7100\n",
      "GODA loss: -0.53006\n",
      "\n",
      "num of updates: 7200\n",
      "GODA loss: -0.54052\n",
      "\n",
      "num of updates: 7300\n",
      "GODA loss: -0.55403\n",
      "\n",
      "num of updates: 7400\n",
      "GODA loss: -0.56272\n",
      "\n",
      "num of updates: 7500\n",
      "GODA loss: -0.57864\n",
      "\n",
      "num of updates: 7600\n",
      "GODA loss: -0.58105\n",
      "\n",
      "num of updates: 7700\n",
      "GODA loss: -0.58683\n",
      "\n",
      "num of updates: 7800\n",
      "GODA loss: -0.60214\n",
      "\n",
      "num of updates: 7900\n",
      "GODA loss: -0.60233\n",
      "\n",
      "num of updates: 8000\n",
      "GODA loss: -0.61120\n",
      "\n",
      "num of updates: 8100\n",
      "GODA loss: -0.61496\n",
      "\n",
      "num of updates: 8200\n",
      "GODA loss: -0.62685\n",
      "\n",
      "num of updates: 8300\n",
      "GODA loss: -0.63957\n",
      "\n",
      "num of updates: 8400\n",
      "GODA loss: -0.64505\n",
      "\n",
      "num of updates: 8500\n",
      "GODA loss: -0.65387\n",
      "\n",
      "num of updates: 8600\n",
      "GODA loss: -0.65408\n",
      "\n",
      "num of updates: 8700\n",
      "GODA loss: -0.66104\n",
      "\n",
      "num of updates: 8800\n",
      "GODA loss: -0.65910\n",
      "\n",
      "num of updates: 8900\n",
      "GODA loss: -0.67036\n",
      "\n",
      "num of updates: 9000\n",
      "GODA loss: -0.68231\n",
      "\n",
      "num of updates: 9100\n",
      "GODA loss: -0.67729\n",
      "\n",
      "num of updates: 9200\n",
      "GODA loss: -0.68404\n",
      "\n",
      "num of updates: 9300\n",
      "GODA loss: -0.68343\n",
      "\n",
      "num of updates: 9400\n",
      "GODA loss: -0.68660\n",
      "\n",
      "num of updates: 9500\n",
      "GODA loss: -0.69514\n",
      "\n",
      "num of updates: 9600\n",
      "GODA loss: -0.69929\n",
      "\n",
      "num of updates: 9700\n",
      "GODA loss: -0.69890\n",
      "\n",
      "num of updates: 9800\n",
      "GODA loss: -0.70188\n",
      "\n",
      "num of updates: 9900\n",
      "GODA loss: -0.70963\n",
      "\n",
      "num of updates: 10000\n",
      "GODA loss: -0.70405\n",
      "\n",
      "num of updates: 10100\n",
      "GODA loss: -0.71223\n",
      "\n",
      "num of updates: 10200\n",
      "GODA loss: -0.71553\n",
      "\n",
      "num of updates: 10300\n",
      "GODA loss: -0.71664\n",
      "\n",
      "num of updates: 10400\n",
      "GODA loss: -0.72679\n",
      "\n",
      "num of updates: 10500\n",
      "GODA loss: -0.72291\n",
      "\n",
      "num of updates: 10600\n",
      "GODA loss: -0.72762\n",
      "\n",
      "num of updates: 10700\n",
      "GODA loss: -0.71928\n",
      "\n",
      "num of updates: 10800\n",
      "GODA loss: -0.73137\n",
      "\n",
      "num of updates: 10900\n",
      "GODA loss: -0.74145\n",
      "\n",
      "num of updates: 11000\n",
      "GODA loss: -0.74083\n",
      "\n",
      "num of updates: 11100\n",
      "GODA loss: -0.73055\n",
      "\n",
      "num of updates: 11200\n",
      "GODA loss: -0.74026\n",
      "\n",
      "num of updates: 11300\n",
      "GODA loss: -0.73550\n",
      "\n",
      "num of updates: 11400\n",
      "GODA loss: -0.74200\n",
      "\n",
      "num of updates: 11500\n",
      "GODA loss: -0.74501\n",
      "\n",
      "num of updates: 11600\n",
      "GODA loss: -0.74703\n",
      "\n",
      "num of updates: 11700\n",
      "GODA loss: -0.74408\n",
      "\n",
      "num of updates: 11800\n",
      "GODA loss: -0.75457\n",
      "\n",
      "num of updates: 11900\n",
      "GODA loss: -0.75464\n",
      "\n",
      "num of updates: 12000\n",
      "GODA loss: -0.75049\n",
      "\n",
      "num of updates: 12100\n",
      "GODA loss: -0.76083\n",
      "\n",
      "num of updates: 12200\n",
      "GODA loss: -0.75518\n",
      "\n",
      "num of updates: 12300\n",
      "GODA loss: -0.75750\n",
      "\n",
      "num of updates: 12400\n",
      "GODA loss: -0.75594\n",
      "\n",
      "num of updates: 12500\n",
      "GODA loss: -0.76130\n",
      "\n",
      "num of updates: 12600\n",
      "GODA loss: -0.76740\n",
      "\n",
      "num of updates: 12700\n",
      "GODA loss: -0.76444\n",
      "\n",
      "num of updates: 12800\n",
      "GODA loss: -0.75894\n",
      "\n",
      "num of updates: 12900\n",
      "GODA loss: -0.76536\n",
      "\n",
      "num of updates: 13000\n",
      "GODA loss: -0.77032\n",
      "\n",
      "num of updates: 13100\n",
      "GODA loss: -0.77300\n",
      "\n",
      "num of updates: 13200\n",
      "GODA loss: -0.76776\n",
      "\n",
      "num of updates: 13300\n",
      "GODA loss: -0.77070\n",
      "\n",
      "num of updates: 13400\n",
      "GODA loss: -0.77466\n",
      "\n",
      "num of updates: 13500\n",
      "GODA loss: -0.77573\n",
      "\n",
      "num of updates: 13600\n",
      "GODA loss: -0.77815\n",
      "\n",
      "num of updates: 13700\n",
      "GODA loss: -0.77618\n",
      "\n",
      "num of updates: 13800\n",
      "GODA loss: -0.77646\n",
      "\n",
      "num of updates: 13900\n",
      "GODA loss: -0.77981\n",
      "\n",
      "num of updates: 14000\n",
      "GODA loss: -0.77918\n",
      "\n",
      "num of updates: 14100\n",
      "GODA loss: -0.78744\n",
      "\n",
      "num of updates: 14200\n",
      "GODA loss: -0.77994\n",
      "\n",
      "num of updates: 14300\n",
      "GODA loss: -0.78127\n",
      "\n",
      "num of updates: 14400\n",
      "GODA loss: -0.78527\n",
      "\n",
      "num of updates: 14500\n",
      "GODA loss: -0.78794\n",
      "\n",
      "num of updates: 14600\n",
      "GODA loss: -0.79038\n",
      "\n",
      "num of updates: 14700\n",
      "GODA loss: -0.79019\n",
      "\n",
      "num of updates: 14800\n",
      "GODA loss: -0.79698\n",
      "\n",
      "num of updates: 14900\n",
      "GODA loss: -0.79171\n",
      "\n",
      "num of updates: 15000\n",
      "GODA loss: -0.79126\n",
      "\n",
      "num of updates: 15100\n",
      "GODA loss: -0.79531\n",
      "\n",
      "num of updates: 15200\n",
      "GODA loss: -0.79148\n",
      "\n",
      "num of updates: 15300\n",
      "GODA loss: -0.79087\n",
      "\n",
      "num of updates: 15400\n",
      "GODA loss: -0.80038\n",
      "\n",
      "num of updates: 15500\n",
      "GODA loss: -0.79290\n",
      "\n",
      "num of updates: 15600\n",
      "GODA loss: -0.79293\n",
      "\n",
      "num of updates: 15700\n",
      "GODA loss: -0.80315\n",
      "\n",
      "num of updates: 15800\n",
      "GODA loss: -0.80291\n",
      "\n",
      "num of updates: 15900\n",
      "GODA loss: -0.80074\n",
      "\n",
      "num of updates: 16000\n",
      "GODA loss: -0.79952\n",
      "\n",
      "num of updates: 16100\n",
      "GODA loss: -0.81109\n",
      "\n",
      "num of updates: 16200\n",
      "GODA loss: -0.80536\n",
      "\n",
      "num of updates: 16300\n",
      "GODA loss: -0.80236\n",
      "\n",
      "num of updates: 16400\n",
      "GODA loss: -0.80189\n",
      "\n",
      "num of updates: 16500\n",
      "GODA loss: -0.80889\n",
      "\n",
      "num of updates: 16600\n",
      "GODA loss: -0.79984\n",
      "\n",
      "num of updates: 16700\n",
      "GODA loss: -0.80055\n",
      "\n",
      "num of updates: 16800\n",
      "GODA loss: -0.80304\n",
      "\n",
      "num of updates: 16900\n",
      "GODA loss: -0.81794\n",
      "\n",
      "num of updates: 17000\n",
      "GODA loss: -0.82134\n",
      "\n",
      "num of updates: 17100\n",
      "GODA loss: -0.80204\n",
      "\n",
      "num of updates: 17200\n",
      "GODA loss: -0.81433\n",
      "\n",
      "num of updates: 17300\n",
      "GODA loss: -0.81159\n",
      "\n",
      "num of updates: 17400\n",
      "GODA loss: -0.80432\n",
      "\n",
      "num of updates: 17500\n",
      "GODA loss: -0.81534\n",
      "\n",
      "num of updates: 17600\n",
      "GODA loss: -0.80496\n",
      "\n",
      "num of updates: 17700\n",
      "GODA loss: -0.81586\n",
      "\n",
      "num of updates: 17800\n",
      "GODA loss: -0.81754\n",
      "\n",
      "num of updates: 17900\n",
      "GODA loss: -0.81870\n",
      "\n",
      "num of updates: 18000\n",
      "GODA loss: -0.81142\n",
      "\n",
      "num of updates: 18100\n",
      "GODA loss: -0.81836\n",
      "\n",
      "num of updates: 18200\n",
      "GODA loss: -0.82033\n",
      "\n",
      "num of updates: 18300\n",
      "GODA loss: -0.81639\n",
      "\n",
      "num of updates: 18400\n",
      "GODA loss: -0.82242\n",
      "\n",
      "num of updates: 18500\n",
      "GODA loss: -0.82304\n",
      "\n",
      "num of updates: 18600\n",
      "GODA loss: -0.82169\n",
      "\n",
      "num of updates: 18700\n",
      "GODA loss: -0.81860\n",
      "\n",
      "num of updates: 18800\n",
      "GODA loss: -0.82525\n",
      "\n",
      "num of updates: 18900\n",
      "GODA loss: -0.82037\n",
      "\n",
      "num of updates: 19000\n",
      "GODA loss: -0.82800\n",
      "\n",
      "num of updates: 19100\n",
      "GODA loss: -0.82617\n",
      "\n",
      "num of updates: 19200\n",
      "GODA loss: -0.81970\n",
      "\n",
      "num of updates: 19300\n",
      "GODA loss: -0.82564\n",
      "\n",
      "num of updates: 19400\n",
      "GODA loss: -0.82749\n",
      "\n",
      "num of updates: 19500\n",
      "GODA loss: -0.82770\n",
      "\n",
      "num of updates: 19600\n",
      "GODA loss: -0.83357\n",
      "\n",
      "num of updates: 19700\n",
      "GODA loss: -0.82881\n",
      "\n",
      "num of updates: 19800\n",
      "GODA loss: -0.83061\n",
      "\n",
      "num of updates: 19900\n",
      "GODA loss: -0.83353\n",
      "\n",
      "num of updates: 20000\n",
      "GODA loss: -0.83801\n",
      "\n",
      "num of updates: 20100\n",
      "GODA loss: -0.83711\n",
      "\n",
      "num of updates: 20200\n",
      "GODA loss: -0.83270\n",
      "\n",
      "num of updates: 20300\n",
      "GODA loss: -0.83733\n",
      "\n",
      "num of updates: 20400\n",
      "GODA loss: -0.84090\n",
      "\n",
      "num of updates: 20500\n",
      "GODA loss: -0.83732\n",
      "\n",
      "num of updates: 20600\n",
      "GODA loss: -0.83138\n",
      "\n",
      "num of updates: 20700\n",
      "GODA loss: -0.83576\n",
      "\n",
      "num of updates: 20800\n",
      "GODA loss: -0.84301\n",
      "\n",
      "num of updates: 20900\n",
      "GODA loss: -0.84307\n",
      "\n",
      "num of updates: 21000\n",
      "GODA loss: -0.84553\n",
      "\n",
      "num of updates: 21100\n",
      "GODA loss: -0.84429\n",
      "\n",
      "num of updates: 21200\n",
      "GODA loss: -0.83774\n",
      "\n",
      "num of updates: 21300\n",
      "GODA loss: -0.84070\n",
      "\n",
      "num of updates: 21400\n",
      "GODA loss: -0.83683\n",
      "\n",
      "num of updates: 21500\n",
      "GODA loss: -0.84267\n",
      "\n",
      "num of updates: 21600\n",
      "GODA loss: -0.84092\n",
      "\n",
      "num of updates: 21700\n",
      "GODA loss: -0.85251\n",
      "\n",
      "num of updates: 21800\n",
      "GODA loss: -0.84284\n",
      "\n",
      "num of updates: 21900\n",
      "GODA loss: -0.85403\n",
      "\n",
      "num of updates: 22000\n",
      "GODA loss: -0.84603\n",
      "\n",
      "num of updates: 22100\n",
      "GODA loss: -0.84167\n",
      "\n",
      "num of updates: 22200\n",
      "GODA loss: -0.84973\n",
      "\n",
      "num of updates: 22300\n",
      "GODA loss: -0.85204\n",
      "\n",
      "num of updates: 22400\n",
      "GODA loss: -0.84687\n",
      "\n",
      "num of updates: 22500\n",
      "GODA loss: -0.85246\n",
      "\n",
      "num of updates: 22600\n",
      "GODA loss: -0.85136\n",
      "\n",
      "num of updates: 22700\n",
      "GODA loss: -0.84869\n",
      "\n",
      "num of updates: 22800\n",
      "GODA loss: -0.85390\n",
      "\n",
      "num of updates: 22900\n",
      "GODA loss: -0.85886\n",
      "\n",
      "num of updates: 23000\n",
      "GODA loss: -0.85278\n",
      "\n",
      "num of updates: 23100\n",
      "GODA loss: -0.85341\n",
      "\n",
      "num of updates: 23200\n",
      "GODA loss: -0.84928\n",
      "\n",
      "num of updates: 23300\n",
      "GODA loss: -0.86386\n",
      "\n",
      "num of updates: 23400\n",
      "GODA loss: -0.85801\n",
      "\n",
      "num of updates: 23500\n",
      "GODA loss: -0.85529\n",
      "\n",
      "num of updates: 23600\n",
      "GODA loss: -0.86552\n",
      "\n",
      "num of updates: 23700\n",
      "GODA loss: -0.85558\n",
      "\n",
      "num of updates: 23800\n",
      "GODA loss: -0.85875\n",
      "\n",
      "num of updates: 23900\n",
      "GODA loss: -0.86229\n",
      "\n",
      "num of updates: 24000\n",
      "GODA loss: -0.85973\n",
      "\n",
      "num of updates: 24100\n",
      "GODA loss: -0.86414\n",
      "\n",
      "num of updates: 24200\n",
      "GODA loss: -0.86608\n",
      "\n",
      "num of updates: 24300\n",
      "GODA loss: -0.86288\n",
      "\n",
      "num of updates: 24400\n",
      "GODA loss: -0.86413\n",
      "\n",
      "num of updates: 24500\n",
      "GODA loss: -0.86475\n",
      "\n",
      "num of updates: 24600\n",
      "GODA loss: -0.86133\n",
      "\n",
      "num of updates: 24700\n",
      "GODA loss: -0.86221\n",
      "\n",
      "num of updates: 24800\n",
      "GODA loss: -0.86771\n",
      "\n",
      "num of updates: 24900\n",
      "GODA loss: -0.86515\n",
      "\n",
      "num of updates: 25000\n",
      "GODA loss: -0.86393\n",
      "\n",
      "num of updates: 25100\n",
      "GODA loss: -0.86556\n",
      "\n",
      "num of updates: 25200\n",
      "GODA loss: -0.86883\n",
      "\n",
      "num of updates: 25300\n",
      "GODA loss: -0.87510\n",
      "\n",
      "num of updates: 25400\n",
      "GODA loss: -0.87328\n",
      "\n",
      "num of updates: 25500\n",
      "GODA loss: -0.86776\n",
      "\n",
      "num of updates: 25600\n",
      "GODA loss: -0.87315\n",
      "\n",
      "num of updates: 25700\n",
      "GODA loss: -0.85982\n",
      "\n",
      "num of updates: 25800\n",
      "GODA loss: -0.87326\n",
      "\n",
      "num of updates: 25900\n",
      "GODA loss: -0.87381\n",
      "\n",
      "num of updates: 26000\n",
      "GODA loss: -0.87350\n",
      "\n",
      "num of updates: 26100\n",
      "GODA loss: -0.86705\n",
      "\n",
      "num of updates: 26200\n",
      "GODA loss: -0.88190\n",
      "\n",
      "num of updates: 26300\n",
      "GODA loss: -0.87442\n",
      "\n",
      "num of updates: 26400\n",
      "GODA loss: -0.86958\n",
      "\n",
      "num of updates: 26500\n",
      "GODA loss: -0.87602\n",
      "\n",
      "num of updates: 26600\n",
      "GODA loss: -0.87329\n",
      "\n",
      "num of updates: 26700\n",
      "GODA loss: -0.87742\n",
      "\n",
      "num of updates: 26800\n",
      "GODA loss: -0.88176\n",
      "\n",
      "num of updates: 26900\n",
      "GODA loss: -0.88081\n",
      "\n",
      "num of updates: 27000\n",
      "GODA loss: -0.88395\n",
      "\n",
      "num of updates: 27100\n",
      "GODA loss: -0.87751\n",
      "\n",
      "num of updates: 27200\n",
      "GODA loss: -0.88517\n",
      "\n",
      "num of updates: 27300\n",
      "GODA loss: -0.88615\n",
      "\n",
      "num of updates: 27400\n",
      "GODA loss: -0.88126\n",
      "\n",
      "num of updates: 27500\n",
      "GODA loss: -0.88927\n",
      "\n",
      "num of updates: 27600\n",
      "GODA loss: -0.89236\n",
      "\n",
      "num of updates: 27700\n",
      "GODA loss: -0.88579\n",
      "\n",
      "num of updates: 27800\n",
      "GODA loss: -0.88175\n",
      "\n",
      "num of updates: 27900\n",
      "GODA loss: -0.88003\n",
      "\n",
      "num of updates: 28000\n",
      "GODA loss: -0.87771\n",
      "\n",
      "num of updates: 28100\n",
      "GODA loss: -0.88114\n",
      "\n",
      "num of updates: 28200\n",
      "GODA loss: -0.88882\n",
      "\n",
      "num of updates: 28300\n",
      "GODA loss: -0.89577\n",
      "\n",
      "num of updates: 28400\n",
      "GODA loss: -0.88792\n",
      "\n",
      "num of updates: 28500\n",
      "GODA loss: -0.88366\n",
      "\n",
      "num of updates: 28600\n",
      "GODA loss: -0.88939\n",
      "\n",
      "num of updates: 28700\n",
      "GODA loss: -0.88372\n",
      "\n",
      "num of updates: 28800\n",
      "GODA loss: -0.88250\n",
      "\n",
      "num of updates: 28900\n",
      "GODA loss: -0.88414\n",
      "\n",
      "num of updates: 29000\n",
      "GODA loss: -0.89929\n",
      "\n",
      "num of updates: 29100\n",
      "GODA loss: -0.88505\n",
      "\n",
      "num of updates: 29200\n",
      "GODA loss: -0.88635\n",
      "\n",
      "num of updates: 29300\n",
      "GODA loss: -0.88631\n",
      "\n",
      "num of updates: 29400\n",
      "GODA loss: -0.89290\n",
      "\n",
      "num of updates: 29500\n",
      "GODA loss: -0.89503\n",
      "\n",
      "num of updates: 29600\n",
      "GODA loss: -0.88463\n",
      "\n",
      "num of updates: 29700\n",
      "GODA loss: -0.90040\n",
      "\n",
      "num of updates: 29800\n",
      "GODA loss: -0.89854\n",
      "\n",
      "num of updates: 29900\n",
      "GODA loss: -0.89601\n",
      "\n",
      "num of updates: 30000\n",
      "GODA loss: -0.89361\n",
      "\n",
      "num of updates: 30100\n",
      "GODA loss: -0.89857\n",
      "\n",
      "num of updates: 30200\n",
      "GODA loss: -0.90043\n",
      "\n",
      "num of updates: 30300\n",
      "GODA loss: -0.89503\n",
      "\n",
      "num of updates: 30400\n",
      "GODA loss: -0.90108\n",
      "\n",
      "num of updates: 30500\n",
      "GODA loss: -0.89610\n",
      "\n",
      "num of updates: 30600\n",
      "GODA loss: -0.89692\n",
      "\n",
      "num of updates: 30700\n",
      "GODA loss: -0.90176\n",
      "\n",
      "num of updates: 30800\n",
      "GODA loss: -0.90227\n",
      "\n",
      "num of updates: 30900\n",
      "GODA loss: -0.90268\n",
      "\n",
      "num of updates: 31000\n",
      "GODA loss: -0.90571\n",
      "\n",
      "num of updates: 31100\n",
      "GODA loss: -0.89399\n",
      "\n",
      "num of updates: 31200\n",
      "GODA loss: -0.90446\n",
      "\n",
      "num of updates: 31300\n",
      "GODA loss: -0.90338\n",
      "\n",
      "num of updates: 31400\n",
      "GODA loss: -0.90142\n",
      "\n",
      "num of updates: 31500\n",
      "GODA loss: -0.90434\n",
      "\n",
      "num of updates: 31600\n",
      "GODA loss: -0.90847\n",
      "\n",
      "num of updates: 31700\n",
      "GODA loss: -0.91068\n",
      "\n",
      "num of updates: 31800\n",
      "GODA loss: -0.89845\n",
      "\n",
      "num of updates: 31900\n",
      "GODA loss: -0.90466\n",
      "\n",
      "num of updates: 32000\n",
      "GODA loss: -0.90265\n",
      "\n",
      "num of updates: 32100\n",
      "GODA loss: -0.90377\n",
      "\n",
      "num of updates: 32200\n",
      "GODA loss: -0.90180\n",
      "\n",
      "num of updates: 32300\n",
      "GODA loss: -0.89900\n",
      "\n",
      "num of updates: 32400\n",
      "GODA loss: -0.91132\n",
      "\n",
      "num of updates: 32500\n",
      "GODA loss: -0.89708\n",
      "\n",
      "num of updates: 32600\n",
      "GODA loss: -0.91434\n",
      "\n",
      "num of updates: 32700\n",
      "GODA loss: -0.90714\n",
      "\n",
      "num of updates: 32800\n",
      "GODA loss: -0.90782\n",
      "\n",
      "num of updates: 32900\n",
      "GODA loss: -0.91316\n",
      "\n",
      "num of updates: 33000\n",
      "GODA loss: -0.91583\n",
      "\n",
      "num of updates: 33100\n",
      "GODA loss: -0.91031\n",
      "\n",
      "num of updates: 33200\n",
      "GODA loss: -0.90083\n",
      "\n",
      "num of updates: 33300\n",
      "GODA loss: -0.91909\n",
      "\n",
      "num of updates: 33400\n",
      "GODA loss: -0.91289\n",
      "\n",
      "num of updates: 33500\n",
      "GODA loss: -0.91659\n",
      "\n",
      "num of updates: 33600\n",
      "GODA loss: -0.91589\n",
      "\n",
      "num of updates: 33700\n",
      "GODA loss: -0.91289\n",
      "\n",
      "num of updates: 33800\n",
      "GODA loss: -0.92018\n",
      "\n",
      "num of updates: 33900\n",
      "GODA loss: -0.92327\n",
      "\n",
      "num of updates: 34000\n",
      "GODA loss: -0.91892\n",
      "\n",
      "num of updates: 34100\n",
      "GODA loss: -0.92588\n",
      "\n",
      "num of updates: 34200\n",
      "GODA loss: -0.91867\n",
      "\n",
      "num of updates: 34300\n",
      "GODA loss: -0.91958\n",
      "\n",
      "num of updates: 34400\n",
      "GODA loss: -0.91937\n",
      "\n",
      "num of updates: 34500\n",
      "GODA loss: -0.92826\n",
      "\n",
      "num of updates: 34600\n",
      "GODA loss: -0.92665\n",
      "\n",
      "num of updates: 34700\n",
      "GODA loss: -0.91852\n",
      "\n",
      "num of updates: 34800\n",
      "GODA loss: -0.92280\n",
      "\n",
      "num of updates: 34900\n",
      "GODA loss: -0.93525\n",
      "\n",
      "num of updates: 35000\n",
      "GODA loss: -0.92994\n",
      "\n",
      "num of updates: 35100\n",
      "GODA loss: -0.92699\n",
      "\n",
      "num of updates: 35200\n",
      "GODA loss: -0.91898\n",
      "\n",
      "num of updates: 35300\n",
      "GODA loss: -0.92651\n",
      "\n",
      "num of updates: 35400\n",
      "GODA loss: -0.92014\n",
      "\n",
      "num of updates: 35500\n",
      "GODA loss: -0.92416\n",
      "\n",
      "num of updates: 35600\n",
      "GODA loss: -0.92656\n",
      "\n",
      "num of updates: 35700\n",
      "GODA loss: -0.93705\n",
      "\n",
      "num of updates: 35800\n",
      "GODA loss: -0.92129\n",
      "\n",
      "num of updates: 35900\n",
      "GODA loss: -0.91891\n",
      "\n",
      "num of updates: 36000\n",
      "GODA loss: -0.92905\n",
      "\n",
      "num of updates: 36100\n",
      "GODA loss: -0.93200\n",
      "\n",
      "num of updates: 36200\n",
      "GODA loss: -0.92917\n",
      "\n",
      "num of updates: 36300\n",
      "GODA loss: -0.92289\n",
      "\n",
      "num of updates: 36400\n",
      "GODA loss: -0.92872\n",
      "\n",
      "num of updates: 36500\n",
      "GODA loss: -0.92682\n",
      "\n",
      "num of updates: 36600\n",
      "GODA loss: -0.93389\n",
      "\n",
      "num of updates: 36700\n",
      "GODA loss: -0.93175\n",
      "\n",
      "num of updates: 36800\n",
      "GODA loss: -0.94106\n",
      "\n",
      "num of updates: 36900\n",
      "GODA loss: -0.93900\n",
      "\n",
      "num of updates: 37000\n",
      "GODA loss: -0.93594\n",
      "\n",
      "num of updates: 37100\n",
      "GODA loss: -0.94273\n",
      "\n",
      "num of updates: 37200\n",
      "GODA loss: -0.93557\n",
      "\n",
      "num of updates: 37300\n",
      "GODA loss: -0.92954\n",
      "\n",
      "num of updates: 37400\n",
      "GODA loss: -0.93514\n",
      "\n",
      "num of updates: 37500\n",
      "GODA loss: -0.94030\n",
      "\n",
      "num of updates: 37600\n",
      "GODA loss: -0.93924\n",
      "\n",
      "num of updates: 37700\n",
      "GODA loss: -0.93970\n",
      "\n",
      "num of updates: 37800\n",
      "GODA loss: -0.94176\n",
      "\n",
      "num of updates: 37900\n",
      "GODA loss: -0.93458\n",
      "\n",
      "num of updates: 38000\n",
      "GODA loss: -0.94009\n",
      "\n",
      "num of updates: 38100\n",
      "GODA loss: -0.95316\n",
      "\n",
      "num of updates: 38200\n",
      "GODA loss: -0.94305\n",
      "\n",
      "num of updates: 38300\n",
      "GODA loss: -0.94283\n",
      "\n",
      "num of updates: 38400\n",
      "GODA loss: -0.93924\n",
      "\n",
      "num of updates: 38500\n",
      "GODA loss: -0.93303\n",
      "\n",
      "num of updates: 38600\n",
      "GODA loss: -0.94250\n",
      "\n",
      "num of updates: 38700\n",
      "GODA loss: -0.94999\n",
      "\n",
      "num of updates: 38800\n",
      "GODA loss: -0.94770\n",
      "\n",
      "num of updates: 38900\n",
      "GODA loss: -0.93691\n",
      "\n",
      "num of updates: 39000\n",
      "GODA loss: -0.93198\n",
      "\n",
      "num of updates: 39100\n",
      "GODA loss: -0.94415\n",
      "\n",
      "num of updates: 39200\n",
      "GODA loss: -0.94643\n",
      "\n",
      "num of updates: 39300\n",
      "GODA loss: -0.95185\n",
      "\n",
      "num of updates: 39400\n",
      "GODA loss: -0.94418\n",
      "\n",
      "num of updates: 39500\n",
      "GODA loss: -0.94115\n",
      "\n",
      "num of updates: 39600\n",
      "GODA loss: -0.94346\n",
      "\n",
      "num of updates: 39700\n",
      "GODA loss: -0.95337\n",
      "\n",
      "num of updates: 39800\n",
      "GODA loss: -0.94890\n",
      "\n",
      "num of updates: 39900\n",
      "GODA loss: -0.93479\n",
      "\n",
      "num of updates: 40000\n",
      "GODA loss: -0.94642\n",
      "\n",
      "num of updates: 40100\n",
      "GODA loss: -0.94354\n",
      "\n",
      "num of updates: 40200\n",
      "GODA loss: -0.95627\n",
      "\n",
      "num of updates: 40300\n",
      "GODA loss: -0.95262\n",
      "\n",
      "num of updates: 40400\n",
      "GODA loss: -0.94808\n",
      "\n",
      "num of updates: 40500\n",
      "GODA loss: -0.95041\n",
      "\n",
      "num of updates: 40600\n",
      "GODA loss: -0.94717\n",
      "\n",
      "num of updates: 40700\n",
      "GODA loss: -0.95302\n",
      "\n",
      "num of updates: 40800\n",
      "GODA loss: -0.95458\n",
      "\n",
      "num of updates: 40900\n",
      "GODA loss: -0.95696\n",
      "\n",
      "num of updates: 41000\n",
      "GODA loss: -0.95614\n",
      "\n",
      "num of updates: 41100\n",
      "GODA loss: -0.94643\n",
      "\n",
      "num of updates: 41200\n",
      "GODA loss: -0.95162\n",
      "\n",
      "num of updates: 41300\n",
      "GODA loss: -0.95735\n",
      "\n",
      "num of updates: 41400\n",
      "GODA loss: -0.95048\n",
      "\n",
      "num of updates: 41500\n",
      "GODA loss: -0.95060\n",
      "\n",
      "num of updates: 41600\n",
      "GODA loss: -0.95495\n",
      "\n",
      "num of updates: 41700\n",
      "GODA loss: -0.95247\n",
      "\n",
      "num of updates: 41800\n",
      "GODA loss: -0.96224\n",
      "\n",
      "num of updates: 41900\n",
      "GODA loss: -0.95827\n",
      "\n",
      "num of updates: 42000\n",
      "GODA loss: -0.95649\n",
      "\n",
      "num of updates: 42100\n",
      "GODA loss: -0.96033\n",
      "\n",
      "num of updates: 42200\n",
      "GODA loss: -0.95256\n",
      "\n",
      "num of updates: 42300\n",
      "GODA loss: -0.96043\n",
      "\n",
      "num of updates: 42400\n",
      "GODA loss: -0.96175\n",
      "\n",
      "num of updates: 42500\n",
      "GODA loss: -0.96002\n",
      "\n",
      "num of updates: 42600\n",
      "GODA loss: -0.96227\n",
      "\n",
      "num of updates: 42700\n",
      "GODA loss: -0.95503\n",
      "\n",
      "num of updates: 42800\n",
      "GODA loss: -0.95852\n",
      "\n",
      "num of updates: 42900\n",
      "GODA loss: -0.95231\n",
      "\n",
      "num of updates: 43000\n",
      "GODA loss: -0.95561\n",
      "\n",
      "num of updates: 43100\n",
      "GODA loss: -0.95101\n",
      "\n",
      "num of updates: 43200\n",
      "GODA loss: -0.95499\n",
      "\n",
      "num of updates: 43300\n",
      "GODA loss: -0.96314\n",
      "\n",
      "num of updates: 43400\n",
      "GODA loss: -0.96922\n",
      "\n",
      "num of updates: 43500\n",
      "GODA loss: -0.96035\n",
      "\n",
      "num of updates: 43600\n",
      "GODA loss: -0.96256\n",
      "\n",
      "num of updates: 43700\n",
      "GODA loss: -0.95099\n",
      "\n",
      "num of updates: 43800\n",
      "GODA loss: -0.96273\n",
      "\n",
      "num of updates: 43900\n",
      "GODA loss: -0.95702\n",
      "\n",
      "num of updates: 44000\n",
      "GODA loss: -0.96395\n",
      "\n",
      "num of updates: 44100\n",
      "GODA loss: -0.97332\n",
      "\n",
      "num of updates: 44200\n",
      "GODA loss: -0.96868\n",
      "\n",
      "num of updates: 44300\n",
      "GODA loss: -0.98260\n",
      "\n",
      "num of updates: 44400\n",
      "GODA loss: -0.96098\n",
      "\n",
      "num of updates: 44500\n",
      "GODA loss: -0.96092\n",
      "\n",
      "num of updates: 44600\n",
      "GODA loss: -0.96389\n",
      "\n",
      "num of updates: 44700\n",
      "GODA loss: -0.96714\n",
      "\n",
      "num of updates: 44800\n",
      "GODA loss: -0.97102\n",
      "\n",
      "num of updates: 44900\n",
      "GODA loss: -0.96758\n",
      "\n",
      "num of updates: 45000\n",
      "GODA loss: -0.96498\n",
      "\n",
      "num of updates: 45100\n",
      "GODA loss: -0.96959\n",
      "\n",
      "num of updates: 45200\n",
      "GODA loss: -0.96925\n",
      "\n",
      "num of updates: 45300\n",
      "GODA loss: -0.96919\n",
      "\n",
      "num of updates: 45400\n",
      "GODA loss: -0.97404\n",
      "\n",
      "num of updates: 45500\n",
      "GODA loss: -0.96907\n",
      "\n",
      "num of updates: 45600\n",
      "GODA loss: -0.95547\n",
      "\n",
      "num of updates: 45700\n",
      "GODA loss: -0.97231\n",
      "\n",
      "num of updates: 45800\n",
      "GODA loss: -0.96116\n",
      "\n",
      "num of updates: 45900\n",
      "GODA loss: -0.98101\n",
      "\n",
      "num of updates: 46000\n",
      "GODA loss: -0.97178\n",
      "\n",
      "num of updates: 46100\n",
      "GODA loss: -0.97785\n",
      "\n",
      "num of updates: 46200\n",
      "GODA loss: -0.98327\n",
      "\n",
      "num of updates: 46300\n",
      "GODA loss: -0.98002\n",
      "\n",
      "num of updates: 46400\n",
      "GODA loss: -0.97017\n",
      "\n",
      "num of updates: 46500\n",
      "GODA loss: -0.96813\n",
      "\n",
      "num of updates: 46600\n",
      "GODA loss: -0.97987\n",
      "\n",
      "num of updates: 46700\n",
      "GODA loss: -0.98269\n",
      "\n",
      "num of updates: 46800\n",
      "GODA loss: -0.96549\n",
      "\n",
      "num of updates: 46900\n",
      "GODA loss: -0.97000\n",
      "\n",
      "num of updates: 47000\n",
      "GODA loss: -0.96738\n",
      "\n",
      "num of updates: 47100\n",
      "GODA loss: -0.97416\n",
      "\n",
      "num of updates: 47200\n",
      "GODA loss: -0.97455\n",
      "\n",
      "num of updates: 47300\n",
      "GODA loss: -0.97456\n",
      "\n",
      "num of updates: 47400\n",
      "GODA loss: -0.97159\n",
      "\n",
      "num of updates: 47500\n",
      "GODA loss: -0.98340\n",
      "\n",
      "num of updates: 47600\n",
      "GODA loss: -0.97336\n",
      "\n",
      "num of updates: 47700\n",
      "GODA loss: -0.97519\n",
      "\n",
      "num of updates: 47800\n",
      "GODA loss: -0.98680\n",
      "\n",
      "num of updates: 47900\n",
      "GODA loss: -0.97920\n",
      "\n",
      "num of updates: 48000\n",
      "GODA loss: -0.98468\n",
      "\n",
      "num of updates: 48100\n",
      "GODA loss: -0.97796\n",
      "\n",
      "num of updates: 48200\n",
      "GODA loss: -0.97588\n",
      "\n",
      "num of updates: 48300\n",
      "GODA loss: -0.97364\n",
      "\n",
      "num of updates: 48400\n",
      "GODA loss: -0.96968\n",
      "\n",
      "num of updates: 48500\n",
      "GODA loss: -0.97209\n",
      "\n",
      "num of updates: 48600\n",
      "GODA loss: -0.98086\n",
      "\n",
      "num of updates: 48700\n",
      "GODA loss: -0.98024\n",
      "\n",
      "num of updates: 48800\n",
      "GODA loss: -0.98770\n",
      "\n",
      "num of updates: 48900\n",
      "GODA loss: -0.98706\n",
      "\n",
      "num of updates: 49000\n",
      "GODA loss: -0.98994\n",
      "\n",
      "num of updates: 49100\n",
      "GODA loss: -0.98861\n",
      "\n",
      "num of updates: 49200\n",
      "GODA loss: -0.98124\n",
      "\n",
      "num of updates: 49300\n",
      "GODA loss: -0.97746\n",
      "\n",
      "num of updates: 49400\n",
      "GODA loss: -0.98049\n",
      "\n",
      "num of updates: 49500\n",
      "GODA loss: -0.97450\n",
      "\n",
      "num of updates: 49600\n",
      "GODA loss: -0.97845\n",
      "\n",
      "num of updates: 49700\n",
      "GODA loss: -0.97143\n",
      "\n",
      "num of updates: 49800\n",
      "GODA loss: -0.98071\n",
      "\n",
      "num of updates: 49900\n",
      "GODA loss: -0.97660\n",
      "\n",
      "num of updates: 50000\n",
      "GODA loss: -0.97563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i_iter in range(500):\n",
    "        log_GODA_losses = []\n",
    "        model_guide.train()\n",
    "        if not args.eval:\n",
    "            for _ in range(100):\n",
    "                try:\n",
    "                    states, actions, rewards = next(data_iter)\n",
    "                except StopIteration:\n",
    "                    data_iter = iter(traj_data_loader)\n",
    "                    states, actions, rewards = next(data_iter)\n",
    "\n",
    "                states = states.reshape(64,-1).to(device)          # 正则化\n",
    "                actions = actions.reshape(64,-1).to(device)        # 未正则化\n",
    "                rewards = rewards.reshape(64,-1).to(device)        #  \n",
    "                \n",
    "                #此处需要将三个变量合并起来\n",
    "                feature = torch.cat([states[:,0:int(state_dim*(context_len))],\n",
    "                                     actions[:,0:int(act_dim*(context_len))],\n",
    "                                     rewards[:,0:int((context_len))]],dim=1) #s1a1r1~s5a5r5     #[64,240]                                  #\n",
    "                recon_mu, recon_std, z1_mu, z1_log_std = model_guide.forward(feature)\n",
    "                GODA_loss = model_guide.loss_function(recon_mu, recon_std, feature)\n",
    "\n",
    "                optimizer_guide.zero_grad()\n",
    "                GODA_loss.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model_guide.parameters(), 0.25)\n",
    "                optimizer_guide.step()\n",
    "                scheduler_guide.step()\n",
    "\n",
    "                log_GODA_losses.append(GODA_loss.detach().cpu().item())\n",
    "        mean_GODA_loss = np.mean(log_GODA_losses)\n",
    "        total_updates += num_updates_per_iter\n",
    "        log_str = (\n",
    "            \"num of updates: \" + str(total_updates) + '\\n' +\n",
    "            \"GODA loss: \" +  format(mean_GODA_loss, \".5f\") + '\\n'\n",
    "        )\n",
    "        print(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decode() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m         loss_star\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)                                                                                                               \u001b[39m#\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         scene_optim\u001b[39m.\u001b[39mstep()                                                                                                                                  \u001b[39m#\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     recon_mu,recon_log_std,z1_mu, z1_log_std \u001b[39m=\u001b[39m model_guide\u001b[39m.\u001b[39;49mdecode(z,feature) \n\u001b[1;32m     48\u001b[0m \u001b[39m#替换数据                                                                                                                                                    #\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39m#恢复s1'a1'r1'~s10'a10'r10'                                                                                                              #\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     states \u001b[39m=\u001b[39m recon_mu[:,\u001b[39m0\u001b[39m:\u001b[39mint\u001b[39m(state_dim\u001b[39m*\u001b[39m(context_len))]\u001b[39m.\u001b[39mreshape(\u001b[39m64\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m17\u001b[39m)\u001b[39m.\u001b[39mto(device)                                                                                               \u001b[39m#\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: decode() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from imitation_learning.model import Starloss\n",
    "model_guide.eval()\n",
    "state_mean, state_std,reward_mean,reward_std = traj_star_dataset.get_state_stats()\n",
    "reward_mean = torch.from_numpy(np.array(reward_mean)).to(device)\n",
    "reward_std = torch.from_numpy(np.array(reward_std)).to(device)\n",
    "for i_train_iter in range(max_train_iters):\n",
    "\n",
    "    log_action_losses = []\n",
    "    model.train()\n",
    "\n",
    "    for _ in range(num_updates_per_iter):\n",
    "        try:\n",
    "            timesteps, states, actions, traj_mask, rewards = next(star_iter)\n",
    "        except StopIteration:\n",
    "            star_iter = iter(traj_star_loader)\n",
    "            timesteps, states, actions, traj_mask, rewards = next(star_iter)\n",
    "\n",
    "        timesteps = timesteps.to(device)    # B x T\n",
    "        states = states.to(device)          # 正则化\n",
    "        actions_ori = actions.to(device)        # 未正则化\n",
    "        traj_mask = traj_mask.to(device)    # B x T\n",
    "        action_target = torch.clone(actions).detach().to(device)\n",
    "        #将采样出的数据输入增强网络********************************************************************************************************************************\n",
    "        states = states.reshape(64 ,-1).to(device)          # B x T x state_dim     [64,340]                                                       # \n",
    "        actions = actions.reshape(64 ,-1).to(device) # B x T x act_dim       [64,120]                                                        #\n",
    "        rewards = rewards.reshape(64 ,-1).to(device)        #                       [64,20]                                                        #\n",
    "                                                                                                                                                                \n",
    "        feature = torch.cat([states[:,0:int(state_dim*(context_len))],\n",
    "                                    actions[:,0:int(act_dim*(context_len))],\n",
    "                                    rewards[:,0:int((context_len))]],dim=1) #s1a1r1~s5a5r5     #[64,240]                                                      #\n",
    "        recon_mu, recon_std, z1_mu, z1_log_std = model_guide.forward(feature)\n",
    "        z = z1_mu.clone().detach()                                                                                                                              #\n",
    "        z.requires_grad = True                                                                                                                                  #\n",
    "        scene_optim = torch.optim.Adam([z], lr=lr)                                                                                                              #\n",
    "        loss_star_function = Starloss()                                                                                                                         #\n",
    "        loss =[]                                                                                                                                                #\n",
    "        #找到这64条序列对应的最好的z                                                                                                                              #                \n",
    "        for i in range(200):                                                                                                                                    #\n",
    "            recon_mu,recon_log_std = model_guide.decode(z)                                                                                              #\n",
    "            rewards_ = recon_mu[:,(state_dim+act_dim)*int(context_len):]#rewards: s6'~s10'\n",
    "            rewards_ =  torch.mean(rewards_.reshape(64,10,1)*reward_std + reward_mean)                                                      #\n",
    "            loss_star = loss_star_function.forward(rewards_, z, z1_mu)                                                                           #\n",
    "            loss.append(loss_star.detach().cpu().item())                                                                                                        #\n",
    "            scene_optim.zero_grad()                                                                                                                             #                 \n",
    "            loss_star.backward(retain_graph=True)                                                                                                               #\n",
    "            scene_optim.step()                                                                                                                                  #\n",
    "        recon_mu,recon_log_std = model_guide.decode(z) \n",
    "    #替换数据                                                                                                                                                    #\n",
    "        #恢复s1'a1'r1'~s10'a10'r10'                                                                                                              #\n",
    "        states = recon_mu[:,0:int(state_dim*(context_len))].reshape(64,10,17).to(device)                                                                                               #\n",
    "        actions = recon_mu[:,state_dim*int(context_len):(state_dim+act_dim)*int(context_len)].reshape(64,10,6).to(device)\n",
    "        #********************************************************************************************************************************************************\n",
    "        state_preds, action_preds   = model.forward(\n",
    "                                                        timesteps=timesteps,\n",
    "                                                        states=states,\n",
    "                                                        actions=actions_ori,\n",
    "                                                    )\n",
    "        # only consider non padded elements\n",
    "        action_preds = action_preds.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
    "        action_target = action_target.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
    "\n",
    "        action_loss = F.mse_loss(action_preds, action_target, reduction='mean')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        action_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        log_action_losses.append(action_loss.detach().cpu().item())\n",
    "\n",
    "    # if i_train_iter ==30:\n",
    "    #     state_mean = torch.from_numpy(np.array(state_mean)).to(device)\n",
    "    #     state_std = torch.from_numpy(np.array(state_std)).to(device)\n",
    "    #     s6s10states = feature[:,0:170].reshape(64,10,17)*state_std+state_mean#s6s10\n",
    "    #     s6_s10_states = recon_mu[:,0:170].reshape(64,10,17)*state_std+state_mean#s6'~s10'\n",
    "    #     s6s10states = pd.DataFrame(s6s10states[63,:,:].detach().cpu().numpy())\n",
    "    #     s6_s10_states = pd.DataFrame(s6_s10_states[63,:,:].detach().cpu().numpy())\n",
    "    #     s6s10states.to_csv(\"/home/data_2/why_22/code/GODA/imitation/BC/data/pic/s.csv\")\n",
    "    #     s6_s10_states.to_csv(\"/home/data_2/why_22/code/GODA/imitation/BC/data/pic/s'.csv\")\n",
    "    #     pdb.set_trace()\n",
    "    # evaluate action accuracy\n",
    "    results = evaluate_on_env(model, device, context_len, env,\n",
    "                            num_eval_ep, max_eval_ep_len, state_mean, state_std)\n",
    "\n",
    "    eval_avg_reward = results['eval/avg_reward']\n",
    "    eval_avg_ep_len = results['eval/avg_ep_len']\n",
    "    eval_d4rl_score = get_d4rl_normalized_score(results['eval/avg_reward'], env_name) * 100\n",
    "\n",
    "    mean_action_loss = np.mean(log_action_losses)\n",
    "    time_elapsed = str(datetime.now().replace(microsecond=0) - start_time)\n",
    "\n",
    "    total_updates += num_updates_per_iter\n",
    "\n",
    "    log_str = (\"=\" * 60 + '\\n' +\n",
    "            \"time elapsed: \" + time_elapsed  + '\\n' +\n",
    "            \"num of updates: \" + str(total_updates) + '\\n' +\n",
    "            \"action loss: \" +  format(mean_action_loss, \".5f\") + '\\n' +\n",
    "            \"eval avg reward: \" + format(eval_avg_reward, \".5f\") + '\\n' +\n",
    "            \"eval avg ep len: \" + format(eval_avg_ep_len, \".5f\") + '\\n' +\n",
    "            \"eval d4rl score: \" + format(eval_d4rl_score, \".5f\")\n",
    "        )\n",
    "\n",
    "    print(log_str)\n",
    "\n",
    "    log_data = [time_elapsed, total_updates, mean_action_loss,\n",
    "                eval_avg_reward, eval_avg_ep_len,\n",
    "                eval_d4rl_score]\n",
    "\n",
    "    csv_writer.writerow(log_data)\n",
    "\n",
    "    # save model\n",
    "    print(\"max d4rl score: \" + format(max_d4rl_score, \".5f\"))\n",
    "    if eval_d4rl_score >= max_d4rl_score:\n",
    "        print(\"saving max d4rl score model at: \" + save_best_model_path)\n",
    "        torch.save(model.state_dict(), save_best_model_path)\n",
    "        max_d4rl_score = eval_d4rl_score\n",
    "\n",
    "    print(\"saving current model at: \" + save_model_path)\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"finished training!\")\n",
    "print(\"=\" * 60)\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "time_elapsed = str(end_time - start_time)\n",
    "end_time_str = end_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "print(\"started training at: \" + start_time_str)\n",
    "print(\"finished training at: \" + end_time_str)\n",
    "print(\"total training time: \" + time_elapsed)\n",
    "print(\"max d4rl score: \" + format(max_d4rl_score, \".5f\"))\n",
    "print(\"saved max d4rl score model at: \" + save_best_model_path)\n",
    "print(\"saved last updated model at: \" + save_model_path)\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safe-slac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
