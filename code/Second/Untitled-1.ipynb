{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import safety_gym\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from imitation_learning.utils import Dataset,STARDataset, D4RLTrajectoryDataset, evaluate_on_env, get_d4rl_normalized_score\n",
    "from imitation_learning.model import BCAgent,GuideVAE,Starloss\n",
    "import pdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--env', type=str, default='halfcheetah')\n",
    "parser.add_argument('--dataset', type=str, default='medium')\n",
    "parser.add_argument('--rtg_scale', type=int, default=1000)\n",
    "\n",
    "parser.add_argument('--max_eval_ep_len', type=int, default=1000)\n",
    "parser.add_argument('--num_eval_ep', type=int, default=10)\n",
    "\n",
    "parser.add_argument('--dataset_dir', type=str, default='data/')\n",
    "parser.add_argument('--log_dir', type=str, default='dt_runs/')\n",
    "\n",
    "parser.add_argument('--context_len', type=int, default=10)\n",
    "parser.add_argument('--n_blocks', type=int, default=3)\n",
    "parser.add_argument('--embed_dim', type=int, default=128)\n",
    "parser.add_argument('--n_heads', type=int, default=1)\n",
    "parser.add_argument('--dropout_p', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--wt_decay', type=float, default=1e-4)\n",
    "parser.add_argument('--warmup_steps', type=int, default=10000)\n",
    "\n",
    "parser.add_argument('--max_train_iters', type=int, default=200)\n",
    "parser.add_argument('--num_updates_per_iter', type=int, default=100)\n",
    "\n",
    "parser.add_argument('--device', type=str, default='cuda')\n",
    "\n",
    "parser.add_argument('--seed',type=int, default=0)\n",
    "parser.add_argument('--log_fn',type=str,default='default')\n",
    "parser.add_argument('--eval', action='store_true')\n",
    "parser.add_argument('--load_model_path', type=str,default='')\n",
    "parser.add_argument('--squences_length', type=int, default=10)\n",
    "parser.add_argument('--recovery_length', type=int, default=5)\n",
    "parser.add_argument('--total_episodes', type=int, default=2186)\n",
    "parser.add_argument('--star_batch_size', type=int, default=64)\n",
    "# parser.add_argument('--log_fn',type=str,default='default')\n",
    "parser.add_argument('--feature_size', type=int, default=120)\n",
    "parser.add_argument('--class_size', type=int, default=120)\n",
    "parser.add_argument('--latent_size', type=int, default=64)\n",
    "parser.add_argument('--batch_nums', type=int, default=1000)\n",
    "parser.add_argument('--traj_length', type=int, default=1000)\n",
    "parser.add_argument('--ratio_a', type=int, default=100)\n",
    "parser.add_argument('--ratio_b', type=int, default=1)\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "start time: 23-03-23-19-27-04\n",
      "============================================================\n",
      "device set to: cuda\n",
      "dataset path: data//halfcheetah_medium-v2.pkl\n",
      "model save path: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "log csv save path: dt_runs/dt_halfcheetah_medium-v2_log_23-03-23-19-27-04.csv\n",
      "train:statesmean and statesstd=[-6.8475075e-02  1.4725347e-02 -1.8368107e-01 -2.7612743e-01\n",
      " -3.4158602e-01 -9.3233280e-02 -2.1339475e-01 -8.7635852e-02\n",
      "  5.1738744e+00 -4.2856235e-02 -3.6295928e-02  1.4089356e-01\n",
      "  6.0693521e-02  9.5642865e-02  6.7417443e-02  4.8005907e-03\n",
      "  1.2263178e-02] and [ 0.07467017  0.30077568  0.30200034  0.34436345  0.17599103  0.50729656\n",
      "  0.25660416  0.32957837  1.2546803   0.75977516  1.9806889   6.5655966\n",
      "  7.4680963   4.469275   10.567002    5.672571    7.499262  ]\n",
      "\n",
      "train:actions_mean and statesstd=[-0.32292253 -0.4103281  -0.7357532  -0.12302412 -0.46861967 -0.1577406 ] and [0.80508125 0.67032164 0.54892266 0.68336844 0.6407193  0.71960443]\n",
      "\n",
      "train:rewards_mean and statesstd=4.771085739135742 and 1.2073556648025512\n",
      "\n",
      "==================================================\n",
      "Starting new experiment:  data//halfcheetah_medium-v2.pkl\n",
      "800 trajectories, 800000 timesteps found\n",
      "Average return: 4.77, std: 1.21\n",
      "Max return: 8.33, min: -2.84\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_2/why_22/anaconda3/envs/safe-slac/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "seed = args.seed\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "dataset = args.dataset          # medium / medium-replay / medium-expert\n",
    "\n",
    "# use v3 env for evaluation because\n",
    "# Decision Transformer paper evaluates results on v3 envs\n",
    "\n",
    "if args.env == 'walker2d':\n",
    "    env_name = 'Walker2d-v3'\n",
    "    #rtg_target = 5000\n",
    "    env_d4rl_name = f'walker2d_{dataset}-v2'\n",
    "\n",
    "elif args.env == 'halfcheetah':\n",
    "    env_name = 'HalfCheetah-v3'\n",
    "    #rtg_target = 6000\n",
    "    env_d4rl_name = f'halfcheetah_{dataset}-v2'\n",
    "\n",
    "elif args.env == 'hopper':\n",
    "    env_name = 'Hopper-v3'\n",
    "    #rtg_target = 3600\n",
    "    env_d4rl_name = f'hopper_{dataset}-v2'\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "max_eval_ep_len = args.max_eval_ep_len  # max len of one episode\n",
    "num_eval_ep = args.num_eval_ep          # num of evaluation episodes\n",
    "rtg_scale = args.rtg_scale\n",
    "\n",
    "batch_size = args.batch_size            # training batch size\n",
    "lr = args.lr                            # learning rate\n",
    "wt_decay = args.wt_decay                # weight decay\n",
    "warmup_steps = args.warmup_steps        # warmup steps for lr scheduler\n",
    "\n",
    "# total updates = max_train_iters x num_updates_per_iter\n",
    "max_train_iters = args.max_train_iters\n",
    "num_updates_per_iter = args.num_updates_per_iter\n",
    "ratio_a = args.ratio_a\n",
    "ratio_b = args.ratio_b\n",
    "\n",
    "context_len = args.context_len      # K in decision transformer\n",
    "n_blocks = args.n_blocks            # num of transformer blocks\n",
    "embed_dim = args.embed_dim          # embedding (hidden) dim of transformer\n",
    "n_heads = args.n_heads              # num of transformer heads\n",
    "dropout_p = args.dropout_p          # dropout probability\n",
    "star_batch_size = args.star_batch_size\n",
    "\n",
    "# load data from this file\n",
    "dataset_path = f'{args.dataset_dir}/{env_d4rl_name}.pkl'\n",
    "\n",
    "# saves model and csv in this directory\n",
    "log_dir = args.log_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# training and evaluation device\n",
    "device = torch.device(args.device)\n",
    "\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "start_time_str = start_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "prefix = \"dt_\" + env_d4rl_name\n",
    "\n",
    "save_model_name =  prefix + \"_model_\" + start_time_str + \".pt\"\n",
    "save_model_path = os.path.join(log_dir, save_model_name)\n",
    "save_best_model_path = save_model_path[:-3] + \"_best.pt\"\n",
    "\n",
    "log_csv_name = prefix + \"_log_\" + start_time_str + \".csv\"\n",
    "log_csv_path = os.path.join(log_dir, log_csv_name)\n",
    "\n",
    "csv_writer = csv.writer(open(log_csv_path, 'a', 1))\n",
    "csv_header = ([\"duration\", \"num_updates\", \"action_loss\",\n",
    "                \"eval_avg_reward\", \"eval_avg_ep_len\", \"eval_d4rl_score\"])\n",
    "\n",
    "csv_writer.writerow(csv_header)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"start time: \" + start_time_str)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"device set to: \" + str(device))\n",
    "print(\"dataset path: \" + dataset_path)\n",
    "print(\"model save path: \" + save_model_path)\n",
    "print(\"log csv save path: \" + log_csv_path)\n",
    "\n",
    "traj_dataset = Dataset(dataset_path, args.context_len,False)\n",
    "traj_star_dataset = D4RLTrajectoryDataset(dataset_path, context_len)\n",
    "\n",
    "traj_star_loader = DataLoader(\n",
    "                    traj_star_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=True\n",
    "                )\n",
    "traj_data_loader = DataLoader(\n",
    "                        traj_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True,\n",
    "                        drop_last=True\n",
    "                    )\n",
    "\n",
    "data_iter = iter(traj_data_loader)\n",
    "star_iter = iter(traj_star_loader)\n",
    "\n",
    "## get state stats from dataset\n",
    "state_mean, state_std ,reward_mean,reward_std = traj_star_dataset.get_state_stats()\n",
    "reward_mean = torch.from_numpy(np.array(reward_mean)).to(device)\n",
    "reward_std = torch.from_numpy(np.array(reward_std)).to(device)\n",
    "\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "model_guide = GuideVAE(args.feature_size, args.class_size, args.latent_size).to(device)\n",
    "model = BCAgent(\n",
    "            state_dim=state_dim,\n",
    "            act_dim=act_dim,\n",
    "            n_blocks=n_blocks,\n",
    "            h_dim=embed_dim,\n",
    "            context_len=context_len,\n",
    "            n_heads=n_heads,\n",
    "            drop_p=dropout_p,\n",
    "        ).to(device)\n",
    "\n",
    "optimizer_guide = torch.optim.AdamW( \n",
    "                        model_guide.parameters(),\n",
    "                        lr=lr,\n",
    "                        weight_decay=wt_decay\n",
    "                    )\n",
    "optimizer = torch.optim.AdamW(\n",
    "                    model.parameters(),\n",
    "                    lr=lr,\n",
    "                    weight_decay=wt_decay\n",
    "                )\n",
    "\n",
    "scheduler_guide = torch.optim.lr_scheduler.LambdaLR(\n",
    "                        optimizer_guide,\n",
    "                        lambda steps: min((steps+1)/warmup_steps, 1)\n",
    "                )\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "                        optimizer,\n",
    "                        lambda steps: min((steps+1)/warmup_steps, 1)\n",
    "                    )\n",
    "\n",
    "max_d4rl_score = -1.0\n",
    "total_updates = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of updates: 100\n",
      "GODA loss: 1.70667\n",
      "\n",
      "num of updates: 200\n",
      "GODA loss: 1.66806\n",
      "\n",
      "num of updates: 300\n",
      "GODA loss: 1.66792\n",
      "\n",
      "num of updates: 400\n",
      "GODA loss: 1.60038\n",
      "\n",
      "num of updates: 500\n",
      "GODA loss: 1.55275\n",
      "\n",
      "num of updates: 600\n",
      "GODA loss: 1.50771\n",
      "\n",
      "num of updates: 700\n",
      "GODA loss: 1.46302\n",
      "\n",
      "num of updates: 800\n",
      "GODA loss: 1.40118\n",
      "\n",
      "num of updates: 900\n",
      "GODA loss: 1.31922\n",
      "\n",
      "num of updates: 1000\n",
      "GODA loss: 1.23680\n",
      "\n",
      "num of updates: 1100\n",
      "GODA loss: 1.14650\n",
      "\n",
      "num of updates: 1200\n",
      "GODA loss: 1.04169\n",
      "\n",
      "num of updates: 1300\n",
      "GODA loss: 0.95276\n",
      "\n",
      "num of updates: 1400\n",
      "GODA loss: 0.88355\n",
      "\n",
      "num of updates: 1500\n",
      "GODA loss: 0.82907\n",
      "\n",
      "num of updates: 1600\n",
      "GODA loss: 0.76977\n",
      "\n",
      "num of updates: 1700\n",
      "GODA loss: 0.71855\n",
      "\n",
      "num of updates: 1800\n",
      "GODA loss: 0.66975\n",
      "\n",
      "num of updates: 1900\n",
      "GODA loss: 0.62810\n",
      "\n",
      "num of updates: 2000\n",
      "GODA loss: 0.58725\n",
      "\n",
      "num of updates: 2100\n",
      "GODA loss: 0.54841\n",
      "\n",
      "num of updates: 2200\n",
      "GODA loss: 0.50730\n",
      "\n",
      "num of updates: 2300\n",
      "GODA loss: 0.47690\n",
      "\n",
      "num of updates: 2400\n",
      "GODA loss: 0.44766\n",
      "\n",
      "num of updates: 2500\n",
      "GODA loss: 0.41622\n",
      "\n",
      "num of updates: 2600\n",
      "GODA loss: 0.38454\n",
      "\n",
      "num of updates: 2700\n",
      "GODA loss: 0.35613\n",
      "\n",
      "num of updates: 2800\n",
      "GODA loss: 0.32430\n",
      "\n",
      "num of updates: 2900\n",
      "GODA loss: 0.29500\n",
      "\n",
      "num of updates: 3000\n",
      "GODA loss: 0.26862\n",
      "\n",
      "num of updates: 3100\n",
      "GODA loss: 0.23772\n",
      "\n",
      "num of updates: 3200\n",
      "GODA loss: 0.21768\n",
      "\n",
      "num of updates: 3300\n",
      "GODA loss: 0.19971\n",
      "\n",
      "num of updates: 3400\n",
      "GODA loss: 0.16308\n",
      "\n",
      "num of updates: 3500\n",
      "GODA loss: 0.13358\n",
      "\n",
      "num of updates: 3600\n",
      "GODA loss: 0.10820\n",
      "\n",
      "num of updates: 3700\n",
      "GODA loss: 0.07909\n",
      "\n",
      "num of updates: 3800\n",
      "GODA loss: 0.04475\n",
      "\n",
      "num of updates: 3900\n",
      "GODA loss: 0.02424\n",
      "\n",
      "num of updates: 4000\n",
      "GODA loss: -0.00338\n",
      "\n",
      "num of updates: 4100\n",
      "GODA loss: -0.02794\n",
      "\n",
      "num of updates: 4200\n",
      "GODA loss: -0.04850\n",
      "\n",
      "num of updates: 4300\n",
      "GODA loss: -0.07823\n",
      "\n",
      "num of updates: 4400\n",
      "GODA loss: -0.09763\n",
      "\n",
      "num of updates: 4500\n",
      "GODA loss: -0.12544\n",
      "\n",
      "num of updates: 4600\n",
      "GODA loss: -0.15203\n",
      "\n",
      "num of updates: 4700\n",
      "GODA loss: -0.17178\n",
      "\n",
      "num of updates: 4800\n",
      "GODA loss: -0.19727\n",
      "\n",
      "num of updates: 4900\n",
      "GODA loss: -0.21216\n",
      "\n",
      "num of updates: 5000\n",
      "GODA loss: -0.23850\n",
      "\n",
      "num of updates: 5100\n",
      "GODA loss: -0.26619\n",
      "\n",
      "num of updates: 5200\n",
      "GODA loss: -0.27493\n",
      "\n",
      "num of updates: 5300\n",
      "GODA loss: -0.29741\n",
      "\n",
      "num of updates: 5400\n",
      "GODA loss: -0.31820\n",
      "\n",
      "num of updates: 5500\n",
      "GODA loss: -0.33546\n",
      "\n",
      "num of updates: 5600\n",
      "GODA loss: -0.35154\n",
      "\n",
      "num of updates: 5700\n",
      "GODA loss: -0.36856\n",
      "\n",
      "num of updates: 5800\n",
      "GODA loss: -0.37402\n",
      "\n",
      "num of updates: 5900\n",
      "GODA loss: -0.39955\n",
      "\n",
      "num of updates: 6000\n",
      "GODA loss: -0.40597\n",
      "\n",
      "num of updates: 6100\n",
      "GODA loss: -0.42353\n",
      "\n",
      "num of updates: 6200\n",
      "GODA loss: -0.43422\n",
      "\n",
      "num of updates: 6300\n",
      "GODA loss: -0.43943\n",
      "\n",
      "num of updates: 6400\n",
      "GODA loss: -0.45959\n",
      "\n",
      "num of updates: 6500\n",
      "GODA loss: -0.46727\n",
      "\n",
      "num of updates: 6600\n",
      "GODA loss: -0.49198\n",
      "\n",
      "num of updates: 6700\n",
      "GODA loss: -0.49313\n",
      "\n",
      "num of updates: 6800\n",
      "GODA loss: -0.49792\n",
      "\n",
      "num of updates: 6900\n",
      "GODA loss: -0.51266\n",
      "\n",
      "num of updates: 7000\n",
      "GODA loss: -0.52393\n",
      "\n",
      "num of updates: 7100\n",
      "GODA loss: -0.53006\n",
      "\n",
      "num of updates: 7200\n",
      "GODA loss: -0.54052\n",
      "\n",
      "num of updates: 7300\n",
      "GODA loss: -0.55403\n",
      "\n",
      "num of updates: 7400\n",
      "GODA loss: -0.56272\n",
      "\n",
      "num of updates: 7500\n",
      "GODA loss: -0.57864\n",
      "\n",
      "num of updates: 7600\n",
      "GODA loss: -0.58105\n",
      "\n",
      "num of updates: 7700\n",
      "GODA loss: -0.58683\n",
      "\n",
      "num of updates: 7800\n",
      "GODA loss: -0.60214\n",
      "\n",
      "num of updates: 7900\n",
      "GODA loss: -0.60233\n",
      "\n",
      "num of updates: 8000\n",
      "GODA loss: -0.61120\n",
      "\n",
      "num of updates: 8100\n",
      "GODA loss: -0.61496\n",
      "\n",
      "num of updates: 8200\n",
      "GODA loss: -0.62685\n",
      "\n",
      "num of updates: 8300\n",
      "GODA loss: -0.63957\n",
      "\n",
      "num of updates: 8400\n",
      "GODA loss: -0.64505\n",
      "\n",
      "num of updates: 8500\n",
      "GODA loss: -0.65387\n",
      "\n",
      "num of updates: 8600\n",
      "GODA loss: -0.65408\n",
      "\n",
      "num of updates: 8700\n",
      "GODA loss: -0.66104\n",
      "\n",
      "num of updates: 8800\n",
      "GODA loss: -0.65910\n",
      "\n",
      "num of updates: 8900\n",
      "GODA loss: -0.67036\n",
      "\n",
      "num of updates: 9000\n",
      "GODA loss: -0.68231\n",
      "\n",
      "num of updates: 9100\n",
      "GODA loss: -0.67729\n",
      "\n",
      "num of updates: 9200\n",
      "GODA loss: -0.68404\n",
      "\n",
      "num of updates: 9300\n",
      "GODA loss: -0.68343\n",
      "\n",
      "num of updates: 9400\n",
      "GODA loss: -0.68660\n",
      "\n",
      "num of updates: 9500\n",
      "GODA loss: -0.69514\n",
      "\n",
      "num of updates: 9600\n",
      "GODA loss: -0.69929\n",
      "\n",
      "num of updates: 9700\n",
      "GODA loss: -0.69890\n",
      "\n",
      "num of updates: 9800\n",
      "GODA loss: -0.70188\n",
      "\n",
      "num of updates: 9900\n",
      "GODA loss: -0.70963\n",
      "\n",
      "num of updates: 10000\n",
      "GODA loss: -0.70405\n",
      "\n",
      "num of updates: 10100\n",
      "GODA loss: -0.71223\n",
      "\n",
      "num of updates: 10200\n",
      "GODA loss: -0.71553\n",
      "\n",
      "num of updates: 10300\n",
      "GODA loss: -0.71664\n",
      "\n",
      "num of updates: 10400\n",
      "GODA loss: -0.72679\n",
      "\n",
      "num of updates: 10500\n",
      "GODA loss: -0.72291\n",
      "\n",
      "num of updates: 10600\n",
      "GODA loss: -0.72762\n",
      "\n",
      "num of updates: 10700\n",
      "GODA loss: -0.71928\n",
      "\n",
      "num of updates: 10800\n",
      "GODA loss: -0.73137\n",
      "\n",
      "num of updates: 10900\n",
      "GODA loss: -0.74145\n",
      "\n",
      "num of updates: 11000\n",
      "GODA loss: -0.74083\n",
      "\n",
      "num of updates: 11100\n",
      "GODA loss: -0.73055\n",
      "\n",
      "num of updates: 11200\n",
      "GODA loss: -0.74026\n",
      "\n",
      "num of updates: 11300\n",
      "GODA loss: -0.73550\n",
      "\n",
      "num of updates: 11400\n",
      "GODA loss: -0.74200\n",
      "\n",
      "num of updates: 11500\n",
      "GODA loss: -0.74501\n",
      "\n",
      "num of updates: 11600\n",
      "GODA loss: -0.74703\n",
      "\n",
      "num of updates: 11700\n",
      "GODA loss: -0.74408\n",
      "\n",
      "num of updates: 11800\n",
      "GODA loss: -0.75457\n",
      "\n",
      "num of updates: 11900\n",
      "GODA loss: -0.75464\n",
      "\n",
      "num of updates: 12000\n",
      "GODA loss: -0.75049\n",
      "\n",
      "num of updates: 12100\n",
      "GODA loss: -0.76083\n",
      "\n",
      "num of updates: 12200\n",
      "GODA loss: -0.75518\n",
      "\n",
      "num of updates: 12300\n",
      "GODA loss: -0.75750\n",
      "\n",
      "num of updates: 12400\n",
      "GODA loss: -0.75594\n",
      "\n",
      "num of updates: 12500\n",
      "GODA loss: -0.76130\n",
      "\n",
      "num of updates: 12600\n",
      "GODA loss: -0.76740\n",
      "\n",
      "num of updates: 12700\n",
      "GODA loss: -0.76444\n",
      "\n",
      "num of updates: 12800\n",
      "GODA loss: -0.75894\n",
      "\n",
      "num of updates: 12900\n",
      "GODA loss: -0.76536\n",
      "\n",
      "num of updates: 13000\n",
      "GODA loss: -0.77032\n",
      "\n",
      "num of updates: 13100\n",
      "GODA loss: -0.77300\n",
      "\n",
      "num of updates: 13200\n",
      "GODA loss: -0.76776\n",
      "\n",
      "num of updates: 13300\n",
      "GODA loss: -0.77070\n",
      "\n",
      "num of updates: 13400\n",
      "GODA loss: -0.77466\n",
      "\n",
      "num of updates: 13500\n",
      "GODA loss: -0.77573\n",
      "\n",
      "num of updates: 13600\n",
      "GODA loss: -0.77815\n",
      "\n",
      "num of updates: 13700\n",
      "GODA loss: -0.77618\n",
      "\n",
      "num of updates: 13800\n",
      "GODA loss: -0.77646\n",
      "\n",
      "num of updates: 13900\n",
      "GODA loss: -0.77981\n",
      "\n",
      "num of updates: 14000\n",
      "GODA loss: -0.77918\n",
      "\n",
      "num of updates: 14100\n",
      "GODA loss: -0.78744\n",
      "\n",
      "num of updates: 14200\n",
      "GODA loss: -0.77994\n",
      "\n",
      "num of updates: 14300\n",
      "GODA loss: -0.78127\n",
      "\n",
      "num of updates: 14400\n",
      "GODA loss: -0.78527\n",
      "\n",
      "num of updates: 14500\n",
      "GODA loss: -0.78794\n",
      "\n",
      "num of updates: 14600\n",
      "GODA loss: -0.79038\n",
      "\n",
      "num of updates: 14700\n",
      "GODA loss: -0.79019\n",
      "\n",
      "num of updates: 14800\n",
      "GODA loss: -0.79698\n",
      "\n",
      "num of updates: 14900\n",
      "GODA loss: -0.79171\n",
      "\n",
      "num of updates: 15000\n",
      "GODA loss: -0.79126\n",
      "\n",
      "num of updates: 15100\n",
      "GODA loss: -0.79531\n",
      "\n",
      "num of updates: 15200\n",
      "GODA loss: -0.79148\n",
      "\n",
      "num of updates: 15300\n",
      "GODA loss: -0.79087\n",
      "\n",
      "num of updates: 15400\n",
      "GODA loss: -0.80038\n",
      "\n",
      "num of updates: 15500\n",
      "GODA loss: -0.79290\n",
      "\n",
      "num of updates: 15600\n",
      "GODA loss: -0.79293\n",
      "\n",
      "num of updates: 15700\n",
      "GODA loss: -0.80315\n",
      "\n",
      "num of updates: 15800\n",
      "GODA loss: -0.80291\n",
      "\n",
      "num of updates: 15900\n",
      "GODA loss: -0.80074\n",
      "\n",
      "num of updates: 16000\n",
      "GODA loss: -0.79952\n",
      "\n",
      "num of updates: 16100\n",
      "GODA loss: -0.81109\n",
      "\n",
      "num of updates: 16200\n",
      "GODA loss: -0.80536\n",
      "\n",
      "num of updates: 16300\n",
      "GODA loss: -0.80236\n",
      "\n",
      "num of updates: 16400\n",
      "GODA loss: -0.80189\n",
      "\n",
      "num of updates: 16500\n",
      "GODA loss: -0.80889\n",
      "\n",
      "num of updates: 16600\n",
      "GODA loss: -0.79984\n",
      "\n",
      "num of updates: 16700\n",
      "GODA loss: -0.80055\n",
      "\n",
      "num of updates: 16800\n",
      "GODA loss: -0.80304\n",
      "\n",
      "num of updates: 16900\n",
      "GODA loss: -0.81794\n",
      "\n",
      "num of updates: 17000\n",
      "GODA loss: -0.82134\n",
      "\n",
      "num of updates: 17100\n",
      "GODA loss: -0.80204\n",
      "\n",
      "num of updates: 17200\n",
      "GODA loss: -0.81433\n",
      "\n",
      "num of updates: 17300\n",
      "GODA loss: -0.81159\n",
      "\n",
      "num of updates: 17400\n",
      "GODA loss: -0.80432\n",
      "\n",
      "num of updates: 17500\n",
      "GODA loss: -0.81534\n",
      "\n",
      "num of updates: 17600\n",
      "GODA loss: -0.80496\n",
      "\n",
      "num of updates: 17700\n",
      "GODA loss: -0.81586\n",
      "\n",
      "num of updates: 17800\n",
      "GODA loss: -0.81754\n",
      "\n",
      "num of updates: 17900\n",
      "GODA loss: -0.81870\n",
      "\n",
      "num of updates: 18000\n",
      "GODA loss: -0.81142\n",
      "\n",
      "num of updates: 18100\n",
      "GODA loss: -0.81836\n",
      "\n",
      "num of updates: 18200\n",
      "GODA loss: -0.82033\n",
      "\n",
      "num of updates: 18300\n",
      "GODA loss: -0.81639\n",
      "\n",
      "num of updates: 18400\n",
      "GODA loss: -0.82242\n",
      "\n",
      "num of updates: 18500\n",
      "GODA loss: -0.82304\n",
      "\n",
      "num of updates: 18600\n",
      "GODA loss: -0.82169\n",
      "\n",
      "num of updates: 18700\n",
      "GODA loss: -0.81860\n",
      "\n",
      "num of updates: 18800\n",
      "GODA loss: -0.82525\n",
      "\n",
      "num of updates: 18900\n",
      "GODA loss: -0.82037\n",
      "\n",
      "num of updates: 19000\n",
      "GODA loss: -0.82800\n",
      "\n",
      "num of updates: 19100\n",
      "GODA loss: -0.82617\n",
      "\n",
      "num of updates: 19200\n",
      "GODA loss: -0.81970\n",
      "\n",
      "num of updates: 19300\n",
      "GODA loss: -0.82564\n",
      "\n",
      "num of updates: 19400\n",
      "GODA loss: -0.82749\n",
      "\n",
      "num of updates: 19500\n",
      "GODA loss: -0.82770\n",
      "\n",
      "num of updates: 19600\n",
      "GODA loss: -0.83357\n",
      "\n",
      "num of updates: 19700\n",
      "GODA loss: -0.82881\n",
      "\n",
      "num of updates: 19800\n",
      "GODA loss: -0.83061\n",
      "\n",
      "num of updates: 19900\n",
      "GODA loss: -0.83353\n",
      "\n",
      "num of updates: 20000\n",
      "GODA loss: -0.83801\n",
      "\n",
      "num of updates: 20100\n",
      "GODA loss: -0.83711\n",
      "\n",
      "num of updates: 20200\n",
      "GODA loss: -0.83270\n",
      "\n",
      "num of updates: 20300\n",
      "GODA loss: -0.83733\n",
      "\n",
      "num of updates: 20400\n",
      "GODA loss: -0.84090\n",
      "\n",
      "num of updates: 20500\n",
      "GODA loss: -0.83732\n",
      "\n",
      "num of updates: 20600\n",
      "GODA loss: -0.83138\n",
      "\n",
      "num of updates: 20700\n",
      "GODA loss: -0.83576\n",
      "\n",
      "num of updates: 20800\n",
      "GODA loss: -0.84301\n",
      "\n",
      "num of updates: 20900\n",
      "GODA loss: -0.84307\n",
      "\n",
      "num of updates: 21000\n",
      "GODA loss: -0.84553\n",
      "\n",
      "num of updates: 21100\n",
      "GODA loss: -0.84429\n",
      "\n",
      "num of updates: 21200\n",
      "GODA loss: -0.83774\n",
      "\n",
      "num of updates: 21300\n",
      "GODA loss: -0.84070\n",
      "\n",
      "num of updates: 21400\n",
      "GODA loss: -0.83683\n",
      "\n",
      "num of updates: 21500\n",
      "GODA loss: -0.84267\n",
      "\n",
      "num of updates: 21600\n",
      "GODA loss: -0.84092\n",
      "\n",
      "num of updates: 21700\n",
      "GODA loss: -0.85251\n",
      "\n",
      "num of updates: 21800\n",
      "GODA loss: -0.84284\n",
      "\n",
      "num of updates: 21900\n",
      "GODA loss: -0.85403\n",
      "\n",
      "num of updates: 22000\n",
      "GODA loss: -0.84603\n",
      "\n",
      "num of updates: 22100\n",
      "GODA loss: -0.84167\n",
      "\n",
      "num of updates: 22200\n",
      "GODA loss: -0.84973\n",
      "\n",
      "num of updates: 22300\n",
      "GODA loss: -0.85204\n",
      "\n",
      "num of updates: 22400\n",
      "GODA loss: -0.84687\n",
      "\n",
      "num of updates: 22500\n",
      "GODA loss: -0.85246\n",
      "\n",
      "num of updates: 22600\n",
      "GODA loss: -0.85136\n",
      "\n",
      "num of updates: 22700\n",
      "GODA loss: -0.84869\n",
      "\n",
      "num of updates: 22800\n",
      "GODA loss: -0.85390\n",
      "\n",
      "num of updates: 22900\n",
      "GODA loss: -0.85886\n",
      "\n",
      "num of updates: 23000\n",
      "GODA loss: -0.85278\n",
      "\n",
      "num of updates: 23100\n",
      "GODA loss: -0.85341\n",
      "\n",
      "num of updates: 23200\n",
      "GODA loss: -0.84928\n",
      "\n",
      "num of updates: 23300\n",
      "GODA loss: -0.86386\n",
      "\n",
      "num of updates: 23400\n",
      "GODA loss: -0.85801\n",
      "\n",
      "num of updates: 23500\n",
      "GODA loss: -0.85529\n",
      "\n",
      "num of updates: 23600\n",
      "GODA loss: -0.86552\n",
      "\n",
      "num of updates: 23700\n",
      "GODA loss: -0.85558\n",
      "\n",
      "num of updates: 23800\n",
      "GODA loss: -0.85875\n",
      "\n",
      "num of updates: 23900\n",
      "GODA loss: -0.86229\n",
      "\n",
      "num of updates: 24000\n",
      "GODA loss: -0.85973\n",
      "\n",
      "num of updates: 24100\n",
      "GODA loss: -0.86414\n",
      "\n",
      "num of updates: 24200\n",
      "GODA loss: -0.86608\n",
      "\n",
      "num of updates: 24300\n",
      "GODA loss: -0.86288\n",
      "\n",
      "num of updates: 24400\n",
      "GODA loss: -0.86413\n",
      "\n",
      "num of updates: 24500\n",
      "GODA loss: -0.86475\n",
      "\n",
      "num of updates: 24600\n",
      "GODA loss: -0.86133\n",
      "\n",
      "num of updates: 24700\n",
      "GODA loss: -0.86221\n",
      "\n",
      "num of updates: 24800\n",
      "GODA loss: -0.86771\n",
      "\n",
      "num of updates: 24900\n",
      "GODA loss: -0.86515\n",
      "\n",
      "num of updates: 25000\n",
      "GODA loss: -0.86393\n",
      "\n",
      "num of updates: 25100\n",
      "GODA loss: -0.86556\n",
      "\n",
      "num of updates: 25200\n",
      "GODA loss: -0.86883\n",
      "\n",
      "num of updates: 25300\n",
      "GODA loss: -0.87510\n",
      "\n",
      "num of updates: 25400\n",
      "GODA loss: -0.87328\n",
      "\n",
      "num of updates: 25500\n",
      "GODA loss: -0.86776\n",
      "\n",
      "num of updates: 25600\n",
      "GODA loss: -0.87315\n",
      "\n",
      "num of updates: 25700\n",
      "GODA loss: -0.85982\n",
      "\n",
      "num of updates: 25800\n",
      "GODA loss: -0.87326\n",
      "\n",
      "num of updates: 25900\n",
      "GODA loss: -0.87381\n",
      "\n",
      "num of updates: 26000\n",
      "GODA loss: -0.87350\n",
      "\n",
      "num of updates: 26100\n",
      "GODA loss: -0.86705\n",
      "\n",
      "num of updates: 26200\n",
      "GODA loss: -0.88190\n",
      "\n",
      "num of updates: 26300\n",
      "GODA loss: -0.87442\n",
      "\n",
      "num of updates: 26400\n",
      "GODA loss: -0.86958\n",
      "\n",
      "num of updates: 26500\n",
      "GODA loss: -0.87602\n",
      "\n",
      "num of updates: 26600\n",
      "GODA loss: -0.87329\n",
      "\n",
      "num of updates: 26700\n",
      "GODA loss: -0.87742\n",
      "\n",
      "num of updates: 26800\n",
      "GODA loss: -0.88176\n",
      "\n",
      "num of updates: 26900\n",
      "GODA loss: -0.88081\n",
      "\n",
      "num of updates: 27000\n",
      "GODA loss: -0.88395\n",
      "\n",
      "num of updates: 27100\n",
      "GODA loss: -0.87751\n",
      "\n",
      "num of updates: 27200\n",
      "GODA loss: -0.88517\n",
      "\n",
      "num of updates: 27300\n",
      "GODA loss: -0.88615\n",
      "\n",
      "num of updates: 27400\n",
      "GODA loss: -0.88126\n",
      "\n",
      "num of updates: 27500\n",
      "GODA loss: -0.88927\n",
      "\n",
      "num of updates: 27600\n",
      "GODA loss: -0.89236\n",
      "\n",
      "num of updates: 27700\n",
      "GODA loss: -0.88579\n",
      "\n",
      "num of updates: 27800\n",
      "GODA loss: -0.88175\n",
      "\n",
      "num of updates: 27900\n",
      "GODA loss: -0.88003\n",
      "\n",
      "num of updates: 28000\n",
      "GODA loss: -0.87771\n",
      "\n",
      "num of updates: 28100\n",
      "GODA loss: -0.88114\n",
      "\n",
      "num of updates: 28200\n",
      "GODA loss: -0.88882\n",
      "\n",
      "num of updates: 28300\n",
      "GODA loss: -0.89577\n",
      "\n",
      "num of updates: 28400\n",
      "GODA loss: -0.88792\n",
      "\n",
      "num of updates: 28500\n",
      "GODA loss: -0.88366\n",
      "\n",
      "num of updates: 28600\n",
      "GODA loss: -0.88939\n",
      "\n",
      "num of updates: 28700\n",
      "GODA loss: -0.88372\n",
      "\n",
      "num of updates: 28800\n",
      "GODA loss: -0.88250\n",
      "\n",
      "num of updates: 28900\n",
      "GODA loss: -0.88414\n",
      "\n",
      "num of updates: 29000\n",
      "GODA loss: -0.89929\n",
      "\n",
      "num of updates: 29100\n",
      "GODA loss: -0.88505\n",
      "\n",
      "num of updates: 29200\n",
      "GODA loss: -0.88635\n",
      "\n",
      "num of updates: 29300\n",
      "GODA loss: -0.88631\n",
      "\n",
      "num of updates: 29400\n",
      "GODA loss: -0.89290\n",
      "\n",
      "num of updates: 29500\n",
      "GODA loss: -0.89503\n",
      "\n",
      "num of updates: 29600\n",
      "GODA loss: -0.88463\n",
      "\n",
      "num of updates: 29700\n",
      "GODA loss: -0.90040\n",
      "\n",
      "num of updates: 29800\n",
      "GODA loss: -0.89854\n",
      "\n",
      "num of updates: 29900\n",
      "GODA loss: -0.89601\n",
      "\n",
      "num of updates: 30000\n",
      "GODA loss: -0.89361\n",
      "\n",
      "num of updates: 30100\n",
      "GODA loss: -0.89857\n",
      "\n",
      "num of updates: 30200\n",
      "GODA loss: -0.90043\n",
      "\n",
      "num of updates: 30300\n",
      "GODA loss: -0.89503\n",
      "\n",
      "num of updates: 30400\n",
      "GODA loss: -0.90108\n",
      "\n",
      "num of updates: 30500\n",
      "GODA loss: -0.89610\n",
      "\n",
      "num of updates: 30600\n",
      "GODA loss: -0.89692\n",
      "\n",
      "num of updates: 30700\n",
      "GODA loss: -0.90176\n",
      "\n",
      "num of updates: 30800\n",
      "GODA loss: -0.90227\n",
      "\n",
      "num of updates: 30900\n",
      "GODA loss: -0.90268\n",
      "\n",
      "num of updates: 31000\n",
      "GODA loss: -0.90571\n",
      "\n",
      "num of updates: 31100\n",
      "GODA loss: -0.89399\n",
      "\n",
      "num of updates: 31200\n",
      "GODA loss: -0.90446\n",
      "\n",
      "num of updates: 31300\n",
      "GODA loss: -0.90338\n",
      "\n",
      "num of updates: 31400\n",
      "GODA loss: -0.90142\n",
      "\n",
      "num of updates: 31500\n",
      "GODA loss: -0.90434\n",
      "\n",
      "num of updates: 31600\n",
      "GODA loss: -0.90847\n",
      "\n",
      "num of updates: 31700\n",
      "GODA loss: -0.91068\n",
      "\n",
      "num of updates: 31800\n",
      "GODA loss: -0.89845\n",
      "\n",
      "num of updates: 31900\n",
      "GODA loss: -0.90466\n",
      "\n",
      "num of updates: 32000\n",
      "GODA loss: -0.90265\n",
      "\n",
      "num of updates: 32100\n",
      "GODA loss: -0.90377\n",
      "\n",
      "num of updates: 32200\n",
      "GODA loss: -0.90180\n",
      "\n",
      "num of updates: 32300\n",
      "GODA loss: -0.89900\n",
      "\n",
      "num of updates: 32400\n",
      "GODA loss: -0.91132\n",
      "\n",
      "num of updates: 32500\n",
      "GODA loss: -0.89708\n",
      "\n",
      "num of updates: 32600\n",
      "GODA loss: -0.91434\n",
      "\n",
      "num of updates: 32700\n",
      "GODA loss: -0.90714\n",
      "\n",
      "num of updates: 32800\n",
      "GODA loss: -0.90782\n",
      "\n",
      "num of updates: 32900\n",
      "GODA loss: -0.91316\n",
      "\n",
      "num of updates: 33000\n",
      "GODA loss: -0.91583\n",
      "\n",
      "num of updates: 33100\n",
      "GODA loss: -0.91031\n",
      "\n",
      "num of updates: 33200\n",
      "GODA loss: -0.90083\n",
      "\n",
      "num of updates: 33300\n",
      "GODA loss: -0.91909\n",
      "\n",
      "num of updates: 33400\n",
      "GODA loss: -0.91289\n",
      "\n",
      "num of updates: 33500\n",
      "GODA loss: -0.91659\n",
      "\n",
      "num of updates: 33600\n",
      "GODA loss: -0.91589\n",
      "\n",
      "num of updates: 33700\n",
      "GODA loss: -0.91289\n",
      "\n",
      "num of updates: 33800\n",
      "GODA loss: -0.92018\n",
      "\n",
      "num of updates: 33900\n",
      "GODA loss: -0.92327\n",
      "\n",
      "num of updates: 34000\n",
      "GODA loss: -0.91892\n",
      "\n",
      "num of updates: 34100\n",
      "GODA loss: -0.92588\n",
      "\n",
      "num of updates: 34200\n",
      "GODA loss: -0.91867\n",
      "\n",
      "num of updates: 34300\n",
      "GODA loss: -0.91958\n",
      "\n",
      "num of updates: 34400\n",
      "GODA loss: -0.91937\n",
      "\n",
      "num of updates: 34500\n",
      "GODA loss: -0.92826\n",
      "\n",
      "num of updates: 34600\n",
      "GODA loss: -0.92665\n",
      "\n",
      "num of updates: 34700\n",
      "GODA loss: -0.91852\n",
      "\n",
      "num of updates: 34800\n",
      "GODA loss: -0.92280\n",
      "\n",
      "num of updates: 34900\n",
      "GODA loss: -0.93525\n",
      "\n",
      "num of updates: 35000\n",
      "GODA loss: -0.92994\n",
      "\n",
      "num of updates: 35100\n",
      "GODA loss: -0.92699\n",
      "\n",
      "num of updates: 35200\n",
      "GODA loss: -0.91898\n",
      "\n",
      "num of updates: 35300\n",
      "GODA loss: -0.92651\n",
      "\n",
      "num of updates: 35400\n",
      "GODA loss: -0.92014\n",
      "\n",
      "num of updates: 35500\n",
      "GODA loss: -0.92416\n",
      "\n",
      "num of updates: 35600\n",
      "GODA loss: -0.92656\n",
      "\n",
      "num of updates: 35700\n",
      "GODA loss: -0.93705\n",
      "\n",
      "num of updates: 35800\n",
      "GODA loss: -0.92129\n",
      "\n",
      "num of updates: 35900\n",
      "GODA loss: -0.91891\n",
      "\n",
      "num of updates: 36000\n",
      "GODA loss: -0.92905\n",
      "\n",
      "num of updates: 36100\n",
      "GODA loss: -0.93200\n",
      "\n",
      "num of updates: 36200\n",
      "GODA loss: -0.92917\n",
      "\n",
      "num of updates: 36300\n",
      "GODA loss: -0.92289\n",
      "\n",
      "num of updates: 36400\n",
      "GODA loss: -0.92872\n",
      "\n",
      "num of updates: 36500\n",
      "GODA loss: -0.92682\n",
      "\n",
      "num of updates: 36600\n",
      "GODA loss: -0.93389\n",
      "\n",
      "num of updates: 36700\n",
      "GODA loss: -0.93175\n",
      "\n",
      "num of updates: 36800\n",
      "GODA loss: -0.94106\n",
      "\n",
      "num of updates: 36900\n",
      "GODA loss: -0.93900\n",
      "\n",
      "num of updates: 37000\n",
      "GODA loss: -0.93594\n",
      "\n",
      "num of updates: 37100\n",
      "GODA loss: -0.94273\n",
      "\n",
      "num of updates: 37200\n",
      "GODA loss: -0.93557\n",
      "\n",
      "num of updates: 37300\n",
      "GODA loss: -0.92954\n",
      "\n",
      "num of updates: 37400\n",
      "GODA loss: -0.93514\n",
      "\n",
      "num of updates: 37500\n",
      "GODA loss: -0.94030\n",
      "\n",
      "num of updates: 37600\n",
      "GODA loss: -0.93924\n",
      "\n",
      "num of updates: 37700\n",
      "GODA loss: -0.93970\n",
      "\n",
      "num of updates: 37800\n",
      "GODA loss: -0.94176\n",
      "\n",
      "num of updates: 37900\n",
      "GODA loss: -0.93458\n",
      "\n",
      "num of updates: 38000\n",
      "GODA loss: -0.94009\n",
      "\n",
      "num of updates: 38100\n",
      "GODA loss: -0.95316\n",
      "\n",
      "num of updates: 38200\n",
      "GODA loss: -0.94305\n",
      "\n",
      "num of updates: 38300\n",
      "GODA loss: -0.94283\n",
      "\n",
      "num of updates: 38400\n",
      "GODA loss: -0.93924\n",
      "\n",
      "num of updates: 38500\n",
      "GODA loss: -0.93303\n",
      "\n",
      "num of updates: 38600\n",
      "GODA loss: -0.94250\n",
      "\n",
      "num of updates: 38700\n",
      "GODA loss: -0.94999\n",
      "\n",
      "num of updates: 38800\n",
      "GODA loss: -0.94770\n",
      "\n",
      "num of updates: 38900\n",
      "GODA loss: -0.93691\n",
      "\n",
      "num of updates: 39000\n",
      "GODA loss: -0.93198\n",
      "\n",
      "num of updates: 39100\n",
      "GODA loss: -0.94415\n",
      "\n",
      "num of updates: 39200\n",
      "GODA loss: -0.94643\n",
      "\n",
      "num of updates: 39300\n",
      "GODA loss: -0.95185\n",
      "\n",
      "num of updates: 39400\n",
      "GODA loss: -0.94418\n",
      "\n",
      "num of updates: 39500\n",
      "GODA loss: -0.94115\n",
      "\n",
      "num of updates: 39600\n",
      "GODA loss: -0.94346\n",
      "\n",
      "num of updates: 39700\n",
      "GODA loss: -0.95337\n",
      "\n",
      "num of updates: 39800\n",
      "GODA loss: -0.94890\n",
      "\n",
      "num of updates: 39900\n",
      "GODA loss: -0.93479\n",
      "\n",
      "num of updates: 40000\n",
      "GODA loss: -0.94642\n",
      "\n",
      "num of updates: 40100\n",
      "GODA loss: -0.94354\n",
      "\n",
      "num of updates: 40200\n",
      "GODA loss: -0.95627\n",
      "\n",
      "num of updates: 40300\n",
      "GODA loss: -0.95262\n",
      "\n",
      "num of updates: 40400\n",
      "GODA loss: -0.94808\n",
      "\n",
      "num of updates: 40500\n",
      "GODA loss: -0.95041\n",
      "\n",
      "num of updates: 40600\n",
      "GODA loss: -0.94717\n",
      "\n",
      "num of updates: 40700\n",
      "GODA loss: -0.95302\n",
      "\n",
      "num of updates: 40800\n",
      "GODA loss: -0.95458\n",
      "\n",
      "num of updates: 40900\n",
      "GODA loss: -0.95696\n",
      "\n",
      "num of updates: 41000\n",
      "GODA loss: -0.95614\n",
      "\n",
      "num of updates: 41100\n",
      "GODA loss: -0.94643\n",
      "\n",
      "num of updates: 41200\n",
      "GODA loss: -0.95162\n",
      "\n",
      "num of updates: 41300\n",
      "GODA loss: -0.95735\n",
      "\n",
      "num of updates: 41400\n",
      "GODA loss: -0.95048\n",
      "\n",
      "num of updates: 41500\n",
      "GODA loss: -0.95060\n",
      "\n",
      "num of updates: 41600\n",
      "GODA loss: -0.95495\n",
      "\n",
      "num of updates: 41700\n",
      "GODA loss: -0.95247\n",
      "\n",
      "num of updates: 41800\n",
      "GODA loss: -0.96224\n",
      "\n",
      "num of updates: 41900\n",
      "GODA loss: -0.95827\n",
      "\n",
      "num of updates: 42000\n",
      "GODA loss: -0.95649\n",
      "\n",
      "num of updates: 42100\n",
      "GODA loss: -0.96033\n",
      "\n",
      "num of updates: 42200\n",
      "GODA loss: -0.95256\n",
      "\n",
      "num of updates: 42300\n",
      "GODA loss: -0.96043\n",
      "\n",
      "num of updates: 42400\n",
      "GODA loss: -0.96175\n",
      "\n",
      "num of updates: 42500\n",
      "GODA loss: -0.96002\n",
      "\n",
      "num of updates: 42600\n",
      "GODA loss: -0.96227\n",
      "\n",
      "num of updates: 42700\n",
      "GODA loss: -0.95503\n",
      "\n",
      "num of updates: 42800\n",
      "GODA loss: -0.95852\n",
      "\n",
      "num of updates: 42900\n",
      "GODA loss: -0.95231\n",
      "\n",
      "num of updates: 43000\n",
      "GODA loss: -0.95561\n",
      "\n",
      "num of updates: 43100\n",
      "GODA loss: -0.95101\n",
      "\n",
      "num of updates: 43200\n",
      "GODA loss: -0.95499\n",
      "\n",
      "num of updates: 43300\n",
      "GODA loss: -0.96314\n",
      "\n",
      "num of updates: 43400\n",
      "GODA loss: -0.96922\n",
      "\n",
      "num of updates: 43500\n",
      "GODA loss: -0.96035\n",
      "\n",
      "num of updates: 43600\n",
      "GODA loss: -0.96256\n",
      "\n",
      "num of updates: 43700\n",
      "GODA loss: -0.95099\n",
      "\n",
      "num of updates: 43800\n",
      "GODA loss: -0.96273\n",
      "\n",
      "num of updates: 43900\n",
      "GODA loss: -0.95702\n",
      "\n",
      "num of updates: 44000\n",
      "GODA loss: -0.96395\n",
      "\n",
      "num of updates: 44100\n",
      "GODA loss: -0.97332\n",
      "\n",
      "num of updates: 44200\n",
      "GODA loss: -0.96868\n",
      "\n",
      "num of updates: 44300\n",
      "GODA loss: -0.98260\n",
      "\n",
      "num of updates: 44400\n",
      "GODA loss: -0.96098\n",
      "\n",
      "num of updates: 44500\n",
      "GODA loss: -0.96092\n",
      "\n",
      "num of updates: 44600\n",
      "GODA loss: -0.96389\n",
      "\n",
      "num of updates: 44700\n",
      "GODA loss: -0.96714\n",
      "\n",
      "num of updates: 44800\n",
      "GODA loss: -0.97102\n",
      "\n",
      "num of updates: 44900\n",
      "GODA loss: -0.96758\n",
      "\n",
      "num of updates: 45000\n",
      "GODA loss: -0.96498\n",
      "\n",
      "num of updates: 45100\n",
      "GODA loss: -0.96959\n",
      "\n",
      "num of updates: 45200\n",
      "GODA loss: -0.96925\n",
      "\n",
      "num of updates: 45300\n",
      "GODA loss: -0.96919\n",
      "\n",
      "num of updates: 45400\n",
      "GODA loss: -0.97404\n",
      "\n",
      "num of updates: 45500\n",
      "GODA loss: -0.96907\n",
      "\n",
      "num of updates: 45600\n",
      "GODA loss: -0.95547\n",
      "\n",
      "num of updates: 45700\n",
      "GODA loss: -0.97231\n",
      "\n",
      "num of updates: 45800\n",
      "GODA loss: -0.96116\n",
      "\n",
      "num of updates: 45900\n",
      "GODA loss: -0.98101\n",
      "\n",
      "num of updates: 46000\n",
      "GODA loss: -0.97178\n",
      "\n",
      "num of updates: 46100\n",
      "GODA loss: -0.97785\n",
      "\n",
      "num of updates: 46200\n",
      "GODA loss: -0.98327\n",
      "\n",
      "num of updates: 46300\n",
      "GODA loss: -0.98002\n",
      "\n",
      "num of updates: 46400\n",
      "GODA loss: -0.97017\n",
      "\n",
      "num of updates: 46500\n",
      "GODA loss: -0.96813\n",
      "\n",
      "num of updates: 46600\n",
      "GODA loss: -0.97987\n",
      "\n",
      "num of updates: 46700\n",
      "GODA loss: -0.98269\n",
      "\n",
      "num of updates: 46800\n",
      "GODA loss: -0.96549\n",
      "\n",
      "num of updates: 46900\n",
      "GODA loss: -0.97000\n",
      "\n",
      "num of updates: 47000\n",
      "GODA loss: -0.96738\n",
      "\n",
      "num of updates: 47100\n",
      "GODA loss: -0.97416\n",
      "\n",
      "num of updates: 47200\n",
      "GODA loss: -0.97455\n",
      "\n",
      "num of updates: 47300\n",
      "GODA loss: -0.97456\n",
      "\n",
      "num of updates: 47400\n",
      "GODA loss: -0.97159\n",
      "\n",
      "num of updates: 47500\n",
      "GODA loss: -0.98340\n",
      "\n",
      "num of updates: 47600\n",
      "GODA loss: -0.97336\n",
      "\n",
      "num of updates: 47700\n",
      "GODA loss: -0.97519\n",
      "\n",
      "num of updates: 47800\n",
      "GODA loss: -0.98680\n",
      "\n",
      "num of updates: 47900\n",
      "GODA loss: -0.97920\n",
      "\n",
      "num of updates: 48000\n",
      "GODA loss: -0.98468\n",
      "\n",
      "num of updates: 48100\n",
      "GODA loss: -0.97796\n",
      "\n",
      "num of updates: 48200\n",
      "GODA loss: -0.97588\n",
      "\n",
      "num of updates: 48300\n",
      "GODA loss: -0.97364\n",
      "\n",
      "num of updates: 48400\n",
      "GODA loss: -0.96968\n",
      "\n",
      "num of updates: 48500\n",
      "GODA loss: -0.97209\n",
      "\n",
      "num of updates: 48600\n",
      "GODA loss: -0.98086\n",
      "\n",
      "num of updates: 48700\n",
      "GODA loss: -0.98024\n",
      "\n",
      "num of updates: 48800\n",
      "GODA loss: -0.98770\n",
      "\n",
      "num of updates: 48900\n",
      "GODA loss: -0.98706\n",
      "\n",
      "num of updates: 49000\n",
      "GODA loss: -0.98994\n",
      "\n",
      "num of updates: 49100\n",
      "GODA loss: -0.98861\n",
      "\n",
      "num of updates: 49200\n",
      "GODA loss: -0.98124\n",
      "\n",
      "num of updates: 49300\n",
      "GODA loss: -0.97746\n",
      "\n",
      "num of updates: 49400\n",
      "GODA loss: -0.98049\n",
      "\n",
      "num of updates: 49500\n",
      "GODA loss: -0.97450\n",
      "\n",
      "num of updates: 49600\n",
      "GODA loss: -0.97845\n",
      "\n",
      "num of updates: 49700\n",
      "GODA loss: -0.97143\n",
      "\n",
      "num of updates: 49800\n",
      "GODA loss: -0.98071\n",
      "\n",
      "num of updates: 49900\n",
      "GODA loss: -0.97660\n",
      "\n",
      "num of updates: 50000\n",
      "GODA loss: -0.97563\n",
      "\n",
      "num of updates: 50100\n",
      "GODA loss: -0.98315\n",
      "\n",
      "num of updates: 50200\n",
      "GODA loss: -0.98932\n",
      "\n",
      "num of updates: 50300\n",
      "GODA loss: -0.98316\n",
      "\n",
      "num of updates: 50400\n",
      "GODA loss: -0.97932\n",
      "\n",
      "num of updates: 50500\n",
      "GODA loss: -0.98046\n",
      "\n",
      "num of updates: 50600\n",
      "GODA loss: -0.98419\n",
      "\n",
      "num of updates: 50700\n",
      "GODA loss: -0.99255\n",
      "\n",
      "num of updates: 50800\n",
      "GODA loss: -0.99185\n",
      "\n",
      "num of updates: 50900\n",
      "GODA loss: -0.98387\n",
      "\n",
      "num of updates: 51000\n",
      "GODA loss: -0.97781\n",
      "\n",
      "num of updates: 51100\n",
      "GODA loss: -0.97746\n",
      "\n",
      "num of updates: 51200\n",
      "GODA loss: -0.99032\n",
      "\n",
      "num of updates: 51300\n",
      "GODA loss: -0.98243\n",
      "\n",
      "num of updates: 51400\n",
      "GODA loss: -0.98266\n",
      "\n",
      "num of updates: 51500\n",
      "GODA loss: -0.98452\n",
      "\n",
      "num of updates: 51600\n",
      "GODA loss: -0.99087\n",
      "\n",
      "num of updates: 51700\n",
      "GODA loss: -0.98927\n",
      "\n",
      "num of updates: 51800\n",
      "GODA loss: -0.98103\n",
      "\n",
      "num of updates: 51900\n",
      "GODA loss: -0.98172\n",
      "\n",
      "num of updates: 52000\n",
      "GODA loss: -0.98937\n",
      "\n",
      "num of updates: 52100\n",
      "GODA loss: -0.99732\n",
      "\n",
      "num of updates: 52200\n",
      "GODA loss: -0.97282\n",
      "\n",
      "num of updates: 52300\n",
      "GODA loss: -0.98244\n",
      "\n",
      "num of updates: 52400\n",
      "GODA loss: -0.99194\n",
      "\n",
      "num of updates: 52500\n",
      "GODA loss: -0.97950\n",
      "\n",
      "num of updates: 52600\n",
      "GODA loss: -0.99169\n",
      "\n",
      "num of updates: 52700\n",
      "GODA loss: -0.99289\n",
      "\n",
      "num of updates: 52800\n",
      "GODA loss: -0.98741\n",
      "\n",
      "num of updates: 52900\n",
      "GODA loss: -0.98704\n",
      "\n",
      "num of updates: 53000\n",
      "GODA loss: -0.99193\n",
      "\n",
      "num of updates: 53100\n",
      "GODA loss: -0.99797\n",
      "\n",
      "num of updates: 53200\n",
      "GODA loss: -0.98492\n",
      "\n",
      "num of updates: 53300\n",
      "GODA loss: -0.99544\n",
      "\n",
      "num of updates: 53400\n",
      "GODA loss: -0.98964\n",
      "\n",
      "num of updates: 53500\n",
      "GODA loss: -0.99889\n",
      "\n",
      "num of updates: 53600\n",
      "GODA loss: -0.99885\n",
      "\n",
      "num of updates: 53700\n",
      "GODA loss: -0.99652\n",
      "\n",
      "num of updates: 53800\n",
      "GODA loss: -0.99083\n",
      "\n",
      "num of updates: 53900\n",
      "GODA loss: -0.99020\n",
      "\n",
      "num of updates: 54000\n",
      "GODA loss: -0.98678\n",
      "\n",
      "num of updates: 54100\n",
      "GODA loss: -0.99118\n",
      "\n",
      "num of updates: 54200\n",
      "GODA loss: -0.99337\n",
      "\n",
      "num of updates: 54300\n",
      "GODA loss: -1.00071\n",
      "\n",
      "num of updates: 54400\n",
      "GODA loss: -0.98574\n",
      "\n",
      "num of updates: 54500\n",
      "GODA loss: -1.00014\n",
      "\n",
      "num of updates: 54600\n",
      "GODA loss: -0.99992\n",
      "\n",
      "num of updates: 54700\n",
      "GODA loss: -1.00032\n",
      "\n",
      "num of updates: 54800\n",
      "GODA loss: -0.98343\n",
      "\n",
      "num of updates: 54900\n",
      "GODA loss: -0.99273\n",
      "\n",
      "num of updates: 55000\n",
      "GODA loss: -1.00081\n",
      "\n",
      "num of updates: 55100\n",
      "GODA loss: -0.99158\n",
      "\n",
      "num of updates: 55200\n",
      "GODA loss: -0.99376\n",
      "\n",
      "num of updates: 55300\n",
      "GODA loss: -0.99364\n",
      "\n",
      "num of updates: 55400\n",
      "GODA loss: -0.99353\n",
      "\n",
      "num of updates: 55500\n",
      "GODA loss: -0.98982\n",
      "\n",
      "num of updates: 55600\n",
      "GODA loss: -0.99100\n",
      "\n",
      "num of updates: 55700\n",
      "GODA loss: -0.99255\n",
      "\n",
      "num of updates: 55800\n",
      "GODA loss: -1.00192\n",
      "\n",
      "num of updates: 55900\n",
      "GODA loss: -0.99913\n",
      "\n",
      "num of updates: 56000\n",
      "GODA loss: -0.96296\n",
      "\n",
      "num of updates: 56100\n",
      "GODA loss: -0.99090\n",
      "\n",
      "num of updates: 56200\n",
      "GODA loss: -0.99121\n",
      "\n",
      "num of updates: 56300\n",
      "GODA loss: -0.99624\n",
      "\n",
      "num of updates: 56400\n",
      "GODA loss: -0.99561\n",
      "\n",
      "num of updates: 56500\n",
      "GODA loss: -0.99529\n",
      "\n",
      "num of updates: 56600\n",
      "GODA loss: -0.99859\n",
      "\n",
      "num of updates: 56700\n",
      "GODA loss: -1.00003\n",
      "\n",
      "num of updates: 56800\n",
      "GODA loss: -0.99786\n",
      "\n",
      "num of updates: 56900\n",
      "GODA loss: -1.00091\n",
      "\n",
      "num of updates: 57000\n",
      "GODA loss: -0.99732\n",
      "\n",
      "num of updates: 57100\n",
      "GODA loss: -0.99977\n",
      "\n",
      "num of updates: 57200\n",
      "GODA loss: -1.00106\n",
      "\n",
      "num of updates: 57300\n",
      "GODA loss: -0.99148\n",
      "\n",
      "num of updates: 57400\n",
      "GODA loss: -0.99828\n",
      "\n",
      "num of updates: 57500\n",
      "GODA loss: -0.99310\n",
      "\n",
      "num of updates: 57600\n",
      "GODA loss: -0.99889\n",
      "\n",
      "num of updates: 57700\n",
      "GODA loss: -1.00184\n",
      "\n",
      "num of updates: 57800\n",
      "GODA loss: -1.00578\n",
      "\n",
      "num of updates: 57900\n",
      "GODA loss: -1.00173\n",
      "\n",
      "num of updates: 58000\n",
      "GODA loss: -0.99970\n",
      "\n",
      "num of updates: 58100\n",
      "GODA loss: -0.99537\n",
      "\n",
      "num of updates: 58200\n",
      "GODA loss: -1.00364\n",
      "\n",
      "num of updates: 58300\n",
      "GODA loss: -0.99931\n",
      "\n",
      "num of updates: 58400\n",
      "GODA loss: -1.00712\n",
      "\n",
      "num of updates: 58500\n",
      "GODA loss: -0.99552\n",
      "\n",
      "num of updates: 58600\n",
      "GODA loss: -0.99836\n",
      "\n",
      "num of updates: 58700\n",
      "GODA loss: -0.98807\n",
      "\n",
      "num of updates: 58800\n",
      "GODA loss: -0.99414\n",
      "\n",
      "num of updates: 58900\n",
      "GODA loss: -0.99921\n",
      "\n",
      "num of updates: 59000\n",
      "GODA loss: -1.00007\n",
      "\n",
      "num of updates: 59100\n",
      "GODA loss: -1.00239\n",
      "\n",
      "num of updates: 59200\n",
      "GODA loss: -1.01096\n",
      "\n",
      "num of updates: 59300\n",
      "GODA loss: -1.00307\n",
      "\n",
      "num of updates: 59400\n",
      "GODA loss: -0.99802\n",
      "\n",
      "num of updates: 59500\n",
      "GODA loss: -1.01587\n",
      "\n",
      "num of updates: 59600\n",
      "GODA loss: -1.01151\n",
      "\n",
      "num of updates: 59700\n",
      "GODA loss: -1.00606\n",
      "\n",
      "num of updates: 59800\n",
      "GODA loss: -0.99505\n",
      "\n",
      "num of updates: 59900\n",
      "GODA loss: -0.99994\n",
      "\n",
      "num of updates: 60000\n",
      "GODA loss: -0.99803\n",
      "\n",
      "num of updates: 60100\n",
      "GODA loss: -1.00342\n",
      "\n",
      "num of updates: 60200\n",
      "GODA loss: -1.00409\n",
      "\n",
      "num of updates: 60300\n",
      "GODA loss: -1.00822\n",
      "\n",
      "num of updates: 60400\n",
      "GODA loss: -1.00208\n",
      "\n",
      "num of updates: 60500\n",
      "GODA loss: -1.00025\n",
      "\n",
      "num of updates: 60600\n",
      "GODA loss: -1.00895\n",
      "\n",
      "num of updates: 60700\n",
      "GODA loss: -0.99661\n",
      "\n",
      "num of updates: 60800\n",
      "GODA loss: -1.01214\n",
      "\n",
      "num of updates: 60900\n",
      "GODA loss: -1.00609\n",
      "\n",
      "num of updates: 61000\n",
      "GODA loss: -0.99844\n",
      "\n",
      "num of updates: 61100\n",
      "GODA loss: -1.00445\n",
      "\n",
      "num of updates: 61200\n",
      "GODA loss: -1.00749\n",
      "\n",
      "num of updates: 61300\n",
      "GODA loss: -1.01170\n",
      "\n",
      "num of updates: 61400\n",
      "GODA loss: -1.00612\n",
      "\n",
      "num of updates: 61500\n",
      "GODA loss: -1.00044\n",
      "\n",
      "num of updates: 61600\n",
      "GODA loss: -0.98732\n",
      "\n",
      "num of updates: 61700\n",
      "GODA loss: -0.99266\n",
      "\n",
      "num of updates: 61800\n",
      "GODA loss: -1.00373\n",
      "\n",
      "num of updates: 61900\n",
      "GODA loss: -1.00184\n",
      "\n",
      "num of updates: 62000\n",
      "GODA loss: -1.00317\n",
      "\n",
      "num of updates: 62100\n",
      "GODA loss: -1.01842\n",
      "\n",
      "num of updates: 62200\n",
      "GODA loss: -1.00638\n",
      "\n",
      "num of updates: 62300\n",
      "GODA loss: -1.00557\n",
      "\n",
      "num of updates: 62400\n",
      "GODA loss: -1.01072\n",
      "\n",
      "num of updates: 62500\n",
      "GODA loss: -1.00184\n",
      "\n",
      "num of updates: 62600\n",
      "GODA loss: -1.01322\n",
      "\n",
      "num of updates: 62700\n",
      "GODA loss: -1.00475\n",
      "\n",
      "num of updates: 62800\n",
      "GODA loss: -1.00796\n",
      "\n",
      "num of updates: 62900\n",
      "GODA loss: -1.00988\n",
      "\n",
      "num of updates: 63000\n",
      "GODA loss: -1.01142\n",
      "\n",
      "num of updates: 63100\n",
      "GODA loss: -1.00992\n",
      "\n",
      "num of updates: 63200\n",
      "GODA loss: -1.01357\n",
      "\n",
      "num of updates: 63300\n",
      "GODA loss: -1.01495\n",
      "\n",
      "num of updates: 63400\n",
      "GODA loss: -1.00727\n",
      "\n",
      "num of updates: 63500\n",
      "GODA loss: -1.01089\n",
      "\n",
      "num of updates: 63600\n",
      "GODA loss: -0.99766\n",
      "\n",
      "num of updates: 63700\n",
      "GODA loss: -1.00569\n",
      "\n",
      "num of updates: 63800\n",
      "GODA loss: -1.01948\n",
      "\n",
      "num of updates: 63900\n",
      "GODA loss: -1.00662\n",
      "\n",
      "num of updates: 64000\n",
      "GODA loss: -0.99852\n",
      "\n",
      "num of updates: 64100\n",
      "GODA loss: -1.00789\n",
      "\n",
      "num of updates: 64200\n",
      "GODA loss: -1.01382\n",
      "\n",
      "num of updates: 64300\n",
      "GODA loss: -1.00862\n",
      "\n",
      "num of updates: 64400\n",
      "GODA loss: -1.01046\n",
      "\n",
      "num of updates: 64500\n",
      "GODA loss: -1.01073\n",
      "\n",
      "num of updates: 64600\n",
      "GODA loss: -1.00301\n",
      "\n",
      "num of updates: 64700\n",
      "GODA loss: -1.01380\n",
      "\n",
      "num of updates: 64800\n",
      "GODA loss: -1.00977\n",
      "\n",
      "num of updates: 64900\n",
      "GODA loss: -1.01728\n",
      "\n",
      "num of updates: 65000\n",
      "GODA loss: -1.02228\n",
      "\n",
      "num of updates: 65100\n",
      "GODA loss: -1.01902\n",
      "\n",
      "num of updates: 65200\n",
      "GODA loss: -1.01553\n",
      "\n",
      "num of updates: 65300\n",
      "GODA loss: -1.01278\n",
      "\n",
      "num of updates: 65400\n",
      "GODA loss: -1.01141\n",
      "\n",
      "num of updates: 65500\n",
      "GODA loss: -1.01493\n",
      "\n",
      "num of updates: 65600\n",
      "GODA loss: -1.01086\n",
      "\n",
      "num of updates: 65700\n",
      "GODA loss: -0.99954\n",
      "\n",
      "num of updates: 65800\n",
      "GODA loss: -1.00955\n",
      "\n",
      "num of updates: 65900\n",
      "GODA loss: -0.99814\n",
      "\n",
      "num of updates: 66000\n",
      "GODA loss: -1.01497\n",
      "\n",
      "num of updates: 66100\n",
      "GODA loss: -1.00949\n",
      "\n",
      "num of updates: 66200\n",
      "GODA loss: -1.00990\n",
      "\n",
      "num of updates: 66300\n",
      "GODA loss: -1.01130\n",
      "\n",
      "num of updates: 66400\n",
      "GODA loss: -1.00729\n",
      "\n",
      "num of updates: 66500\n",
      "GODA loss: -1.01092\n",
      "\n",
      "num of updates: 66600\n",
      "GODA loss: -1.01362\n",
      "\n",
      "num of updates: 66700\n",
      "GODA loss: -1.01251\n",
      "\n",
      "num of updates: 66800\n",
      "GODA loss: -1.01467\n",
      "\n",
      "num of updates: 66900\n",
      "GODA loss: -1.00673\n",
      "\n",
      "num of updates: 67000\n",
      "GODA loss: -1.01891\n",
      "\n",
      "num of updates: 67100\n",
      "GODA loss: -1.01500\n",
      "\n",
      "num of updates: 67200\n",
      "GODA loss: -1.01382\n",
      "\n",
      "num of updates: 67300\n",
      "GODA loss: -1.01580\n",
      "\n",
      "num of updates: 67400\n",
      "GODA loss: -1.00378\n",
      "\n",
      "num of updates: 67500\n",
      "GODA loss: -1.01801\n",
      "\n",
      "num of updates: 67600\n",
      "GODA loss: -1.01575\n",
      "\n",
      "num of updates: 67700\n",
      "GODA loss: -0.99720\n",
      "\n",
      "num of updates: 67800\n",
      "GODA loss: -0.99649\n",
      "\n",
      "num of updates: 67900\n",
      "GODA loss: -1.01103\n",
      "\n",
      "num of updates: 68000\n",
      "GODA loss: -1.01836\n",
      "\n",
      "num of updates: 68100\n",
      "GODA loss: -1.02317\n",
      "\n",
      "num of updates: 68200\n",
      "GODA loss: -1.02155\n",
      "\n",
      "num of updates: 68300\n",
      "GODA loss: -1.00812\n",
      "\n",
      "num of updates: 68400\n",
      "GODA loss: -1.01941\n",
      "\n",
      "num of updates: 68500\n",
      "GODA loss: -1.03102\n",
      "\n",
      "num of updates: 68600\n",
      "GODA loss: -1.00696\n",
      "\n",
      "num of updates: 68700\n",
      "GODA loss: -1.01824\n",
      "\n",
      "num of updates: 68800\n",
      "GODA loss: -1.01737\n",
      "\n",
      "num of updates: 68900\n",
      "GODA loss: -1.01331\n",
      "\n",
      "num of updates: 69000\n",
      "GODA loss: -1.02586\n",
      "\n",
      "num of updates: 69100\n",
      "GODA loss: -1.00943\n",
      "\n",
      "num of updates: 69200\n",
      "GODA loss: -1.02163\n",
      "\n",
      "num of updates: 69300\n",
      "GODA loss: -1.03239\n",
      "\n",
      "num of updates: 69400\n",
      "GODA loss: -1.02167\n",
      "\n",
      "num of updates: 69500\n",
      "GODA loss: -1.01513\n",
      "\n",
      "num of updates: 69600\n",
      "GODA loss: -1.02087\n",
      "\n",
      "num of updates: 69700\n",
      "GODA loss: -1.01647\n",
      "\n",
      "num of updates: 69800\n",
      "GODA loss: -1.02494\n",
      "\n",
      "num of updates: 69900\n",
      "GODA loss: -1.01624\n",
      "\n",
      "num of updates: 70000\n",
      "GODA loss: -1.02148\n",
      "\n",
      "num of updates: 70100\n",
      "GODA loss: -1.02632\n",
      "\n",
      "num of updates: 70200\n",
      "GODA loss: -1.02248\n",
      "\n",
      "num of updates: 70300\n",
      "GODA loss: -1.01571\n",
      "\n",
      "num of updates: 70400\n",
      "GODA loss: -1.02398\n",
      "\n",
      "num of updates: 70500\n",
      "GODA loss: -1.01825\n",
      "\n",
      "num of updates: 70600\n",
      "GODA loss: -1.02445\n",
      "\n",
      "num of updates: 70700\n",
      "GODA loss: -1.01375\n",
      "\n",
      "num of updates: 70800\n",
      "GODA loss: -1.02559\n",
      "\n",
      "num of updates: 70900\n",
      "GODA loss: -1.02293\n",
      "\n",
      "num of updates: 71000\n",
      "GODA loss: -1.03016\n",
      "\n",
      "num of updates: 71100\n",
      "GODA loss: -1.00987\n",
      "\n",
      "num of updates: 71200\n",
      "GODA loss: -1.01922\n",
      "\n",
      "num of updates: 71300\n",
      "GODA loss: -1.02672\n",
      "\n",
      "num of updates: 71400\n",
      "GODA loss: -1.03506\n",
      "\n",
      "num of updates: 71500\n",
      "GODA loss: -1.02110\n",
      "\n",
      "num of updates: 71600\n",
      "GODA loss: -1.03129\n",
      "\n",
      "num of updates: 71700\n",
      "GODA loss: -1.02615\n",
      "\n",
      "num of updates: 71800\n",
      "GODA loss: -1.02214\n",
      "\n",
      "num of updates: 71900\n",
      "GODA loss: -1.02609\n",
      "\n",
      "num of updates: 72000\n",
      "GODA loss: -1.01709\n",
      "\n",
      "num of updates: 72100\n",
      "GODA loss: -1.02390\n",
      "\n",
      "num of updates: 72200\n",
      "GODA loss: -1.02933\n",
      "\n",
      "num of updates: 72300\n",
      "GODA loss: -1.01381\n",
      "\n",
      "num of updates: 72400\n",
      "GODA loss: -1.02273\n",
      "\n",
      "num of updates: 72500\n",
      "GODA loss: -1.02101\n",
      "\n",
      "num of updates: 72600\n",
      "GODA loss: -1.02252\n",
      "\n",
      "num of updates: 72700\n",
      "GODA loss: -1.01698\n",
      "\n",
      "num of updates: 72800\n",
      "GODA loss: -1.02417\n",
      "\n",
      "num of updates: 72900\n",
      "GODA loss: -1.02458\n",
      "\n",
      "num of updates: 73000\n",
      "GODA loss: -1.03392\n",
      "\n",
      "num of updates: 73100\n",
      "GODA loss: -1.03479\n",
      "\n",
      "num of updates: 73200\n",
      "GODA loss: -1.03098\n",
      "\n",
      "num of updates: 73300\n",
      "GODA loss: -1.03200\n",
      "\n",
      "num of updates: 73400\n",
      "GODA loss: -1.02969\n",
      "\n",
      "num of updates: 73500\n",
      "GODA loss: -1.03196\n",
      "\n",
      "num of updates: 73600\n",
      "GODA loss: -1.04072\n",
      "\n",
      "num of updates: 73700\n",
      "GODA loss: -1.02570\n",
      "\n",
      "num of updates: 73800\n",
      "GODA loss: -1.02405\n",
      "\n",
      "num of updates: 73900\n",
      "GODA loss: -1.02610\n",
      "\n",
      "num of updates: 74000\n",
      "GODA loss: -1.02159\n",
      "\n",
      "num of updates: 74100\n",
      "GODA loss: -1.02445\n",
      "\n",
      "num of updates: 74200\n",
      "GODA loss: -1.03606\n",
      "\n",
      "num of updates: 74300\n",
      "GODA loss: -1.02902\n",
      "\n",
      "num of updates: 74400\n",
      "GODA loss: -1.03499\n",
      "\n",
      "num of updates: 74500\n",
      "GODA loss: -1.03099\n",
      "\n",
      "num of updates: 74600\n",
      "GODA loss: -1.03635\n",
      "\n",
      "num of updates: 74700\n",
      "GODA loss: -1.03832\n",
      "\n",
      "num of updates: 74800\n",
      "GODA loss: -1.03388\n",
      "\n",
      "num of updates: 74900\n",
      "GODA loss: -1.02436\n",
      "\n",
      "num of updates: 75000\n",
      "GODA loss: -1.03654\n",
      "\n",
      "num of updates: 75100\n",
      "GODA loss: -1.02252\n",
      "\n",
      "num of updates: 75200\n",
      "GODA loss: -1.03586\n",
      "\n",
      "num of updates: 75300\n",
      "GODA loss: -1.03659\n",
      "\n",
      "num of updates: 75400\n",
      "GODA loss: -1.03459\n",
      "\n",
      "num of updates: 75500\n",
      "GODA loss: -1.03661\n",
      "\n",
      "num of updates: 75600\n",
      "GODA loss: -1.04262\n",
      "\n",
      "num of updates: 75700\n",
      "GODA loss: -1.04592\n",
      "\n",
      "num of updates: 75800\n",
      "GODA loss: -1.03090\n",
      "\n",
      "num of updates: 75900\n",
      "GODA loss: -1.02639\n",
      "\n",
      "num of updates: 76000\n",
      "GODA loss: -1.04091\n",
      "\n",
      "num of updates: 76100\n",
      "GODA loss: -1.03717\n",
      "\n",
      "num of updates: 76200\n",
      "GODA loss: -1.03370\n",
      "\n",
      "num of updates: 76300\n",
      "GODA loss: -1.03795\n",
      "\n",
      "num of updates: 76400\n",
      "GODA loss: -1.04402\n",
      "\n",
      "num of updates: 76500\n",
      "GODA loss: -1.03444\n",
      "\n",
      "num of updates: 76600\n",
      "GODA loss: -1.03353\n",
      "\n",
      "num of updates: 76700\n",
      "GODA loss: -1.04241\n",
      "\n",
      "num of updates: 76800\n",
      "GODA loss: -1.03174\n",
      "\n",
      "num of updates: 76900\n",
      "GODA loss: -1.03834\n",
      "\n",
      "num of updates: 77000\n",
      "GODA loss: -1.04693\n",
      "\n",
      "num of updates: 77100\n",
      "GODA loss: -1.03809\n",
      "\n",
      "num of updates: 77200\n",
      "GODA loss: -1.04544\n",
      "\n",
      "num of updates: 77300\n",
      "GODA loss: -1.03635\n",
      "\n",
      "num of updates: 77400\n",
      "GODA loss: -1.04094\n",
      "\n",
      "num of updates: 77500\n",
      "GODA loss: -1.03751\n",
      "\n",
      "num of updates: 77600\n",
      "GODA loss: -1.04643\n",
      "\n",
      "num of updates: 77700\n",
      "GODA loss: -1.03305\n",
      "\n",
      "num of updates: 77800\n",
      "GODA loss: -1.02743\n",
      "\n",
      "num of updates: 77900\n",
      "GODA loss: -1.04240\n",
      "\n",
      "num of updates: 78000\n",
      "GODA loss: -1.04976\n",
      "\n",
      "num of updates: 78100\n",
      "GODA loss: -1.03684\n",
      "\n",
      "num of updates: 78200\n",
      "GODA loss: -1.03619\n",
      "\n",
      "num of updates: 78300\n",
      "GODA loss: -1.03994\n",
      "\n",
      "num of updates: 78400\n",
      "GODA loss: -1.04012\n",
      "\n",
      "num of updates: 78500\n",
      "GODA loss: -1.04424\n",
      "\n",
      "num of updates: 78600\n",
      "GODA loss: -1.03204\n",
      "\n",
      "num of updates: 78700\n",
      "GODA loss: -1.04402\n",
      "\n",
      "num of updates: 78800\n",
      "GODA loss: -1.05238\n",
      "\n",
      "num of updates: 78900\n",
      "GODA loss: -1.03779\n",
      "\n",
      "num of updates: 79000\n",
      "GODA loss: -1.04357\n",
      "\n",
      "num of updates: 79100\n",
      "GODA loss: -1.04065\n",
      "\n",
      "num of updates: 79200\n",
      "GODA loss: -1.03895\n",
      "\n",
      "num of updates: 79300\n",
      "GODA loss: -1.03567\n",
      "\n",
      "num of updates: 79400\n",
      "GODA loss: -1.03770\n",
      "\n",
      "num of updates: 79500\n",
      "GODA loss: -1.04238\n",
      "\n",
      "num of updates: 79600\n",
      "GODA loss: -1.04190\n",
      "\n",
      "num of updates: 79700\n",
      "GODA loss: -1.01426\n",
      "\n",
      "num of updates: 79800\n",
      "GODA loss: -1.03286\n",
      "\n",
      "num of updates: 79900\n",
      "GODA loss: -1.03067\n",
      "\n",
      "num of updates: 80000\n",
      "GODA loss: -1.04074\n",
      "\n",
      "num of updates: 80100\n",
      "GODA loss: -1.04352\n",
      "\n",
      "num of updates: 80200\n",
      "GODA loss: -1.04616\n",
      "\n",
      "num of updates: 80300\n",
      "GODA loss: -1.03786\n",
      "\n",
      "num of updates: 80400\n",
      "GODA loss: -1.04510\n",
      "\n",
      "num of updates: 80500\n",
      "GODA loss: -1.03822\n",
      "\n",
      "num of updates: 80600\n",
      "GODA loss: -1.04552\n",
      "\n",
      "num of updates: 80700\n",
      "GODA loss: -1.04270\n",
      "\n",
      "num of updates: 80800\n",
      "GODA loss: -1.05349\n",
      "\n",
      "num of updates: 80900\n",
      "GODA loss: -1.03180\n",
      "\n",
      "num of updates: 81000\n",
      "GODA loss: -1.04838\n",
      "\n",
      "num of updates: 81100\n",
      "GODA loss: -1.04385\n",
      "\n",
      "num of updates: 81200\n",
      "GODA loss: -1.04927\n",
      "\n",
      "num of updates: 81300\n",
      "GODA loss: -1.03872\n",
      "\n",
      "num of updates: 81400\n",
      "GODA loss: -1.03557\n",
      "\n",
      "num of updates: 81500\n",
      "GODA loss: -1.03882\n",
      "\n",
      "num of updates: 81600\n",
      "GODA loss: -1.04678\n",
      "\n",
      "num of updates: 81700\n",
      "GODA loss: -1.04794\n",
      "\n",
      "num of updates: 81800\n",
      "GODA loss: -1.04785\n",
      "\n",
      "num of updates: 81900\n",
      "GODA loss: -1.04592\n",
      "\n",
      "num of updates: 82000\n",
      "GODA loss: -1.03838\n",
      "\n",
      "num of updates: 82100\n",
      "GODA loss: -1.04723\n",
      "\n",
      "num of updates: 82200\n",
      "GODA loss: -1.04305\n",
      "\n",
      "num of updates: 82300\n",
      "GODA loss: -1.04467\n",
      "\n",
      "num of updates: 82400\n",
      "GODA loss: -1.04484\n",
      "\n",
      "num of updates: 82500\n",
      "GODA loss: -1.04351\n",
      "\n",
      "num of updates: 82600\n",
      "GODA loss: -1.04385\n",
      "\n",
      "num of updates: 82700\n",
      "GODA loss: -1.05223\n",
      "\n",
      "num of updates: 82800\n",
      "GODA loss: -1.05692\n",
      "\n",
      "num of updates: 82900\n",
      "GODA loss: -1.05270\n",
      "\n",
      "num of updates: 83000\n",
      "GODA loss: -1.04935\n",
      "\n",
      "num of updates: 83100\n",
      "GODA loss: -1.05604\n",
      "\n",
      "num of updates: 83200\n",
      "GODA loss: -1.05074\n",
      "\n",
      "num of updates: 83300\n",
      "GODA loss: -1.05699\n",
      "\n",
      "num of updates: 83400\n",
      "GODA loss: -1.04881\n",
      "\n",
      "num of updates: 83500\n",
      "GODA loss: -1.05945\n",
      "\n",
      "num of updates: 83600\n",
      "GODA loss: -1.05027\n",
      "\n",
      "num of updates: 83700\n",
      "GODA loss: -1.04860\n",
      "\n",
      "num of updates: 83800\n",
      "GODA loss: -1.05281\n",
      "\n",
      "num of updates: 83900\n",
      "GODA loss: -1.04571\n",
      "\n",
      "num of updates: 84000\n",
      "GODA loss: -1.03995\n",
      "\n",
      "num of updates: 84100\n",
      "GODA loss: -1.05670\n",
      "\n",
      "num of updates: 84200\n",
      "GODA loss: -1.05852\n",
      "\n",
      "num of updates: 84300\n",
      "GODA loss: -1.04971\n",
      "\n",
      "num of updates: 84400\n",
      "GODA loss: -1.04173\n",
      "\n",
      "num of updates: 84500\n",
      "GODA loss: -1.04544\n",
      "\n",
      "num of updates: 84600\n",
      "GODA loss: -1.03980\n",
      "\n",
      "num of updates: 84700\n",
      "GODA loss: -1.05700\n",
      "\n",
      "num of updates: 84800\n",
      "GODA loss: -1.05154\n",
      "\n",
      "num of updates: 84900\n",
      "GODA loss: -1.05130\n",
      "\n",
      "num of updates: 85000\n",
      "GODA loss: -1.05446\n",
      "\n",
      "num of updates: 85100\n",
      "GODA loss: -1.04854\n",
      "\n",
      "num of updates: 85200\n",
      "GODA loss: -1.04846\n",
      "\n",
      "num of updates: 85300\n",
      "GODA loss: -1.05187\n",
      "\n",
      "num of updates: 85400\n",
      "GODA loss: -1.04937\n",
      "\n",
      "num of updates: 85500\n",
      "GODA loss: -1.05310\n",
      "\n",
      "num of updates: 85600\n",
      "GODA loss: -1.05404\n",
      "\n",
      "num of updates: 85700\n",
      "GODA loss: -1.05175\n",
      "\n",
      "num of updates: 85800\n",
      "GODA loss: -1.04860\n",
      "\n",
      "num of updates: 85900\n",
      "GODA loss: -1.05674\n",
      "\n",
      "num of updates: 86000\n",
      "GODA loss: -1.05104\n",
      "\n",
      "num of updates: 86100\n",
      "GODA loss: -1.05089\n",
      "\n",
      "num of updates: 86200\n",
      "GODA loss: -1.05338\n",
      "\n",
      "num of updates: 86300\n",
      "GODA loss: -1.05323\n",
      "\n",
      "num of updates: 86400\n",
      "GODA loss: -1.04360\n",
      "\n",
      "num of updates: 86500\n",
      "GODA loss: -1.05452\n",
      "\n",
      "num of updates: 86600\n",
      "GODA loss: -1.04976\n",
      "\n",
      "num of updates: 86700\n",
      "GODA loss: -1.03893\n",
      "\n",
      "num of updates: 86800\n",
      "GODA loss: -1.05395\n",
      "\n",
      "num of updates: 86900\n",
      "GODA loss: -1.05327\n",
      "\n",
      "num of updates: 87000\n",
      "GODA loss: -1.05734\n",
      "\n",
      "num of updates: 87100\n",
      "GODA loss: -1.04221\n",
      "\n",
      "num of updates: 87200\n",
      "GODA loss: -1.05787\n",
      "\n",
      "num of updates: 87300\n",
      "GODA loss: -1.04877\n",
      "\n",
      "num of updates: 87400\n",
      "GODA loss: -1.05762\n",
      "\n",
      "num of updates: 87500\n",
      "GODA loss: -1.05470\n",
      "\n",
      "num of updates: 87600\n",
      "GODA loss: -1.06448\n",
      "\n",
      "num of updates: 87700\n",
      "GODA loss: -1.04972\n",
      "\n",
      "num of updates: 87800\n",
      "GODA loss: -1.05245\n",
      "\n",
      "num of updates: 87900\n",
      "GODA loss: -1.05743\n",
      "\n",
      "num of updates: 88000\n",
      "GODA loss: -1.05754\n",
      "\n",
      "num of updates: 88100\n",
      "GODA loss: -1.04869\n",
      "\n",
      "num of updates: 88200\n",
      "GODA loss: -1.06005\n",
      "\n",
      "num of updates: 88300\n",
      "GODA loss: -1.05774\n",
      "\n",
      "num of updates: 88400\n",
      "GODA loss: -1.05778\n",
      "\n",
      "num of updates: 88500\n",
      "GODA loss: -1.04901\n",
      "\n",
      "num of updates: 88600\n",
      "GODA loss: -1.05648\n",
      "\n",
      "num of updates: 88700\n",
      "GODA loss: -1.06021\n",
      "\n",
      "num of updates: 88800\n",
      "GODA loss: -1.04856\n",
      "\n",
      "num of updates: 88900\n",
      "GODA loss: -1.06528\n",
      "\n",
      "num of updates: 89000\n",
      "GODA loss: -1.06258\n",
      "\n",
      "num of updates: 89100\n",
      "GODA loss: -1.05255\n",
      "\n",
      "num of updates: 89200\n",
      "GODA loss: -1.04901\n",
      "\n",
      "num of updates: 89300\n",
      "GODA loss: -1.06388\n",
      "\n",
      "num of updates: 89400\n",
      "GODA loss: -1.05160\n",
      "\n",
      "num of updates: 89500\n",
      "GODA loss: -1.05200\n",
      "\n",
      "num of updates: 89600\n",
      "GODA loss: -1.05993\n",
      "\n",
      "num of updates: 89700\n",
      "GODA loss: -1.05442\n",
      "\n",
      "num of updates: 89800\n",
      "GODA loss: -1.05104\n",
      "\n",
      "num of updates: 89900\n",
      "GODA loss: -1.05672\n",
      "\n",
      "num of updates: 90000\n",
      "GODA loss: -1.04971\n",
      "\n",
      "num of updates: 90100\n",
      "GODA loss: -1.05711\n",
      "\n",
      "num of updates: 90200\n",
      "GODA loss: -1.05916\n",
      "\n",
      "num of updates: 90300\n",
      "GODA loss: -1.06000\n",
      "\n",
      "num of updates: 90400\n",
      "GODA loss: -1.06324\n",
      "\n",
      "num of updates: 90500\n",
      "GODA loss: -1.06110\n",
      "\n",
      "num of updates: 90600\n",
      "GODA loss: -1.06894\n",
      "\n",
      "num of updates: 90700\n",
      "GODA loss: -1.06397\n",
      "\n",
      "num of updates: 90800\n",
      "GODA loss: -1.06093\n",
      "\n",
      "num of updates: 90900\n",
      "GODA loss: -1.05700\n",
      "\n",
      "num of updates: 91000\n",
      "GODA loss: -1.06237\n",
      "\n",
      "num of updates: 91100\n",
      "GODA loss: -1.04966\n",
      "\n",
      "num of updates: 91200\n",
      "GODA loss: -1.05615\n",
      "\n",
      "num of updates: 91300\n",
      "GODA loss: -1.06063\n",
      "\n",
      "num of updates: 91400\n",
      "GODA loss: -1.05951\n",
      "\n",
      "num of updates: 91500\n",
      "GODA loss: -1.06466\n",
      "\n",
      "num of updates: 91600\n",
      "GODA loss: -1.06622\n",
      "\n",
      "num of updates: 91700\n",
      "GODA loss: -1.06248\n",
      "\n",
      "num of updates: 91800\n",
      "GODA loss: -1.06193\n",
      "\n",
      "num of updates: 91900\n",
      "GODA loss: -1.06312\n",
      "\n",
      "num of updates: 92000\n",
      "GODA loss: -1.05069\n",
      "\n",
      "num of updates: 92100\n",
      "GODA loss: -1.05332\n",
      "\n",
      "num of updates: 92200\n",
      "GODA loss: -1.05926\n",
      "\n",
      "num of updates: 92300\n",
      "GODA loss: -1.06617\n",
      "\n",
      "num of updates: 92400\n",
      "GODA loss: -1.06322\n",
      "\n",
      "num of updates: 92500\n",
      "GODA loss: -1.06841\n",
      "\n",
      "num of updates: 92600\n",
      "GODA loss: -1.06563\n",
      "\n",
      "num of updates: 92700\n",
      "GODA loss: -1.06648\n",
      "\n",
      "num of updates: 92800\n",
      "GODA loss: -1.07070\n",
      "\n",
      "num of updates: 92900\n",
      "GODA loss: -1.07044\n",
      "\n",
      "num of updates: 93000\n",
      "GODA loss: -1.07097\n",
      "\n",
      "num of updates: 93100\n",
      "GODA loss: -1.06903\n",
      "\n",
      "num of updates: 93200\n",
      "GODA loss: -1.06763\n",
      "\n",
      "num of updates: 93300\n",
      "GODA loss: -1.07643\n",
      "\n",
      "num of updates: 93400\n",
      "GODA loss: -1.07349\n",
      "\n",
      "num of updates: 93500\n",
      "GODA loss: -1.06731\n",
      "\n",
      "num of updates: 93600\n",
      "GODA loss: -1.07376\n",
      "\n",
      "num of updates: 93700\n",
      "GODA loss: -1.05960\n",
      "\n",
      "num of updates: 93800\n",
      "GODA loss: -1.07192\n",
      "\n",
      "num of updates: 93900\n",
      "GODA loss: -1.05898\n",
      "\n",
      "num of updates: 94000\n",
      "GODA loss: -1.06084\n",
      "\n",
      "num of updates: 94100\n",
      "GODA loss: -1.07254\n",
      "\n",
      "num of updates: 94200\n",
      "GODA loss: -1.06787\n",
      "\n",
      "num of updates: 94300\n",
      "GODA loss: -1.07662\n",
      "\n",
      "num of updates: 94400\n",
      "GODA loss: -1.07510\n",
      "\n",
      "num of updates: 94500\n",
      "GODA loss: -1.07299\n",
      "\n",
      "num of updates: 94600\n",
      "GODA loss: -1.07404\n",
      "\n",
      "num of updates: 94700\n",
      "GODA loss: -1.06206\n",
      "\n",
      "num of updates: 94800\n",
      "GODA loss: -1.08148\n",
      "\n",
      "num of updates: 94900\n",
      "GODA loss: -1.07249\n",
      "\n",
      "num of updates: 95000\n",
      "GODA loss: -1.06536\n",
      "\n",
      "num of updates: 95100\n",
      "GODA loss: -1.07644\n",
      "\n",
      "num of updates: 95200\n",
      "GODA loss: -1.07472\n",
      "\n",
      "num of updates: 95300\n",
      "GODA loss: -1.07031\n",
      "\n",
      "num of updates: 95400\n",
      "GODA loss: -1.07470\n",
      "\n",
      "num of updates: 95500\n",
      "GODA loss: -1.07295\n",
      "\n",
      "num of updates: 95600\n",
      "GODA loss: -1.06726\n",
      "\n",
      "num of updates: 95700\n",
      "GODA loss: -1.07413\n",
      "\n",
      "num of updates: 95800\n",
      "GODA loss: -1.07229\n",
      "\n",
      "num of updates: 95900\n",
      "GODA loss: -1.07839\n",
      "\n",
      "num of updates: 96000\n",
      "GODA loss: -1.08002\n",
      "\n",
      "num of updates: 96100\n",
      "GODA loss: -1.07664\n",
      "\n",
      "num of updates: 96200\n",
      "GODA loss: -1.07340\n",
      "\n",
      "num of updates: 96300\n",
      "GODA loss: -1.07606\n",
      "\n",
      "num of updates: 96400\n",
      "GODA loss: -1.08108\n",
      "\n",
      "num of updates: 96500\n",
      "GODA loss: -1.07002\n",
      "\n",
      "num of updates: 96600\n",
      "GODA loss: -1.07707\n",
      "\n",
      "num of updates: 96700\n",
      "GODA loss: -1.07675\n",
      "\n",
      "num of updates: 96800\n",
      "GODA loss: -1.07882\n",
      "\n",
      "num of updates: 96900\n",
      "GODA loss: -1.08105\n",
      "\n",
      "num of updates: 97000\n",
      "GODA loss: -1.08704\n",
      "\n",
      "num of updates: 97100\n",
      "GODA loss: -1.07643\n",
      "\n",
      "num of updates: 97200\n",
      "GODA loss: -1.07403\n",
      "\n",
      "num of updates: 97300\n",
      "GODA loss: -1.06932\n",
      "\n",
      "num of updates: 97400\n",
      "GODA loss: -1.08125\n",
      "\n",
      "num of updates: 97500\n",
      "GODA loss: -1.07634\n",
      "\n",
      "num of updates: 97600\n",
      "GODA loss: -1.07749\n",
      "\n",
      "num of updates: 97700\n",
      "GODA loss: -1.08258\n",
      "\n",
      "num of updates: 97800\n",
      "GODA loss: -1.08476\n",
      "\n",
      "num of updates: 97900\n",
      "GODA loss: -1.06971\n",
      "\n",
      "num of updates: 98000\n",
      "GODA loss: -1.08501\n",
      "\n",
      "num of updates: 98100\n",
      "GODA loss: -1.07099\n",
      "\n",
      "num of updates: 98200\n",
      "GODA loss: -1.07373\n",
      "\n",
      "num of updates: 98300\n",
      "GODA loss: -1.08426\n",
      "\n",
      "num of updates: 98400\n",
      "GODA loss: -1.07827\n",
      "\n",
      "num of updates: 98500\n",
      "GODA loss: -1.08117\n",
      "\n",
      "num of updates: 98600\n",
      "GODA loss: -1.08028\n",
      "\n",
      "num of updates: 98700\n",
      "GODA loss: -1.08581\n",
      "\n",
      "num of updates: 98800\n",
      "GODA loss: -1.07726\n",
      "\n",
      "num of updates: 98900\n",
      "GODA loss: -1.08503\n",
      "\n",
      "num of updates: 99000\n",
      "GODA loss: -1.08576\n",
      "\n",
      "num of updates: 99100\n",
      "GODA loss: -1.08463\n",
      "\n",
      "num of updates: 99200\n",
      "GODA loss: -1.08787\n",
      "\n",
      "num of updates: 99300\n",
      "GODA loss: -1.08209\n",
      "\n",
      "num of updates: 99400\n",
      "GODA loss: -1.07115\n",
      "\n",
      "num of updates: 99500\n",
      "GODA loss: -1.08438\n",
      "\n",
      "num of updates: 99600\n",
      "GODA loss: -1.08472\n",
      "\n",
      "num of updates: 99700\n",
      "GODA loss: -1.08516\n",
      "\n",
      "num of updates: 99800\n",
      "GODA loss: -1.08090\n",
      "\n",
      "num of updates: 99900\n",
      "GODA loss: -1.09127\n",
      "\n",
      "num of updates: 100000\n",
      "GODA loss: -1.08515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i_iter in range(1000):\n",
    "        log_GODA_losses = []\n",
    "        model_guide.train()\n",
    "        if not args.eval:\n",
    "            for _ in range(100):\n",
    "                try:\n",
    "                    states, actions, rewards = next(data_iter)\n",
    "                except StopIteration:\n",
    "                    data_iter = iter(traj_data_loader)\n",
    "                    states, actions, rewards = next(data_iter)\n",
    "\n",
    "                states = states.reshape(64,-1).to(device)          # 正则化\n",
    "                actions = actions.reshape(64,-1).to(device)        # 未正则化\n",
    "                rewards = rewards.reshape(64,-1).to(device)        #  \n",
    "                \n",
    "                #此处需要将三个变量合并起来\n",
    "                feature = torch.cat([states[:,0:int(state_dim*(context_len))],\n",
    "                                     actions[:,0:int(act_dim*(context_len))],\n",
    "                                     rewards[:,0:int((context_len))]],dim=1) #s1a1r1~s5a5r5     #[64,240]                                  #\n",
    "                recon_mu, recon_std, z1_mu, z1_log_std = model_guide.forward(feature)\n",
    "                GODA_loss = model_guide.loss_function(recon_mu, recon_std, feature)\n",
    "\n",
    "                optimizer_guide.zero_grad()\n",
    "                GODA_loss.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model_guide.parameters(), 0.25)\n",
    "                optimizer_guide.step()\n",
    "                scheduler_guide.step()\n",
    "\n",
    "                log_GODA_losses.append(GODA_loss.detach().cpu().item())\n",
    "        mean_GODA_loss = np.mean(log_GODA_losses)\n",
    "        total_updates += num_updates_per_iter\n",
    "        log_str = (\n",
    "            \"num of updates: \" + str(total_updates) + '\\n' +\n",
    "            \"GODA loss: \" +  format(mean_GODA_loss, \".5f\") + '\\n'\n",
    "        )\n",
    "        print(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:16:00\n",
      "num of updates: 100100\n",
      "action loss: 0.83190\n",
      "eval avg reward: -312.67801\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: -0.26177\n",
      "max d4rl score: -1.00000\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:17:16\n",
      "num of updates: 100200\n",
      "action loss: 0.78742\n",
      "eval avg reward: -297.08416\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: -0.13617\n",
      "max d4rl score: -0.26177\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:18:32\n",
      "num of updates: 100300\n",
      "action loss: 0.70179\n",
      "eval avg reward: -219.56338\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 0.48824\n",
      "max d4rl score: -0.13617\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:19:46\n",
      "num of updates: 100400\n",
      "action loss: 0.58909\n",
      "eval avg reward: -97.89647\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.46822\n",
      "max d4rl score: 0.48824\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:21:03\n",
      "num of updates: 100500\n",
      "action loss: 0.47989\n",
      "eval avg reward: -30.78485\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.00878\n",
      "max d4rl score: 1.46822\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:22:17\n",
      "num of updates: 100600\n",
      "action loss: 0.39665\n",
      "eval avg reward: -10.53133\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.17192\n",
      "max d4rl score: 2.00878\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:23:32\n",
      "num of updates: 100700\n",
      "action loss: 0.33876\n",
      "eval avg reward: 76.93117\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.87640\n",
      "max d4rl score: 2.17192\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:24:48\n",
      "num of updates: 100800\n",
      "action loss: 0.30081\n",
      "eval avg reward: 153.33422\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 3.49180\n",
      "max d4rl score: 2.87640\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:26:03\n",
      "num of updates: 100900\n",
      "action loss: 0.27738\n",
      "eval avg reward: 180.98699\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 3.71453\n",
      "max d4rl score: 3.49180\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:27:19\n",
      "num of updates: 101000\n",
      "action loss: 0.26067\n",
      "eval avg reward: 226.41669\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 4.08045\n",
      "max d4rl score: 3.71453\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:28:33\n",
      "num of updates: 101100\n",
      "action loss: 0.24575\n",
      "eval avg reward: 262.16446\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 4.36839\n",
      "max d4rl score: 4.08045\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:29:48\n",
      "num of updates: 101200\n",
      "action loss: 0.23600\n",
      "eval avg reward: 278.91335\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 4.50330\n",
      "max d4rl score: 4.36839\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:31:03\n",
      "num of updates: 101300\n",
      "action loss: 0.22902\n",
      "eval avg reward: 374.61335\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 5.27413\n",
      "max d4rl score: 4.50330\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:32:18\n",
      "num of updates: 101400\n",
      "action loss: 0.22029\n",
      "eval avg reward: 325.04815\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 4.87490\n",
      "max d4rl score: 5.27413\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:33:35\n",
      "num of updates: 101500\n",
      "action loss: 0.21572\n",
      "eval avg reward: 412.96937\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 5.58307\n",
      "max d4rl score: 5.27413\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:34:49\n",
      "num of updates: 101600\n",
      "action loss: 0.20957\n",
      "eval avg reward: 179.43359\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 3.70202\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:36:04\n",
      "num of updates: 101700\n",
      "action loss: 0.20213\n",
      "eval avg reward: 256.80081\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 4.32519\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:37:20\n",
      "num of updates: 101800\n",
      "action loss: 0.19690\n",
      "eval avg reward: 237.37312\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 4.16870\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:38:35\n",
      "num of updates: 101900\n",
      "action loss: 0.19157\n",
      "eval avg reward: 239.83260\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 4.18851\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:39:51\n",
      "num of updates: 102000\n",
      "action loss: 0.18363\n",
      "eval avg reward: 182.01688\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 3.72283\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:41:06\n",
      "num of updates: 102100\n",
      "action loss: 0.17884\n",
      "eval avg reward: 191.30619\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 3.79765\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:42:22\n",
      "num of updates: 102200\n",
      "action loss: 0.17360\n",
      "eval avg reward: 190.04618\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 3.78750\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:43:37\n",
      "num of updates: 102300\n",
      "action loss: 0.16798\n",
      "eval avg reward: 95.12350\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 3.02293\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:44:51\n",
      "num of updates: 102400\n",
      "action loss: 0.16387\n",
      "eval avg reward: 14.49061\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.37346\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:46:07\n",
      "num of updates: 102500\n",
      "action loss: 0.16244\n",
      "eval avg reward: -30.27417\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.01290\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:47:22\n",
      "num of updates: 102600\n",
      "action loss: 0.15832\n",
      "eval avg reward: -37.51515\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.95457\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:48:36\n",
      "num of updates: 102700\n",
      "action loss: 0.15356\n",
      "eval avg reward: -59.11879\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.78056\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:49:52\n",
      "num of updates: 102800\n",
      "action loss: 0.15147\n",
      "eval avg reward: -56.16725\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.80434\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:51:07\n",
      "num of updates: 102900\n",
      "action loss: 0.14833\n",
      "eval avg reward: -60.20646\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.77180\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:52:22\n",
      "num of updates: 103000\n",
      "action loss: 0.14396\n",
      "eval avg reward: -53.50183\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.82581\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:53:37\n",
      "num of updates: 103100\n",
      "action loss: 0.14228\n",
      "eval avg reward: -54.17947\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.82035\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:54:51\n",
      "num of updates: 103200\n",
      "action loss: 0.14196\n",
      "eval avg reward: -52.71999\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.83210\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:56:09\n",
      "num of updates: 103300\n",
      "action loss: 0.13724\n",
      "eval avg reward: -67.65955\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.71177\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:57:29\n",
      "num of updates: 103400\n",
      "action loss: 0.13502\n",
      "eval avg reward: -56.05446\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.80525\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 0:58:49\n",
      "num of updates: 103500\n",
      "action loss: 0.13320\n",
      "eval avg reward: -36.04443\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.96642\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:00:07\n",
      "num of updates: 103600\n",
      "action loss: 0.13252\n",
      "eval avg reward: -29.17066\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.02179\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:01:25\n",
      "num of updates: 103700\n",
      "action loss: 0.12798\n",
      "eval avg reward: -34.31614\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.98034\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:02:45\n",
      "num of updates: 103800\n",
      "action loss: 0.12615\n",
      "eval avg reward: -28.52294\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.02700\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:04:04\n",
      "num of updates: 103900\n",
      "action loss: 0.12472\n",
      "eval avg reward: -38.00777\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.95061\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:05:24\n",
      "num of updates: 104000\n",
      "action loss: 0.12271\n",
      "eval avg reward: -53.50700\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.82576\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:06:45\n",
      "num of updates: 104100\n",
      "action loss: 0.12065\n",
      "eval avg reward: -22.07004\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.07898\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:08:05\n",
      "num of updates: 104200\n",
      "action loss: 0.11755\n",
      "eval avg reward: -20.80423\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.08917\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:09:25\n",
      "num of updates: 104300\n",
      "action loss: 0.11861\n",
      "eval avg reward: -11.34798\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.16534\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:10:45\n",
      "num of updates: 104400\n",
      "action loss: 0.11501\n",
      "eval avg reward: -20.54010\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.09130\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:12:03\n",
      "num of updates: 104500\n",
      "action loss: 0.11338\n",
      "eval avg reward: -35.86148\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.96789\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:13:23\n",
      "num of updates: 104600\n",
      "action loss: 0.11268\n",
      "eval avg reward: -23.84479\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.06468\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:14:41\n",
      "num of updates: 104700\n",
      "action loss: 0.11222\n",
      "eval avg reward: -34.94305\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.97529\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:16:03\n",
      "num of updates: 104800\n",
      "action loss: 0.10998\n",
      "eval avg reward: -33.39819\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.98773\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:17:30\n",
      "num of updates: 104900\n",
      "action loss: 0.10841\n",
      "eval avg reward: -22.92544\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.07209\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:18:51\n",
      "num of updates: 105000\n",
      "action loss: 0.10737\n",
      "eval avg reward: -34.79317\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.97650\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:20:07\n",
      "num of updates: 105100\n",
      "action loss: 0.10504\n",
      "eval avg reward: -21.14951\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.08639\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:21:27\n",
      "num of updates: 105200\n",
      "action loss: 0.10362\n",
      "eval avg reward: -29.44267\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.01959\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:22:43\n",
      "num of updates: 105300\n",
      "action loss: 0.10346\n",
      "eval avg reward: -50.84545\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.84720\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:24:01\n",
      "num of updates: 105400\n",
      "action loss: 0.10141\n",
      "eval avg reward: -36.06671\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.96624\n",
      "max d4rl score: 5.58307\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:25:27\n",
      "num of updates: 105500\n",
      "action loss: 0.10086\n",
      "eval avg reward: 1015.69376\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 10.43781\n",
      "max d4rl score: 5.58307\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:26:50\n",
      "num of updates: 105600\n",
      "action loss: 0.09896\n",
      "eval avg reward: 42.99235\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 2.60303\n",
      "max d4rl score: 10.43781\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:28:13\n",
      "num of updates: 105700\n",
      "action loss: 0.09946\n",
      "eval avg reward: -60.89016\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 1.76630\n",
      "max d4rl score: 10.43781\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:29:37\n",
      "num of updates: 105800\n",
      "action loss: 0.09716\n",
      "eval avg reward: 1115.81333\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 11.24424\n",
      "max d4rl score: 10.43781\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:31:01\n",
      "num of updates: 105900\n",
      "action loss: 0.09708\n",
      "eval avg reward: 564.27505\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 6.80179\n",
      "max d4rl score: 11.24424\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:32:24\n",
      "num of updates: 106000\n",
      "action loss: 0.09584\n",
      "eval avg reward: 381.05211\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 5.32599\n",
      "max d4rl score: 11.24424\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:33:49\n",
      "num of updates: 106100\n",
      "action loss: 0.09336\n",
      "eval avg reward: 1351.35644\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 13.14146\n",
      "max d4rl score: 11.24424\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:35:13\n",
      "num of updates: 106200\n",
      "action loss: 0.09389\n",
      "eval avg reward: 1882.12980\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 17.41665\n",
      "max d4rl score: 13.14146\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:36:37\n",
      "num of updates: 106300\n",
      "action loss: 0.09108\n",
      "eval avg reward: 2458.01076\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 22.05518\n",
      "max d4rl score: 17.41665\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:38:01\n",
      "num of updates: 106400\n",
      "action loss: 0.09093\n",
      "eval avg reward: 1989.23215\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 18.27933\n",
      "max d4rl score: 22.05518\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:39:24\n",
      "num of updates: 106500\n",
      "action loss: 0.09097\n",
      "eval avg reward: 2109.09333\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 19.24477\n",
      "max d4rl score: 22.05518\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:40:48\n",
      "num of updates: 106600\n",
      "action loss: 0.08951\n",
      "eval avg reward: 2294.85223\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 20.74099\n",
      "max d4rl score: 22.05518\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:42:13\n",
      "num of updates: 106700\n",
      "action loss: 0.08959\n",
      "eval avg reward: 2468.59608\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 22.14044\n",
      "max d4rl score: 22.05518\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:43:36\n",
      "num of updates: 106800\n",
      "action loss: 0.08808\n",
      "eval avg reward: 1868.09709\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 17.30363\n",
      "max d4rl score: 22.14044\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:44:59\n",
      "num of updates: 106900\n",
      "action loss: 0.08707\n",
      "eval avg reward: 1818.32848\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 16.90276\n",
      "max d4rl score: 22.14044\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:46:24\n",
      "num of updates: 107000\n",
      "action loss: 0.08720\n",
      "eval avg reward: 2031.41757\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 18.61912\n",
      "max d4rl score: 22.14044\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:47:48\n",
      "num of updates: 107100\n",
      "action loss: 0.08570\n",
      "eval avg reward: 2882.54327\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 25.47464\n",
      "max d4rl score: 22.14044\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:49:12\n",
      "num of updates: 107200\n",
      "action loss: 0.08581\n",
      "eval avg reward: 1687.38631\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 15.84806\n",
      "max d4rl score: 25.47464\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:50:36\n",
      "num of updates: 107300\n",
      "action loss: 0.08473\n",
      "eval avg reward: 2672.45250\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 23.78243\n",
      "max d4rl score: 25.47464\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:52:00\n",
      "num of updates: 107400\n",
      "action loss: 0.08292\n",
      "eval avg reward: 2641.97082\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 23.53691\n",
      "max d4rl score: 25.47464\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:53:24\n",
      "num of updates: 107500\n",
      "action loss: 0.08281\n",
      "eval avg reward: 2531.39638\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 22.64627\n",
      "max d4rl score: 25.47464\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:54:48\n",
      "num of updates: 107600\n",
      "action loss: 0.08047\n",
      "eval avg reward: 2031.24968\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 18.61776\n",
      "max d4rl score: 25.47464\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:56:11\n",
      "num of updates: 107700\n",
      "action loss: 0.08206\n",
      "eval avg reward: 2625.23806\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 23.40214\n",
      "max d4rl score: 25.47464\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:57:36\n",
      "num of updates: 107800\n",
      "action loss: 0.08083\n",
      "eval avg reward: 2722.27002\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 24.18369\n",
      "max d4rl score: 25.47464\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 1:59:01\n",
      "num of updates: 107900\n",
      "action loss: 0.07947\n",
      "eval avg reward: 3013.95174\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 26.53309\n",
      "max d4rl score: 25.47464\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:00:26\n",
      "num of updates: 108000\n",
      "action loss: 0.07986\n",
      "eval avg reward: 3285.03717\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 28.71659\n",
      "max d4rl score: 26.53309\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:01:56\n",
      "num of updates: 108100\n",
      "action loss: 0.07812\n",
      "eval avg reward: 3849.09593\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 33.25989\n",
      "max d4rl score: 28.71659\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:03:27\n",
      "num of updates: 108200\n",
      "action loss: 0.07973\n",
      "eval avg reward: 3281.87268\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 28.69110\n",
      "max d4rl score: 33.25989\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:04:57\n",
      "num of updates: 108300\n",
      "action loss: 0.07795\n",
      "eval avg reward: 3978.91416\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 34.30553\n",
      "max d4rl score: 33.25989\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:06:29\n",
      "num of updates: 108400\n",
      "action loss: 0.07668\n",
      "eval avg reward: 4049.26246\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 34.87216\n",
      "max d4rl score: 34.30553\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:08:00\n",
      "num of updates: 108500\n",
      "action loss: 0.07724\n",
      "eval avg reward: 3777.57620\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 32.68382\n",
      "max d4rl score: 34.87216\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:09:30\n",
      "num of updates: 108600\n",
      "action loss: 0.07618\n",
      "eval avg reward: 2690.76529\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 23.92993\n",
      "max d4rl score: 34.87216\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:11:01\n",
      "num of updates: 108700\n",
      "action loss: 0.07509\n",
      "eval avg reward: 3822.44357\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 33.04521\n",
      "max d4rl score: 34.87216\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:12:30\n",
      "num of updates: 108800\n",
      "action loss: 0.07551\n",
      "eval avg reward: 2685.91474\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 23.89087\n",
      "max d4rl score: 34.87216\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:14:01\n",
      "num of updates: 108900\n",
      "action loss: 0.07410\n",
      "eval avg reward: 4251.80062\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 36.50354\n",
      "max d4rl score: 34.87216\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:15:33\n",
      "num of updates: 109000\n",
      "action loss: 0.07445\n",
      "eval avg reward: 3540.79098\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 30.77660\n",
      "max d4rl score: 36.50354\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:17:08\n",
      "num of updates: 109100\n",
      "action loss: 0.07452\n",
      "eval avg reward: 3083.41216\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 27.09257\n",
      "max d4rl score: 36.50354\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:18:49\n",
      "num of updates: 109200\n",
      "action loss: 0.07388\n",
      "eval avg reward: 3962.15983\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 34.17058\n",
      "max d4rl score: 36.50354\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:20:28\n",
      "num of updates: 109300\n",
      "action loss: 0.07295\n",
      "eval avg reward: 3783.85603\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 32.73441\n",
      "max d4rl score: 36.50354\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:22:08\n",
      "num of updates: 109400\n",
      "action loss: 0.07172\n",
      "eval avg reward: 3139.35732\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 27.54319\n",
      "max d4rl score: 36.50354\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:23:48\n",
      "num of updates: 109500\n",
      "action loss: 0.07258\n",
      "eval avg reward: 4563.73225\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.01604\n",
      "max d4rl score: 36.50354\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:25:29\n",
      "num of updates: 109600\n",
      "action loss: 0.07159\n",
      "eval avg reward: 3918.89071\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 33.82206\n",
      "max d4rl score: 39.01604\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:27:08\n",
      "num of updates: 109700\n",
      "action loss: 0.07242\n",
      "eval avg reward: 3791.26034\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 32.79404\n",
      "max d4rl score: 39.01604\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:28:48\n",
      "num of updates: 109800\n",
      "action loss: 0.07084\n",
      "eval avg reward: 3990.36637\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 34.39777\n",
      "max d4rl score: 39.01604\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:30:28\n",
      "num of updates: 109900\n",
      "action loss: 0.07080\n",
      "eval avg reward: 4574.65110\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.10399\n",
      "max d4rl score: 39.01604\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:32:08\n",
      "num of updates: 110000\n",
      "action loss: 0.07056\n",
      "eval avg reward: 3991.18758\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 34.40439\n",
      "max d4rl score: 39.10399\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:33:47\n",
      "num of updates: 110100\n",
      "action loss: 0.07012\n",
      "eval avg reward: 3103.78309\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 27.25665\n",
      "max d4rl score: 39.10399\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:35:27\n",
      "num of updates: 110200\n",
      "action loss: 0.07008\n",
      "eval avg reward: 3684.94229\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 31.93769\n",
      "max d4rl score: 39.10399\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:37:05\n",
      "num of updates: 110300\n",
      "action loss: 0.06983\n",
      "eval avg reward: 3252.04102\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 28.45082\n",
      "max d4rl score: 39.10399\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:38:44\n",
      "num of updates: 110400\n",
      "action loss: 0.06863\n",
      "eval avg reward: 4031.03181\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 34.72532\n",
      "max d4rl score: 39.10399\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:40:24\n",
      "num of updates: 110500\n",
      "action loss: 0.06872\n",
      "eval avg reward: 3924.45749\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 33.86690\n",
      "max d4rl score: 39.10399\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:42:04\n",
      "num of updates: 110600\n",
      "action loss: 0.06716\n",
      "eval avg reward: 3539.13078\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 30.76323\n",
      "max d4rl score: 39.10399\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:43:44\n",
      "num of updates: 110700\n",
      "action loss: 0.06945\n",
      "eval avg reward: 3634.72667\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 31.53322\n",
      "max d4rl score: 39.10399\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:45:23\n",
      "num of updates: 110800\n",
      "action loss: 0.06803\n",
      "eval avg reward: 4594.77707\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.26610\n",
      "max d4rl score: 39.10399\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:47:04\n",
      "num of updates: 110900\n",
      "action loss: 0.06771\n",
      "eval avg reward: 4169.46017\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.84031\n",
      "max d4rl score: 39.26610\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:48:43\n",
      "num of updates: 111000\n",
      "action loss: 0.06688\n",
      "eval avg reward: 4891.98758\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.66002\n",
      "max d4rl score: 39.26610\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:50:24\n",
      "num of updates: 111100\n",
      "action loss: 0.06655\n",
      "eval avg reward: 4494.41929\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.45775\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:52:03\n",
      "num of updates: 111200\n",
      "action loss: 0.06626\n",
      "eval avg reward: 4387.46503\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.59627\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:53:43\n",
      "num of updates: 111300\n",
      "action loss: 0.06596\n",
      "eval avg reward: 4619.68214\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.46670\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:55:22\n",
      "num of updates: 111400\n",
      "action loss: 0.06509\n",
      "eval avg reward: 4343.87035\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.24513\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:57:02\n",
      "num of updates: 111500\n",
      "action loss: 0.06526\n",
      "eval avg reward: 4563.42203\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.01354\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 2:58:45\n",
      "num of updates: 111600\n",
      "action loss: 0.06596\n",
      "eval avg reward: 4172.78600\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.86710\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:00:25\n",
      "num of updates: 111700\n",
      "action loss: 0.06449\n",
      "eval avg reward: 4198.18293\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 36.07167\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:02:06\n",
      "num of updates: 111800\n",
      "action loss: 0.06559\n",
      "eval avg reward: 4415.51376\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.82219\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:03:47\n",
      "num of updates: 111900\n",
      "action loss: 0.06467\n",
      "eval avg reward: 4149.53285\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.67981\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:05:32\n",
      "num of updates: 112000\n",
      "action loss: 0.06433\n",
      "eval avg reward: 4398.93686\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.68867\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:07:15\n",
      "num of updates: 112100\n",
      "action loss: 0.06413\n",
      "eval avg reward: 4608.25104\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.37462\n",
      "max d4rl score: 41.66002\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:09:02\n",
      "num of updates: 112200\n",
      "action loss: 0.06353\n",
      "eval avg reward: 5020.58674\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.69585\n",
      "max d4rl score: 41.66002\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:10:47\n",
      "num of updates: 112300\n",
      "action loss: 0.06464\n",
      "eval avg reward: 4429.03939\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.93114\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:12:30\n",
      "num of updates: 112400\n",
      "action loss: 0.06308\n",
      "eval avg reward: 4769.98996\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.67738\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:14:15\n",
      "num of updates: 112500\n",
      "action loss: 0.06289\n",
      "eval avg reward: 4430.26308\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.94099\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:16:00\n",
      "num of updates: 112600\n",
      "action loss: 0.06387\n",
      "eval avg reward: 5013.73829\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.64068\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:17:44\n",
      "num of updates: 112700\n",
      "action loss: 0.06323\n",
      "eval avg reward: 4241.18006\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 36.41799\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:19:28\n",
      "num of updates: 112800\n",
      "action loss: 0.06206\n",
      "eval avg reward: 4462.46853\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.20040\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:21:12\n",
      "num of updates: 112900\n",
      "action loss: 0.06284\n",
      "eval avg reward: 4517.34672\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.64242\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:22:57\n",
      "num of updates: 113000\n",
      "action loss: 0.06260\n",
      "eval avg reward: 4732.62680\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.37643\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:24:41\n",
      "num of updates: 113100\n",
      "action loss: 0.06180\n",
      "eval avg reward: 4909.76266\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.80320\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:26:25\n",
      "num of updates: 113200\n",
      "action loss: 0.06056\n",
      "eval avg reward: 4160.18359\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.76559\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:28:11\n",
      "num of updates: 113300\n",
      "action loss: 0.06103\n",
      "eval avg reward: 4159.70838\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.76177\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:29:55\n",
      "num of updates: 113400\n",
      "action loss: 0.06134\n",
      "eval avg reward: 4957.32856\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.18632\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:31:40\n",
      "num of updates: 113500\n",
      "action loss: 0.06134\n",
      "eval avg reward: 4926.38239\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.93706\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:33:24\n",
      "num of updates: 113600\n",
      "action loss: 0.06012\n",
      "eval avg reward: 4651.35876\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.72184\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:35:09\n",
      "num of updates: 113700\n",
      "action loss: 0.06071\n",
      "eval avg reward: 4245.16637\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 36.45010\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:36:53\n",
      "num of updates: 113800\n",
      "action loss: 0.06147\n",
      "eval avg reward: 4989.39693\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.44462\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:38:37\n",
      "num of updates: 113900\n",
      "action loss: 0.06073\n",
      "eval avg reward: 4926.27365\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.93619\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:40:22\n",
      "num of updates: 114000\n",
      "action loss: 0.06008\n",
      "eval avg reward: 4536.92370\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.80011\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:42:07\n",
      "num of updates: 114100\n",
      "action loss: 0.06001\n",
      "eval avg reward: 4445.56831\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.06427\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:43:51\n",
      "num of updates: 114200\n",
      "action loss: 0.06017\n",
      "eval avg reward: 4624.47702\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.50532\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:45:34\n",
      "num of updates: 114300\n",
      "action loss: 0.05948\n",
      "eval avg reward: 4847.10051\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.29847\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:47:22\n",
      "num of updates: 114400\n",
      "action loss: 0.05968\n",
      "eval avg reward: 4929.41558\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.96149\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:49:06\n",
      "num of updates: 114500\n",
      "action loss: 0.05939\n",
      "eval avg reward: 4621.63244\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.48241\n",
      "max d4rl score: 42.69585\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:50:50\n",
      "num of updates: 114600\n",
      "action loss: 0.05967\n",
      "eval avg reward: 5041.14706\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.86145\n",
      "max d4rl score: 42.69585\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:52:35\n",
      "num of updates: 114700\n",
      "action loss: 0.05926\n",
      "eval avg reward: 4459.70903\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.17817\n",
      "max d4rl score: 42.86145\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:54:21\n",
      "num of updates: 114800\n",
      "action loss: 0.05911\n",
      "eval avg reward: 4390.23933\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.61861\n",
      "max d4rl score: 42.86145\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:56:05\n",
      "num of updates: 114900\n",
      "action loss: 0.05828\n",
      "eval avg reward: 4364.83736\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.41401\n",
      "max d4rl score: 42.86145\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:57:51\n",
      "num of updates: 115000\n",
      "action loss: 0.05871\n",
      "eval avg reward: 4521.69935\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.67748\n",
      "max d4rl score: 42.86145\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 3:59:36\n",
      "num of updates: 115100\n",
      "action loss: 0.05769\n",
      "eval avg reward: 4170.67378\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.85009\n",
      "max d4rl score: 42.86145\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:01:22\n",
      "num of updates: 115200\n",
      "action loss: 0.05840\n",
      "eval avg reward: 4183.14973\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.95058\n",
      "max d4rl score: 42.86145\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:03:07\n",
      "num of updates: 115300\n",
      "action loss: 0.05720\n",
      "eval avg reward: 5077.07400\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 43.15083\n",
      "max d4rl score: 42.86145\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:04:53\n",
      "num of updates: 115400\n",
      "action loss: 0.05822\n",
      "eval avg reward: 5014.38448\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.64589\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:06:38\n",
      "num of updates: 115500\n",
      "action loss: 0.05764\n",
      "eval avg reward: 3623.74254\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 31.44475\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:08:23\n",
      "num of updates: 115600\n",
      "action loss: 0.05702\n",
      "eval avg reward: 4571.24204\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.07653\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:10:06\n",
      "num of updates: 115700\n",
      "action loss: 0.05845\n",
      "eval avg reward: 4399.21296\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.69089\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:11:52\n",
      "num of updates: 115800\n",
      "action loss: 0.05715\n",
      "eval avg reward: 4122.53744\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.46237\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:13:37\n",
      "num of updates: 115900\n",
      "action loss: 0.05790\n",
      "eval avg reward: 4505.93373\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.55049\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:15:21\n",
      "num of updates: 116000\n",
      "action loss: 0.05767\n",
      "eval avg reward: 4900.50712\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.72865\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:17:07\n",
      "num of updates: 116100\n",
      "action loss: 0.05627\n",
      "eval avg reward: 4308.40542\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 36.95947\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:18:52\n",
      "num of updates: 116200\n",
      "action loss: 0.05717\n",
      "eval avg reward: 4705.68921\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.15945\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:20:39\n",
      "num of updates: 116300\n",
      "action loss: 0.05643\n",
      "eval avg reward: 4646.08260\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.67934\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:22:27\n",
      "num of updates: 116400\n",
      "action loss: 0.05668\n",
      "eval avg reward: 4135.07705\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.56337\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:24:18\n",
      "num of updates: 116500\n",
      "action loss: 0.05677\n",
      "eval avg reward: 4868.00481\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.46685\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:26:07\n",
      "num of updates: 116600\n",
      "action loss: 0.05640\n",
      "eval avg reward: 4921.45084\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.89734\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:27:56\n",
      "num of updates: 116700\n",
      "action loss: 0.05599\n",
      "eval avg reward: 4805.61997\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.96436\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:29:44\n",
      "num of updates: 116800\n",
      "action loss: 0.05552\n",
      "eval avg reward: 4925.31368\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.92845\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:31:28\n",
      "num of updates: 116900\n",
      "action loss: 0.05642\n",
      "eval avg reward: 4972.41234\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.30782\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:33:07\n",
      "num of updates: 117000\n",
      "action loss: 0.05591\n",
      "eval avg reward: 4537.61786\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.80570\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:34:42\n",
      "num of updates: 117100\n",
      "action loss: 0.05673\n",
      "eval avg reward: 4378.03938\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.52035\n",
      "max d4rl score: 43.15083\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:36:16\n",
      "num of updates: 117200\n",
      "action loss: 0.05650\n",
      "eval avg reward: 5096.84075\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 43.31005\n",
      "max d4rl score: 43.15083\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:37:51\n",
      "num of updates: 117300\n",
      "action loss: 0.05548\n",
      "eval avg reward: 4755.34293\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.55940\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:39:27\n",
      "num of updates: 117400\n",
      "action loss: 0.05555\n",
      "eval avg reward: 4887.61020\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.62477\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:41:05\n",
      "num of updates: 117500\n",
      "action loss: 0.05512\n",
      "eval avg reward: 4942.42786\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.06630\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:42:42\n",
      "num of updates: 117600\n",
      "action loss: 0.05555\n",
      "eval avg reward: 4530.99855\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.75238\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:44:18\n",
      "num of updates: 117700\n",
      "action loss: 0.05501\n",
      "eval avg reward: 4109.81667\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 35.35991\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:45:55\n",
      "num of updates: 117800\n",
      "action loss: 0.05503\n",
      "eval avg reward: 4527.85309\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.72705\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:47:29\n",
      "num of updates: 117900\n",
      "action loss: 0.05488\n",
      "eval avg reward: 4366.19422\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 37.42494\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:49:02\n",
      "num of updates: 118000\n",
      "action loss: 0.05491\n",
      "eval avg reward: 4931.32531\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.97688\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:50:36\n",
      "num of updates: 118100\n",
      "action loss: 0.05440\n",
      "eval avg reward: 3991.23116\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 34.40474\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:52:10\n",
      "num of updates: 118200\n",
      "action loss: 0.05466\n",
      "eval avg reward: 4736.24393\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.40556\n",
      "max d4rl score: 43.31005\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:53:40\n",
      "num of updates: 118300\n",
      "action loss: 0.05436\n",
      "eval avg reward: 5123.57741\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 43.52540\n",
      "max d4rl score: 43.31005\n",
      "saving max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:55:07\n",
      "num of updates: 118400\n",
      "action loss: 0.05395\n",
      "eval avg reward: 4794.46815\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.87454\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:56:34\n",
      "num of updates: 118500\n",
      "action loss: 0.05436\n",
      "eval avg reward: 4644.54474\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.66696\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:58:01\n",
      "num of updates: 118600\n",
      "action loss: 0.05393\n",
      "eval avg reward: 4944.11603\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.07990\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 4:59:28\n",
      "num of updates: 118700\n",
      "action loss: 0.05473\n",
      "eval avg reward: 4558.77603\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.97612\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:00:55\n",
      "num of updates: 118800\n",
      "action loss: 0.05451\n",
      "eval avg reward: 4484.25599\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 38.37589\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:02:22\n",
      "num of updates: 118900\n",
      "action loss: 0.05474\n",
      "eval avg reward: 4943.81223\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.07745\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:03:49\n",
      "num of updates: 119000\n",
      "action loss: 0.05487\n",
      "eval avg reward: 4984.65342\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.40642\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:05:18\n",
      "num of updates: 119100\n",
      "action loss: 0.05331\n",
      "eval avg reward: 3408.82752\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 29.71368\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:06:44\n",
      "num of updates: 119200\n",
      "action loss: 0.05433\n",
      "eval avg reward: 4727.45660\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.33478\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:08:11\n",
      "num of updates: 119300\n",
      "action loss: 0.05430\n",
      "eval avg reward: 4987.71818\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.43110\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:09:40\n",
      "num of updates: 119400\n",
      "action loss: 0.05392\n",
      "eval avg reward: 4624.79065\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.50784\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:11:06\n",
      "num of updates: 119500\n",
      "action loss: 0.05333\n",
      "eval avg reward: 5010.50133\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.61461\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:12:34\n",
      "num of updates: 119600\n",
      "action loss: 0.05322\n",
      "eval avg reward: 4905.72549\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 41.77068\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:14:02\n",
      "num of updates: 119700\n",
      "action loss: 0.05365\n",
      "eval avg reward: 4702.18059\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.13119\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:15:31\n",
      "num of updates: 119800\n",
      "action loss: 0.05328\n",
      "eval avg reward: 4749.35098\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 40.51114\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:17:02\n",
      "num of updates: 119900\n",
      "action loss: 0.05232\n",
      "eval avg reward: 5006.44799\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 42.58196\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "time elapsed: 5:18:32\n",
      "num of updates: 120000\n",
      "action loss: 0.05375\n",
      "eval avg reward: 4629.45210\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 39.54539\n",
      "max d4rl score: 43.52540\n",
      "saving current model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n",
      "finished training!\n",
      "============================================================\n",
      "started training at: 23-03-23-19-27-04\n",
      "finished training at: 23-03-24-00-45-36\n",
      "total training time: 5:18:32\n",
      "max d4rl score: 43.52540\n",
      "saved max d4rl score model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04_best.pt\n",
      "saved last updated model at: dt_runs/dt_halfcheetah_medium-v2_model_23-03-23-19-27-04.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from imitation_learning.model import Starloss\n",
    "model_guide.eval()\n",
    "state_mean, state_std,reward_mean,reward_std = traj_star_dataset.get_state_stats()\n",
    "reward_mean = torch.from_numpy(np.array(reward_mean)).to(device)\n",
    "reward_std = torch.from_numpy(np.array(reward_std)).to(device)\n",
    "for i_train_iter in range(max_train_iters):\n",
    "\n",
    "    log_action_losses = []\n",
    "    model.train()\n",
    "\n",
    "    for _ in range(num_updates_per_iter):\n",
    "        try:\n",
    "            timesteps, states, actions, traj_mask, rewards = next(star_iter)\n",
    "        except StopIteration:\n",
    "            star_iter = iter(traj_star_loader)\n",
    "            timesteps, states, actions, traj_mask, rewards = next(star_iter)\n",
    "\n",
    "        timesteps = timesteps.to(device)    # B x T\n",
    "        states = states.to(device)          # 正则化\n",
    "        actions_ori = actions.to(device)        # 未正则化\n",
    "        traj_mask = traj_mask.to(device)    # B x T\n",
    "        action_target = torch.clone(actions).detach().to(device)\n",
    "        #将采样出的数据输入增强网络********************************************************************************************************************************\n",
    "        states = states.reshape(64 ,-1).to(device)          # B x T x state_dim     [64,340]                                                       # \n",
    "        actions = actions.reshape(64 ,-1).to(device) # B x T x act_dim       [64,120]                                                        #\n",
    "        rewards = rewards.reshape(64 ,-1).to(device)        #                       [64,20]                                                        #\n",
    "                                                                                                                                                                \n",
    "        feature = torch.cat([states[:,0:int(state_dim*(context_len))],\n",
    "                                    actions[:,0:int(act_dim*(context_len))],\n",
    "                                    rewards[:,0:int((context_len))]],dim=1) #s1a1r1~s5a5r5     #[64,240]                                                      #\n",
    "        recon_mu, recon_std, z1_mu, z1_log_std = model_guide.forward(feature)\n",
    "        z = z1_mu.clone().detach()                                                                                                                              #\n",
    "        z.requires_grad = True                                                                                                                                  #\n",
    "        scene_optim = torch.optim.Adam([z], lr=lr)                                                                                                              #\n",
    "        loss_star_function = Starloss()                                                                                                                         #\n",
    "        loss =[]                                                                                                                                                #\n",
    "        #找到这64条序列对应的最好的z                                                                                                                              #                \n",
    "        for i in range(200):                                                                                                                                    #\n",
    "            recon_mu,recon_log_std = model_guide.decode(z)                                                                                              #\n",
    "            rewards_ = recon_mu[:,(state_dim+act_dim)*int(context_len):]#rewards: s6'~s10'\n",
    "            rewards_ =  torch.mean(rewards_.reshape(64,10,1)*reward_std + reward_mean)                                                      #\n",
    "            loss_star = loss_star_function.forward(rewards_, z, z1_mu, ratio_a, ratio_b)                                                                           #\n",
    "            loss.append(loss_star.detach().cpu().item())                                                                                                        #\n",
    "            scene_optim.zero_grad()                                                                                                                             #                 \n",
    "            loss_star.backward(retain_graph=True)                                                                                                               #\n",
    "            scene_optim.step()                                                                                                                                  #\n",
    "        recon_mu,recon_log_std = model_guide.decode(z) \n",
    "    #替换数据                                                                                                                                                    #\n",
    "        #恢复s1'a1'r1'~s10'a10'r10'                                                                                                              #\n",
    "        states = recon_mu[:,0:int(state_dim*(context_len))].reshape(64,10,17).to(device)                                                                                               #\n",
    "        actions = recon_mu[:,state_dim*int(context_len):(state_dim+act_dim)*int(context_len)].reshape(64,10,6).to(device)\n",
    "        #********************************************************************************************************************************************************\n",
    "        state_preds, action_preds   = model.forward(\n",
    "                                                        timesteps=timesteps,\n",
    "                                                        states=states,\n",
    "                                                        actions=actions_ori,\n",
    "                                                    )\n",
    "        # only consider non padded elements\n",
    "        action_preds = action_preds.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
    "        action_target = action_target.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
    "\n",
    "        action_loss = F.mse_loss(action_preds, action_target, reduction='mean')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        action_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        log_action_losses.append(action_loss.detach().cpu().item())\n",
    "\n",
    "    # evaluate action accuracy\n",
    "    results = evaluate_on_env(model, device, context_len, env,\n",
    "                            num_eval_ep, max_eval_ep_len, state_mean, state_std)\n",
    "\n",
    "    eval_avg_reward = results['eval/avg_reward']\n",
    "    eval_avg_ep_len = results['eval/avg_ep_len']\n",
    "    eval_d4rl_score = get_d4rl_normalized_score(results['eval/avg_reward'], env_name) * 100\n",
    "\n",
    "    mean_action_loss = np.mean(log_action_losses)\n",
    "    time_elapsed = str(datetime.now().replace(microsecond=0) - start_time)\n",
    "\n",
    "    total_updates += num_updates_per_iter\n",
    "\n",
    "    log_str = (\"=\" * 60 + '\\n' +\n",
    "            \"time elapsed: \" + time_elapsed  + '\\n' +\n",
    "            \"num of updates: \" + str(total_updates) + '\\n' +\n",
    "            \"action loss: \" +  format(mean_action_loss, \".5f\") + '\\n' +\n",
    "            \"eval avg reward: \" + format(eval_avg_reward, \".5f\") + '\\n' +\n",
    "            \"eval avg ep len: \" + format(eval_avg_ep_len, \".5f\") + '\\n' +\n",
    "            \"eval d4rl score: \" + format(eval_d4rl_score, \".5f\")\n",
    "        )\n",
    "\n",
    "    print(log_str)\n",
    "\n",
    "    log_data = [time_elapsed, total_updates, mean_action_loss,\n",
    "                eval_avg_reward, eval_avg_ep_len,\n",
    "                eval_d4rl_score]\n",
    "\n",
    "    csv_writer.writerow(log_data)\n",
    "\n",
    "    # save model\n",
    "    print(\"max d4rl score: \" + format(max_d4rl_score, \".5f\"))\n",
    "    if eval_d4rl_score >= max_d4rl_score:\n",
    "        print(\"saving max d4rl score model at: \" + save_best_model_path)\n",
    "        torch.save(model.state_dict(), save_best_model_path)\n",
    "        max_d4rl_score = eval_d4rl_score\n",
    "\n",
    "    print(\"saving current model at: \" + save_model_path)\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"finished training!\")\n",
    "print(\"=\" * 60)\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "time_elapsed = str(end_time - start_time)\n",
    "end_time_str = end_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "print(\"started training at: \" + start_time_str)\n",
    "print(\"finished training at: \" + end_time_str)\n",
    "print(\"total training time: \" + time_elapsed)\n",
    "print(\"max d4rl score: \" + format(max_d4rl_score, \".5f\"))\n",
    "print(\"saved max d4rl score model at: \" + save_best_model_path)\n",
    "print(\"saved last updated model at: \" + save_model_path)\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safe-slac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
